[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "확률과정론\nguebin@jbnu.ac.kr\n자연과학대학 본관 205호"
  },
  {
    "objectID": "posts/2023-04-10-6wk-2-mid.html",
    "href": "posts/2023-04-10-6wk-2-mid.html",
    "title": "06wk-2: 중간고사",
    "section": "",
    "text": "1. Cardinality\n(1) \\(\\mathbb{Q}\\)의 cardinality가 \\(\\aleph_0\\)임을 증명하라.\n(풀이) 생략\n(2) \\(\\mathbb{R}\\)의 cardinality가 \\(\\aleph_0\\)이 아님을 보여라.\n(풀이) 생략\n\n\n2. \\(\\sigma\\)-field\n(1) \\(\\Omega=\\{1,2,3,4,5,6\\}\\)일 때, 다음 중 시그마필드의 정의를 만족하는 집합을 모두 골라라.\n\n\\({\\cal F}=\\{\\emptyset, \\Omega\\}\\)\n\\({\\cal F}=\\{\\emptyset, \\{1\\},\\{2,3,4,5,6\\},\\Omega\\}\\)\n\\({\\cal F}=\\{\\emptyset, \\{1,2,3\\}, \\{4,5,6\\}, \\Omega\\}\\)\n\\({\\cal F}=2^\\Omega\\)\n\n(풀이) 1,2,3,4 모두 시그마필드\n(2) \\(\\Omega=\\{1,2,3,4,5,6\\}\\) 일 때,\n\\[{\\cal A}=\\{\\{1,2,3\\},\\{4,5,6\\}\\}\\]\n이라고 하자. \\(\\sigma({\\cal A})\\)를 구하여라.\n(풀이) \\(\\sigma({\\cal A}) = \\{\\emptyset, \\Omega, \\{1,2,3\\},\\{4,5,6\\}\\}\\)\n(3) \\(\\Omega=\\mathbb{N}\\) 일 때,\n\n\\({\\cal A}=\\{\\{n\\}: n \\in \\mathbb{N}\\}\\)\n\\({\\cal F} = \\sigma({\\cal A})\\)\n\n이라고 하자. 아래의 물음에 답하여라.\n\n\\(\\{2\\} \\in {\\cal F}\\) 인가?\n\\(\\mathbb{N} \\in {\\cal F}\\) 인가?\n\\(\\emptyset \\in {\\cal F}\\) 인가?\n\\(\\{2n: n\\in \\mathbb{N}\\} \\in {\\cal F}\\) 인가?\n\\(\\mathbb{Z} \\in {\\cal F}\\) 인가?\n\n(풀이) 1,2,3,4 (O) // 5 (X)\n시그마필드는 공집합과 전체집합을 포함하므로 \\(\\mathbb{N}, \\emptyset\\)은 \\({\\cal F}\\)의 원소이어야 한다. 시그마필드의 원소는 \\(\\mathbb{N}\\)의 부분집합이어야 하므로 \\(\\mathbb{Z}\\)는 \\({\\cal F}\\)의 원소가 될 수 없다. \\({\\cal F}\\)는 \\(\\{2\\},\\{4\\},\\{6\\},\\dots\\) 등을 원소로 포함하고 가산합집합에 닫혀있으므로 \\(\\{2n: n \\in \\mathbb{N}\\}\\) 은 \\({\\cal F}\\)의 원소이다.\n(4) \\(\\Omega=\\mathbb{R}\\) 일 때,\n\n\\({\\cal A}=\\{(a,b): -\\infty <a< b< \\infty\\}\\)\n\\({\\cal F}=\\sigma({\\cal A})\\)\n\n이라고 하자. 아래의 물음에 답하여라.\n\n\\(\\{0\\} \\in {\\cal F}\\) 인가?\n\\(\\mathbb{R} \\in {\\cal F}\\) 인가?\n\\(\\mathbb{Q} \\in {\\cal F}\\) 인가?\n\\(\\mathbb{R} - \\mathbb{Q} \\in {\\cal F}\\) 인가?\n\\((1,3] \\in {\\cal F}\\) 인가?\n\\([1,3] \\in {\\cal F}\\) 인가?\n\\([1,3) \\in {\\cal F}\\) 인가?\n\\([1,3) \\cup (3,5] \\in {\\cal F}\\) 인가?\n\nnote: 시그마필드가 교집합, 차집합등에 닫혀있다는 성질은 증명없이 이용해도 무방함.\n(풀이) 1,2,3,4,5,6,7,8 모두 O.\n1. \\((-1,1) - \\big((-1,0)\\cup (0,1)\\big) \\in {\\cal F}\\)\n\n모든 열린구간은 \\({\\cal F}\\)의 원소이고, 열린구간의 합집합 역시 \\({\\cal F}\\)의 원소이므로 \\((-1,0) \\cup (0,1)\\) 역시 \\({\\cal F}\\)의 원소이다.\n\\(A=(-1,1)\\), \\(B=(-1,0)\\cup (0,1)\\) 이라고 하면, \\(A-B = \\{0\\}\\) 이고 시그마필드는 차집합에 닫혀있으므로 \\(A\\in {\\cal F}, B \\in {\\cal F}\\) 는 \\(A-B=\\{0\\} \\in {\\cal F}\\)를 imply한다.\n\n2. \\(\\Omega \\in {\\cal F}\\)\n\n시그마필드는 전체집합을 포함하므로 \\(\\mathbb{R}\\)은 \\({\\cal F}\\)의 원소이다.\n\n3. \\(\\forall x \\in \\mathbb{Q}, \\{x\\} \\in \\mathbb{Q} ~\\Rightarrow ~\\cup_{x \\in \\mathbb{Q}} \\{x\\} \\in {\\cal F}\\)\n\n1에 의하여 하나의 원소만 포함하는 모든 집합은 \\({\\cal F}\\)의 원소이다. 즉 모든 \\(x\\in \\mathbb{R}\\)에 대하여 \\(\\{x\\} \\in {\\cal F}\\) 이 성립한다.\n유리수전체의 집합은 \\(\\mathbb{Q}=\\cup_{x \\in \\mathbb{Q}} \\{x\\}\\) 와 같이 한점만 포함하는 집합들의 countable union으로 표현가능하고, 시그마필드는 countable union에 닫혀있으므로 \\(\\mathbb{Q} \\in {\\cal F}\\) 이다.\n\n4. \\(\\mathbb{Q} \\in {\\cal F} ~\\Rightarrow~ \\mathbb{Q}^c \\in {\\cal F}\\)\n\n무리수전체의 집합은 \\(\\mathbb{Q}^c = \\cup_{x \\in \\mathbb{Q}^c}\\{x\\}\\) 와 같이 한점만 포함하는 집합들의 uncountable union으로 표현되므로 3과 같은 방식으로는 증명할 수 없음.\n하지만 \\(\\mathbb{Q} \\in \\mathbb{R}\\)임을 3에서 보였고, 시그마필드는 여집합에 닫혀있으므로 \\(\\mathbb{Q}^c \\in \\mathbb{R}\\) 임을 보일 수 있다.\n\n5-8.\n\n모든 열린구간은 \\({\\cal F}\\)의 원소이며, 한점만 포함된 모든 집합 \\(\\{x\\}, x\\in\\mathbb{R}\\) 은 1과 유사한 논리로 \\({\\cal F}\\)의 원소임을 보일 수 있으므로 5-8은 모두 성립함.\n\n\n\n3. 확률과 확률변수\n(1) 아래와 같은 잴 수 있는 공간 \\((\\Omega, {\\cal F})\\)를 고려하자.\n\n\\(\\Omega=\\{a,b,c,d\\}\\)\n\\({\\cal F}=2^\\Omega\\)\n\n아래와 같은 확률변수 \\(X: \\Omega \\to \\{1,2,3,4\\}\\) 를 고려하자. 다음 중 올바른 표현은?\n\n\\(X(a)\\)\n\\(X(\\{a\\})\\)\n\\(P(a)\\)\n\\(P(\\{a\\})\\)\n\\(P(X=1)\\)\n\\(X = \\begin{cases} 1 & w.p.~\\frac{1}{2} \\\\ 2 & w.p. ~\\frac{1}{6} \\\\ 3 & w.p. ~\\frac{1}{6} \\\\ 4 & w.p. ~\\frac{1}{6} \\end{cases}\\)\n\n(풀이) 1,4,5,6\n(2) 두개의 잴 수 있는 공간 \\((\\Omega, {\\cal F})\\)와 \\((S,{\\cal S})\\)를 고려하자. 단,\n\n\\(\\Omega=\\mathbb{R}\\),\n\\({\\cal F} =\\sigma({\\cal A})\\) where \\({\\cal A} = \\{\\mathbb{Q}\\}\\),\n\\(S = \\{0,1\\}\\),\n\\({\\cal S} = 2^{S}\\).\n\n아래와 같은 함수 \\(X:\\Omega \\to S\\)을 고려하라.\n\\[X(\\omega) = \\begin{cases}\n0 & \\omega \\in \\mathbb{Q}\\\\\n1 & \\omega \\in \\mathbb{R} - \\mathbb{Q}\n\\end{cases}\\]\n\\(X\\)는 \\((\\Omega,{\\cal F})\\)에서의 확률변수인가? (즉 \\(X\\)는 \\((\\Omega,{\\cal F})\\to(S,{\\cal S})\\)인 가측함수인가?)\n(풀이) 확률변수임.\nNote: \\(\\sigma({\\cal A})=\\{\\emptyset, \\mathbb{Q}, \\mathbb{Q}^c, \\mathbb{R} \\}, 2^S = \\{\\emptyset, \\{0\\}, \\{1\\}, \\{0,1\\}\\}\\)\n확률변수임을 체크하기 위해서는 \\(2^S\\)의 모든 원소 \\(B\\)에 대하여 \\(X^{-1}(B):= \\{\\omega : X(\\omega) \\in B\\} \\in {\\cal F}\\) 임을 확인하면 된다.\n\n\\(B=\\emptyset\\) 일 경우: \\(\\{\\omega: X(\\omega) \\in \\emptyset\\}=\\emptyset \\in \\sigma({\\cal A})\\)\n\\(B=\\{0\\}\\) 일 경우: \\(\\{\\omega: X(\\omega) \\in \\{0\\}\\}=\\mathbb{Q} \\in \\sigma({\\cal A})\\)\n\\(B=\\{1\\}\\) 일 경우: \\(\\{\\omega: X(\\omega) \\in \\{1\\}\\}=\\mathbb{Q}^c \\in \\sigma({\\cal A})\\)\n\\(B=\\{0,1\\}\\) 일 경우: \\(\\{\\omega: X(\\omega) \\in \\{0,1\\}\\}=\\mathbb{R} \\in \\sigma({\\cal A})\\)\n\n(3) 두개의 잴 수 있는 공간 \\((\\Omega, {\\cal F})\\)와 \\((S,{\\cal S})\\)를 고려하자. 단,\n\n\\(\\Omega=\\mathbb{R}\\),\n\\({\\cal F} =\\sigma({\\cal A})\\) where \\({\\cal A} = \\{\\mathbb{Q}\\}\\),\n\\(S = \\{0,1\\}\\),\n\\({\\cal S} = 2^S\\).\n\n아래와 같은 함수 \\(X:\\Omega \\to S\\)을 고려하라.\n\\[X(\\omega) = \\begin{cases}\n0 & \\omega =0\\\\\n1 & \\omega \\neq 0\n\\end{cases}\\]\n\\(X\\)는 \\((\\Omega,{\\cal F})\\)에서의 확률변수인가? (즉 \\(X\\)는 \\((\\Omega,{\\cal F})\\to(S,{\\cal S})\\)인 가측함수인가?)\n(풀이) 확률변수가 아님. \\(B=\\{0\\}\\) 일 경우, \\(\\{\\omega: X(\\omega) \\in B\\}=\\{0\\} \\notin \\sigma({\\cal A})\\) 이므로 확률변수의 정의에 만족하지 않음."
  },
  {
    "objectID": "posts/2023-03-07-1wk-2.html",
    "href": "posts/2023-03-07-1wk-2.html",
    "title": "01wk-2: 강의소개",
    "section": "",
    "text": "수업구성\n1. 측도론(실변수함수론)\n\n확률과정을 이해함에 있어서 필요함.\n그런데 학부수준에서는 꼭 필요한 내용은 아님.\n대학원 진학 등 깊이 공부 할 학생들은 필요함.\n\n2. 확률과정론\n\n원래는 금융통계을 위한 백업과목\n여러가지 확률과정 중 우리는 마코프체인에만 집중\n\n3. 마코프체인의 응용 (유동적으로 변경가능)\n\n“마코프체인”이라는 용어가 나오는 응용분야를 리뷰.\nMCMC, 베이지안모형, 토픽모형(LDA), 강화학습, 구글페이지랭크 –> 몇 개만 다를 수 있지 않을까?\n\n\n\n이 수업을 들어야 하는 이유\npass\n\n\n이 수업을 듣지 말아야 하는 이유\n1. F학점 줄 수 있음.\n\n진짜 줌.\n\n2. 쓸모가 없다.\n\n그동안 제가 강의했던 과목들: R입문, 파이썬입문, 통계전산, 데이터시각화, 딥러닝(파이토치/텐서플로우),\n측도론: 재미는 있음. 그런데 대학원가서 고급이론을 공부할 것이 아니면 쓸모가 없다. (통계학과에서 배우는 가장 이론적인 과목)\n확률과정론: 확률과정론 \\(\\to\\) 금융공학으로 가는 교과과정은 학부수준에 다루기 어려움. 마코프체인은 응용이 많이 되는 편이지만 이론을 꼭 알아야 하는건 아니야.\n마코프체인의 응용: 꽤 재미있는 토픽들이 많음. 그런데 이 과목에서 깊게 다루기 불가능.\n\n3. 회귀분석2와 시간이 겹침\n\n이영미교수님 수업!\n회귀분석2는 엄청 중요한 수업이에요.\n지금이라도 늦지 않음"
  },
  {
    "objectID": "posts/2. 마코프체인/2023-04-27-9wk-1.html",
    "href": "posts/2. 마코프체인/2023-04-27-9wk-1.html",
    "title": "09wk-1: 마코프체인 (6)",
    "section": "",
    "text": "youtube: https://youtube.com/playlist?list=PLQqh36zP38-xbWjXgaQNqqqZDzuV1QsgL"
  },
  {
    "objectID": "posts/2. 마코프체인/2023-04-27-9wk-1.html#motivating-examples-cont",
    "href": "posts/2. 마코프체인/2023-04-27-9wk-1.html#motivating-examples-cont",
    "title": "09wk-1: 마코프체인 (6)",
    "section": "Motivating Examples (cont)",
    "text": "Motivating Examples (cont)\n\n예제3\n- 아래의 전이확률을 고려하자.\n\nP =np.array([0.0, 1.0, 0.0, 0.0, \n             1/2, 0.0, 1/2, 0.0,\n             0.0, 0.0, 0.0, 1.0,\n             0.0, 1.0, 0.0, 0.0]).reshape(4,4)\nP\n\narray([[0. , 1. , 0. , 0. ],\n       [0.5, 0. , 0.5, 0. ],\n       [0. , 0. , 0. , 1. ],\n       [0. , 1. , 0. , 0. ]])\n\n\n- 다이어그램\n\n\n\n\nflowchart LR\n  0 -->|1| 1\n  1 -->|1/2| 0\n  1 -->|1/2| 2\n  2 -->|1| 3\n  3 -->|1| 1\n\n\n\n\n\n\n\n\n- 특징1,2:\n\nnp.matrix(P)**500\n\nmatrix([[0.2, 0.4, 0.2, 0.2],\n        [0.2, 0.4, 0.2, 0.2],\n        [0.2, 0.4, 0.2, 0.2],\n        [0.2, 0.4, 0.2, 0.2]])\n\n\n- 특징3: 정상분포를 가짐\n- 특징4: 초기분포가 정상분포라면 정상확률과정\n- 특징5: irr\n- 특징6: 주기가 없음\n\n\n\n\nflowchart LR\n  0 -->|1| 1\n  1 -->|1/2| 0\n  1 -->|1/2| 2\n  2 -->|1| 3\n  3 -->|1| 1\n\n\n\n\n\n\n\n\n1에서 시작한다면?\n\n\\(1 \\to 0 \\to 1\\), 2번만에 리턴\n\\(1 \\to 2 \\to 3 \\to 1\\), 3번만에 리턴\n\n이 경우 2와 3의 최대공약수는 1이므로 주기는 1이다. 그리고 finite state space를 가지는 HMC는 모든 state가 항상 같은 주기를 가지므로 이 마코프체인의 모든 주기는 1이다.\n\n주기가 1인 경우는 aperiodic 하다고 표현한다. (언제 올지 몰라)\n\n\n꿀팁: 자기자신으로 1턴만에 되돌아올 확률이 있다면 항상 aperiodic 하다."
  },
  {
    "objectID": "posts/2. 마코프체인/2023-04-27-9wk-1.html#정의-및-이론",
    "href": "posts/2. 마코프체인/2023-04-27-9wk-1.html#정의-및-이론",
    "title": "09wk-1: 마코프체인 (6)",
    "section": "정의 및 이론",
    "text": "정의 및 이론\n- 정의:\n- 느낌: 상태 \\(i\\)에서 \\(i\\)로 되돌아오는 횟수들의 최대공약수를 HMC \\(\\{X_t\\}\\)의 period라고 하고, period=1인 경우를 aperiodic 이라고 한다.\n- 이론: \\(\\{X_t\\}\\)가 finte state HMC 이면, 모든 상태가 항상 같은 주기를 가진다."
  },
  {
    "objectID": "posts/2. 마코프체인/2023-04-27-9wk-1.html#정의-및-이론-1",
    "href": "posts/2. 마코프체인/2023-04-27-9wk-1.html#정의-및-이론-1",
    "title": "09wk-1: 마코프체인 (6)",
    "section": "정의 및 이론",
    "text": "정의 및 이론\n- Thm: HMC \\(\\{X_t\\}\\)가 (1) finite state space를 가지고 (2) irreduciable 하고 (3) aperiodic 이라면, \\({\\bf P}\\)가 수렴하고 수렴한 matrix의 모든 row는 같다. 따라서 임의의 초기분포 \\({\\boldsymbol \\mu}\\) 에 대하여\n\\[\\lim_{t\\to \\infty}{\\boldsymbol \\mu}^\\top{\\bf P}^t = {\\boldsymbol \\pi}^\\top \\]\n이 성립한다. 여기에서 \\({\\boldsymbol \\pi}\\)는 \\(\\{X_t\\}\\)의 정상분포이다.\n- 정의: 아래의 식을 만족하는 HMC \\(\\{X_t\\}\\)을 에르고딕하다고 말한다.\n\\[\\lim_{t\\to \\infty}{\\boldsymbol \\mu}^\\top{\\bf P}^t = {\\boldsymbol \\pi}^\\top \\]"
  },
  {
    "objectID": "posts/2. 마코프체인/2023-04-27-9wk-1.html#intro",
    "href": "posts/2. 마코프체인/2023-04-27-9wk-1.html#intro",
    "title": "09wk-1: 마코프체인 (6)",
    "section": "intro",
    "text": "intro\n- Google\n\nGoogle은 사용자의 검색어와 일치하는 검색 결과를 제공\nGoogle은 웹사이트들 사이에서 “더 나은” 또는 “더 중요한” 웹사이트가 검색 결과 상위에 나타나도록 순위를 유지\n이 순위는 전체 문제를 한 번에 해결하는 것이 아니라 먼저 전체적으로 수립되고(검색어와는 독립적으로), 그 후에 검색어와 일치하는 웹사이트들만 해당 순위에 따라 정렬된다고 함\n\n- 이 강의에서는 순위 매기기에 초점을 맞추어 생각해보자. (이는 마코프체인과 관련이 있음)\n\nref: https://en.wikipedia.org/wiki/PageRank\n\n- 페이지랭크\n\n페이지랭크(PageRank)는 구글 검색에서 웹 페이지의 순위를 결정하는 알고리즘으로 이는 “웹 페이지”와 구글 공동 창업자인 라리 페이지(Larry Page)의 이름을 따서 지어졌음\n페이지랭크는 웹사이트 페이지의 중요성을 측정하는 방법이며 기본적으로 더 중요한 웹사이일수록 다른 웹사이트에서 더 많은 링크를 받을 가능성이 높다는 점에 착안함\n페이지랭크는 구글이 검색 결과를 정렬하는 데 사용하는 유일한 알고리즘이 아니지만, 구글에서 사용한 최초의 알고리즘이며, 가장 잘 알려진 알고리즘임"
  },
  {
    "objectID": "posts/2. 마코프체인/2023-04-27-9wk-1.html#toy-example",
    "href": "posts/2. 마코프체인/2023-04-27-9wk-1.html#toy-example",
    "title": "09wk-1: 마코프체인 (6)",
    "section": "toy example",
    "text": "toy example\n- 아래는 7개의 website에 대한 web graph이다.\n\n\n\n\nflowchart LR\n  0 -->|1/2| 1\n  1 -->|1/2| 0\n  0 -->|1/2| 2\n  1 -->|1/2| 2\n  2 -->|1| 3 \n  4 -->|1| 3\n  3 -->|1| 5 \n  6 -->|1| 5\n\n\n\n\n\n\n\n\n- 여기에서 가장 중요한 웹사이트는 무엇일까?\n\n구글의 아이디어는 기본적으로 더 많은 화살표를 받는 쪽이 더 중요한 웹사이트이다 라는 것이었다.\n이 논리대로라면 노드 2,3,5가 똑같이 중요해보인다.\n좀 더 생각해보니까 노드2보다 노드3과 노드5가 더 중요해보인다. 왜냐하면 노드2는 확률 1/2 짜리 화살표 2개이지만 노드3과 노드5는 확률 1짜리 화살표가 2개임\n그렇지만 또 노드3보다는 노드5가 더 중요해보인다. 왜냐하면 노드3을 방문한 사람은 결국은 노드5로 갈테니까 노드3보다 노드5가 더 중요한 사이트라고 볼 수 있다.\n그럼 노드3의 중요도가 1일때 노드5의 중요도는 얼마정도 될까?\n\n- 구글의 아이디어: random surfer\n\n무작위로 웹사이트를 방문하는 가상의 유저를 만들자.\n그리고 이 유저가 많이 방문하게 되는 웹사이트를 기록하자.\n\n- 구글의 아이디어는 결국 위의 다이어그램을 토대로 transition matrix \\({\\bf P}\\)를 만들고 임의의 초기상태 \\({\\boldsymbol \\mu}\\)에 대하여\n\\[\\lim_{t\\to\\infty}{\\boldsymbol \\mu}^\\top{\\bf P}^{t}\\]\n를 계산하겠다는 의미이다.\n- 문제점1: 이 상황은 transition matrix를 만들 수 없는걸?\n\nP = np.array([0.0, 1/2, 1/2, 0.0, 0.0, 0.0, 0.0,\n              1/2, 0.0, 1/2, 0.0, 0.0, 0.0, 0.0,\n              0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0,\n              0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0,\n              0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0,\n              0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ### 이 부분은 다 0이다. \n              0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]).reshape(7,7)\nP\n\narray([[0. , 0.5, 0.5, 0. , 0. , 0. , 0. ],\n       [0.5, 0. , 0.5, 0. , 0. , 0. , 0. ],\n       [0. , 0. , 0. , 1. , 0. , 0. , 0. ],\n       [0. , 0. , 0. , 0. , 0. , 1. , 0. ],\n       [0. , 0. , 0. , 1. , 0. , 0. , 0. ],\n       [0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n       [0. , 0. , 0. , 0. , 0. , 1. , 0. ]])\n\n\n- 문제점1의 해결: 이러한 경우 상태5에서 다른상태로 갈 확률은 랜덤으로 다시 뿌린다.\n\nP = np.array([0.0, 1/2, 1/2, 0.0, 0.0, 0.0, 0.0,\n              1/2, 0.0, 1/2, 0.0, 0.0, 0.0, 0.0,\n              0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0,\n              0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0,\n              0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0,\n              1/7, 1/7, 1/7, 1/7, 1/7, 1/7, 1/7, ### 이렇게 고쳐버리자~\n              0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]).reshape(7,7)\nP\n\narray([[0.        , 0.5       , 0.5       , 0.        , 0.        ,\n        0.        , 0.        ],\n       [0.5       , 0.        , 0.5       , 0.        , 0.        ,\n        0.        , 0.        ],\n       [0.        , 0.        , 0.        , 1.        , 0.        ,\n        0.        , 0.        ],\n       [0.        , 0.        , 0.        , 0.        , 0.        ,\n        1.        , 0.        ],\n       [0.        , 0.        , 0.        , 1.        , 0.        ,\n        0.        , 0.        ],\n       [0.14285714, 0.14285714, 0.14285714, 0.14285714, 0.14285714,\n        0.14285714, 0.14285714],\n       [0.        , 0.        , 0.        , 0.        , 0.        ,\n        1.        , 0.        ]])\n\n\n- 문제점2: \\(\\lim_{t\\to\\infty}{\\boldsymbol \\mu}^\\top{\\bf P}^{t}\\)이게 수렴한다는 보장이 어디있지?"
  },
  {
    "objectID": "posts/2. 마코프체인/2023-04-27-9wk-1.html#수렴의-트릭",
    "href": "posts/2. 마코프체인/2023-04-27-9wk-1.html#수렴의-트릭",
    "title": "09wk-1: 마코프체인 (6)",
    "section": "수렴의 트릭",
    "text": "수렴의 트릭\n- 생각: HMC \\(\\{X_t\\}\\)가 에르고딕이려면 (1) finite state space를 가지고 (2) irreducible (3) aperiodic 해야한다.\n- 그런데 (N,N) 차원을 가지는 임의의 transition matrix \\({\\bf P}\\)를 아래와 같이 \\(\\tilde{\\bf P}\\)로 변형한다면 이 transition matrix는 aperiodic하고 irreducible하게 된다.\n\\[\\tilde{\\bf P} = 0.99 \\cdot {\\bf P} + 0.01 \\cdot \\frac{1}{N}{\\bf J}\\]\n여기에서 \\({\\bf J}\\)는 \\({\\bf P}\\)와 차원이 같고 모든 원소가 1인 매트릭스이다. 즉\n\\[{\\bf J} = \\begin{bmatrix} 1 & 1 & \\dots & 1 \\\\ 1 & 1 & \\dots & 1 \\\\ \\dots & \\dots & \\dots & \\dots \\\\ 1 & 1 & \\dots & 1 \\end{bmatrix}\\]\n이다.\n- 위의 수식에서 \\(\\tilde{\\bf P}\\)는 \\({\\bf P}\\)와 매우 비슷하지만 에르고딕한 마코프체인이다.\n- 이러한 \\(\\tilde{\\bf P}\\)를 구글매트릭스라고 부르자. 위의 식을 좀 더 간결하게 쓰면\n\\[{\\bf GoogleMatrix}:= \\alpha\\cdot {\\bf P} + (1-\\alpha)\\cdot\\frac{1}{N}{\\bf J}\\]\n와 같이 된다. 여기에서 \\(\\alpha \\in (0,1)\\) 이다.\n- 여기에서 \\(\\alpha\\)는 수렴의 속도를 결정한다.\n\n\\({\\bf P}\\)가 원래 수렴안하는 조건이었다면 \\(\\alpha \\approx 1\\) 일수록 구글매트릭스는 매우 느리게 수렴할 것이다.\n\\(\\alpha=0\\) 이라면 구글매트릭스는 이미 수렴되어 있다."
  },
  {
    "objectID": "posts/2. 마코프체인/2023-04-27-9wk-1.html#구현",
    "href": "posts/2. 마코프체인/2023-04-27-9wk-1.html#구현",
    "title": "09wk-1: 마코프체인 (6)",
    "section": "구현",
    "text": "구현\n\nP = np.array([0.0, 1/2, 1/2, 0.0, 0.0, 0.0, 0.0,\n              1/2, 0.0, 1/2, 0.0, 0.0, 0.0, 0.0,\n              0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0,\n              0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0,\n              0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0,\n              1/7, 1/7, 1/7, 1/7, 1/7, 1/7, 1/7,\n              0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]).reshape(7,7)\nP\n\narray([[0.        , 0.5       , 0.5       , 0.        , 0.        ,\n        0.        , 0.        ],\n       [0.5       , 0.        , 0.5       , 0.        , 0.        ,\n        0.        , 0.        ],\n       [0.        , 0.        , 0.        , 1.        , 0.        ,\n        0.        , 0.        ],\n       [0.        , 0.        , 0.        , 0.        , 0.        ,\n        1.        , 0.        ],\n       [0.        , 0.        , 0.        , 1.        , 0.        ,\n        0.        , 0.        ],\n       [0.14285714, 0.14285714, 0.14285714, 0.14285714, 0.14285714,\n        0.14285714, 0.14285714],\n       [0.        , 0.        , 0.        , 0.        , 0.        ,\n        1.        , 0.        ]])\n\n\n\nalpha= 0.85 \nJ = np.ones(49).reshape(7,7)\nGoogleMatrix = alpha*P + (1-alpha)/7 \n\n\nnp.linalg.matrix_power(GoogleMatrix,100)[0].round(3).tolist()\n\n[0.102, 0.102, 0.145, 0.231, 0.058, 0.304, 0.058]\n\n\n\nimport pandas as pd \npd.DataFrame({'website':['state'+i for i in '0123456'], \n             'pagerank': np.linalg.matrix_power(GoogleMatrix,100)[0].round(3).tolist()})\n\n\n\n\n\n  \n    \n      \n      website\n      pagerank\n    \n  \n  \n    \n      0\n      state0\n      0.102\n    \n    \n      1\n      state1\n      0.102\n    \n    \n      2\n      state2\n      0.145\n    \n    \n      3\n      state3\n      0.231\n    \n    \n      4\n      state4\n      0.058\n    \n    \n      5\n      state5\n      0.304\n    \n    \n      6\n      state6\n      0.058"
  },
  {
    "objectID": "posts/2. 마코프체인/2023-04-27-9wk-1.html#다른풀이",
    "href": "posts/2. 마코프체인/2023-04-27-9wk-1.html#다른풀이",
    "title": "09wk-1: 마코프체인 (6)",
    "section": "다른풀이",
    "text": "다른풀이\n\n_, eigen_vector_matrix = np.linalg.eig(GoogleMatrix.T)\n\n\nabs(eigen_vector_matrix[:,0])/ abs(eigen_vector_matrix[:,0]).sum()\n\narray([0.10154862, 0.10154862, 0.14470678, 0.2310231 , 0.05839045,\n       0.30439198, 0.05839045])"
  },
  {
    "objectID": "posts/2. 마코프체인/2023-04-27-9wk-1.html#페이지랭크의-약점",
    "href": "posts/2. 마코프체인/2023-04-27-9wk-1.html#페이지랭크의-약점",
    "title": "09wk-1: 마코프체인 (6)",
    "section": "페이지랭크의 약점",
    "text": "페이지랭크의 약점\n- 아래와 같은 상황을 고려하자.\n\n\n\n\nflowchart LR\n  0 -->|1/2| 1\n  1 -->|1/2| 0\n  0 -->|1/2| 2\n  1 -->|1/2| 2\n  2 -->|1| 3 \n  4 -->|1| 3\n\n\n\n\n\n\n\n\n\nP = np.arrfffq/5, 1/5,\n              0.0, 0.0, 0.0, 1.0, 0.0]).reshape(5,5)\nP\n\narray([[0. , 0.5, 0.5, 0. , 0. ],\n       [0.5, 0. , 0.5, 0. , 0. ],\n       [0. , 0. , 0. , 1. , 0. ],\n       [0.2, 0.2, 0.2, 0.2, 0.2],\n       [0. , 0. , 0. , 1. , 0. ]])\n\n\n\nGoogleMatrix = P*0.85 + 0.15/5 \n\n\nnp.linalg.matrix_power(GoogleMatrix,100)\n\narray([[0.15936255, 0.15936255, 0.22709163, 0.3625498 , 0.09163347],\n       [0.15936255, 0.15936255, 0.22709163, 0.3625498 , 0.09163347],\n       [0.15936255, 0.15936255, 0.22709163, 0.3625498 , 0.09163347],\n       [0.15936255, 0.15936255, 0.22709163, 0.3625498 , 0.09163347],\n       [0.15936255, 0.15936255, 0.22709163, 0.3625498 , 0.09163347]])\n\n\n- 우리는 여기에서 1번네트워크의 page rank를 올리고 싶다고 가정하자. (현재는 5개중 0.15936255)\n\n\n\n\nflowchart LR\n  0 -->|1/2| 1\n  1 -->|1/2| 0\n  0 -->|1/2| 2\n  1 -->|1/2| 2\n  2 -->|1| 3 \n  4 -->|1| 3\n\n\n\n\n\n\n\n\nStep1: 먼저 1번에서 다른쪽으로 가는 모든 링크를 끊는다. (다른 웹사이트의 page rank를 올려줄 이유가 없음)\n\n\n\n\nflowchart LR\n  0 -->|1/2| 1\n  0 -->|1/2| 2\n  2 -->|1| 3 \n  4 -->|1| 3\n\n\n\n\n\n\n\n\n\nP = np.array([0.0, 1/2, 1/2, 0.0, 0.0,\n              1/5, 1/5, 1/5, 1/5, 1/5,\n              0.0, 0.0, 0.0, 1.0, 0.0,\n              1/5, 1/5, 1/5, 1/5, 1/5,\n              0.0, 0.0, 0.0, 1.0, 0.0]).reshape(5,5)\n\n\nGoogleMatrix = P*0.85 + 0.15/5 \nnp.linalg.matrix_power(GoogleMatrix,100)\n\narray([[0.12640228, 0.18012324, 0.18012324, 0.38694897, 0.12640228],\n       [0.12640228, 0.18012324, 0.18012324, 0.38694897, 0.12640228],\n       [0.12640228, 0.18012324, 0.18012324, 0.38694897, 0.12640228],\n       [0.12640228, 0.18012324, 0.18012324, 0.38694897, 0.12640228],\n       [0.12640228, 0.18012324, 0.18012324, 0.38694897, 0.12640228]])\n\n\nStep2: 3개의 더미사이트 5,6,7을 만들어서 1번네트워크와 서로 연결시킨다.\n\n\n\n\nflowchart LR\n  0 -->|1/2| 1\n  0 -->|1/2| 2\n  2 -->|1| 3 \n  4 -->|1| 3\n  1 -->|1/3| 5\n  5 -->|1| 1\n  1 -->|1/3| 6\n  6 -->|1| 1\n  1 -->|1/3| 7 \n  7 -->|1| 1 \n\n\n\n\n\n\n\n\n\nP = np.array([0.0, 1/2, 1/2, 0.0, 0.0, 0.0, 0.0, 0.0,\n              0.0, 0.0, 0.0, 0.0, 0.0, 1/3, 1/3, 1/3,\n              0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0,\n              1/8, 1/8, 1/8, 1/8, 1/8, 1/8, 1/8, 1/8,\n              0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0,\n              0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n              0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n              0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]).reshape(8,8)\n\n\nGoogleMatrix = P*0.85 + 0.15/8\npagerank =np.linalg.matrix_power(GoogleMatrix,100)[0]\npagerank\n\narray([0.02778839, 0.39804992, 0.03959846, 0.08506721, 0.02778839,\n       0.14056921, 0.14056921, 0.14056921])\n\n\n\nwebsite = ['state'+i for i in '01234567']\nwebsite\n\n['state0',\n 'state1',\n 'state2',\n 'state3',\n 'state4',\n 'state5',\n 'state6',\n 'state7']\n\n\n\npd.DataFrame({'pagerank':pagerank,'website':website})\n\n\n\n\n\n  \n    \n      \n      pagerank\n      website\n    \n  \n  \n    \n      0\n      0.027788\n      state0\n    \n    \n      1\n      0.398050\n      state1\n    \n    \n      2\n      0.039598\n      state2\n    \n    \n      3\n      0.085067\n      state3\n    \n    \n      4\n      0.027788\n      state4\n    \n    \n      5\n      0.140569\n      state5\n    \n    \n      6\n      0.140569\n      state6\n    \n    \n      7\n      0.140569\n      state7\n    \n  \n\n\n\n\n- 약점을 극복한 구글의 아이디어: 저도 몰라용.."
  },
  {
    "objectID": "posts/2. 마코프체인/2023-04-13-7wk-2.html",
    "href": "posts/2. 마코프체인/2023-04-13-7wk-2.html",
    "title": "07wk-2: 마코프체인 (3)",
    "section": "",
    "text": "youtube: https://youtube.com/playlist?list=PLQqh36zP38-zAMowm9anbqZG0fCAmFI_1"
  },
  {
    "objectID": "posts/2. 마코프체인/2023-04-13-7wk-2.html#formular",
    "href": "posts/2. 마코프체인/2023-04-13-7wk-2.html#formular",
    "title": "07wk-2: 마코프체인 (3)",
    "section": "formular",
    "text": "formular\n- 저번시간에 살펴본 날씨모형은 결국 아래와 같은 모형이었다.\n\\[\\begin{bmatrix}\nP(X_{t+1}=0) \\\\\nP(X_{t+1}=1)\n\\end{bmatrix}= \\begin{bmatrix} 0.8 & 0.1 \\\\ 0.2 & 0.9 \\end{bmatrix} \\begin{bmatrix}\nP(X_{t}=0) \\\\\nP(X_{t}=1)\n\\end{bmatrix}\\]\n양변에 트랜스포즈를 취하게 되면\n\\[\\begin{bmatrix}\nP(X_{t+1}=0) &\nP(X_{t+1}=1)\n\\end{bmatrix}= \\begin{bmatrix}\nP(X_{t}=0) &\nP(X_{t}=1)\n\\end{bmatrix}\\begin{bmatrix} 0.8 & 0.2 \\\\ 0.1 & 0.9 \\end{bmatrix} \\]\n수식화하면 아래와 같이 된다. (보통 이러한 형태로 책에 많이 쓰니까 이 형태로 외울것!)\n\\[{\\boldsymbol \\mu}_{t+1}^\\top ={\\boldsymbol \\mu}_{t}^\\top {\\bf P}\\]\n\n참고: \\(X_t\\)는 0 혹은 1의 값을 가질수 있는데, 이렇게 \\(X_t\\)가 가질 수 있는 값들을 모은 공간을 상태공간이라고 하고 기호로는 \\(V=\\{0,1\\}\\)와 같이 표현한다.\n\n\n참고: 여기에서 확률과정 \\(\\{X_t\\}\\)는 이전시점의 값 \\(X_{t-1}\\)에 의하여서만 결정된다. 이러한 확률과정을 마코프체인이라고 한다.\n\n\n참고: 이때 매트릭스 \\({\\bf P}\\)를 transition matrix 라고 한다.\n\n- \\({\\bf P}\\)의 의미 (\\(\\star\\))\n\\({\\bf P}\\)의 각 원소를 아래와 같이 두자.\n\n\\({\\bf P} = \\begin{bmatrix} p_{00} & p_{01} \\\\ p_{10} & p_{11} \\end{bmatrix}\\)\n\n\\({\\bf P}\\)의 \\((i,j)\\)의 원소는 \\(i \\to j\\)로 이동할 확률을 의미한다. 즉 \\(p_{00}\\), \\(p_{01}\\), \\(p_{10}\\), \\(p_{11}\\) 은 각각 아래를 의미한다.\n\n\\(p_{00}\\): \\(0 \\to 0\\)일 확률. 즉 \\(P(X_t = 0 | X_{t-1} = 0)\\)\n\\(p_{01}\\): \\(0 \\to 1\\)일 확률. 즉 \\(P(X_t = 1 | X_{t-1} = 0)\\)\n\\(p_{10}\\): \\(1 \\to 0\\)일 확률. 즉 \\(P(X_t = 0 | X_{t-1} = 1)\\)\n\\(p_{11}\\): \\(1 \\to 1\\)일 확률. 즉 \\(P(X_t = 1 | X_{t-1} = 1)\\)\n\n- \\({\\boldsymbol \\mu}\\)의 의미 (\\(\\star\\))\n\n\\({\\boldsymbol \\mu}_t\\)는 \\(X_t\\)의 pmf를 의미한다.\n\\({\\boldsymbol \\mu}_0\\)는 \\(X_0\\)의 pmf를 의미한다. 즉 초기분포를 의미한다.\n\\({\\boldsymbol \\mu}\\)자체가 어떠한 분포를 의미한다."
  },
  {
    "objectID": "posts/2. 마코프체인/2023-04-13-7wk-2.html#특징들",
    "href": "posts/2. 마코프체인/2023-04-13-7wk-2.html#특징들",
    "title": "07wk-2: 마코프체인 (3)",
    "section": "특징들",
    "text": "특징들\n- 특징1: \\({\\bf P}\\)는 수렴한다. 즉 \\({\\bf P}^{\\infty}\\)가 존재한다.\n\nP = np.array([[0.8, 0.2],[0.1, 0.9]])\nP\n\narray([[0.8, 0.2],\n       [0.1, 0.9]])\n\n\n\nnp.linalg.matrix_power(P,1),np.linalg.matrix_power(P,10),np.linalg.matrix_power(P,30),np.linalg.matrix_power(P,50)\n\n(array([[0.8, 0.2],\n        [0.1, 0.9]]),\n array([[0.35216502, 0.64783498],\n        [0.32391749, 0.67608251]]),\n array([[0.33334836, 0.66665164],\n        [0.33332582, 0.66667418]]),\n array([[0.33333335, 0.66666665],\n        [0.33333333, 0.66666667]]))\n\n\n\nPlim = np.linalg.matrix_power(P,100)\n\n- 특징2: \\({\\bf P}^{\\infty}\\)의 each column은 모두 동일한 값을 가진다. \\(\\Rightarrow\\) \\(\\mu\\)에 어떠한 값을 넣어도 \\({\\boldsymbol \\mu}^\\top{\\bf P}^{\\infty}={\\boldsymbol \\pi}^\\top = [1/3, 2/3]\\) \\(\\Rightarrow\\) \\({\\bf P}\\)의 아무 row 나 선택하여 그것을 \\({\\boldsymbol \\pi}^\\top\\)라고 두자. \\({\\boldsymbol \\pi}\\)는 \\(X_{\\infty}\\)의 pmf가 된다.\n\nμ = np.array([[0.5],[0.5]]) \nμ.T @ Plim\n\narray([[0.33333333, 0.66666667]])\n\n\n\nπ = np.array([1/3,2/3]).reshape(2,1)\nπ\n\narray([[0.33333333],\n       [0.66666667]])\n\n\n\n\\(X_{\\infty}=\\begin{cases} 0 & w.p.~ 1/3 \\\\ 1 & w.p.~ 2/3 \\end{cases}\\)\n\n\n참고: 여기에서 \\({\\boldsymbol \\pi}\\)를 확률과정 \\(\\{X_t\\}\\)의 정상분포 (stationary distribution) 라고 한다.\n\n- 특징3: \\({\\boldsymbol \\pi}^\\top {\\bf P} = {\\boldsymbol \\pi}^\\top\\) 가 성립한다.\n\n근데 이건 왜 이러지?\n\n\nπ.T @ P\n\narray([[0.33333333, 0.66666667]])\n\n\n당연히 다른 분포 \\({\\boldsymbol \\mu}\\)에 대하여서는 성립하지 않음\n\nμ = np.array([[0.5],[0.5]]) \nμ.T @ P\n\narray([[0.45, 0.55]])\n\n\n\n참고: 여기에서 수식 \\({\\boldsymbol \\pi}^\\top {\\bf P} = {\\boldsymbol \\pi}^\\top\\) 자체가 정상분포의 정의가 된다. 즉 마코프체인 \\(\\{X_t\\}\\)의 트랜지션 매트릭스가 \\({\\bf P}\\)일때, \\({\\boldsymbol \\pi}^\\top {\\bf P} = {\\boldsymbol \\pi}^\\top\\)를 만족하는 \\({\\boldsymbol \\pi}\\)가 존재한다면 \\({\\boldsymbol \\pi}\\)를 확률과정 \\(\\{X_t\\}\\)의 정상분포라고 한다.\n\n- 특징4: 초기분포 \\({\\boldsymbol \\mu}_0\\)를 \\({\\boldsymbol \\pi}\\)로 설정하면 \\(\\{X_t\\}\\)는 모든 \\(t\\)에 대하여 동일한 분포를 가진다. (독립은 아니다)\n\nπ # 초기분포: X0의 pmf \n\narray([[0.33333333],\n       [0.66666667]])\n\n\n\nX0 = np.random.rand() < 2/3\n# X0 = np.random.rand() > 0.52941176\n\n\narr = np.array([doctor_strange(np.random.rand() < 2/3) for i in range(4305)])\narr\n\narray([[False, False,  True, ...,  True,  True,  True],\n       [ True,  True,  True, ...,  True, False, False],\n       [ True,  True,  True, ...,  True,  True,  True],\n       ...,\n       [ True,  True,  True, ...,  True,  True,  True],\n       [ True,  True,  True, ..., False, False, False],\n       [False,  True, False, ..., False, False, False]])\n\n\n\nplt.plot(arr[0][-100:])\n\n\n\n\n\narr[:,0]*1\n\narray([0, 1, 1, ..., 1, 1, 0])\n\n\n\narr[:,-1].sum()\n\n2850\n\n\n\narr[:,0].sum()\n\n2840\n\n\n\nfig, ax = plt.subplots(3,3)\nax[0][0].hist(arr[:,0]*1,alpha=0.5);\nax[0][1].hist(arr[:,500]*1,alpha=0.5);\nax[0][2].hist(arr[:,1000]*1,alpha=0.5);\nax[1][0].hist(arr[:,1500]*1,alpha=0.5);\nax[1][1].hist(arr[:,2000]*1,alpha=0.5);\nax[1][2].hist(arr[:,2500]*1,alpha=0.5);\nax[2][0].hist(arr[:,3000]*1,alpha=0.5);\nax[2][1].hist(arr[:,3500]*1,alpha=0.5);\nax[2][2].hist(arr[:,4000]*1,alpha=0.5);\nfig.tight_layout()\n\n\n\n\n\nplt.hist(arr[0]*1)\n\n(array([3512.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n        6489.]),\n array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n <BarContainer object of 10 artists>)\n\n\n\n\n\n특징4의 변형: 초기분포가 \\({\\boldsymbol \\pi}\\)가 아니더라도 적당한 시점 \\(T_0\\) 이후에는 \\(\\{X_t\\}_{t\\geq T_0}\\)는 동일한분포를 가진다고 볼 수 있다.\n\n참고: 특징4는 후에 MCMC를 이해하는 중요한 예제가 된다."
  },
  {
    "objectID": "posts/2. 마코프체인/2023-04-13-7wk-2.html#특징3을-위한-약간의-해설",
    "href": "posts/2. 마코프체인/2023-04-13-7wk-2.html#특징3을-위한-약간의-해설",
    "title": "07wk-2: 마코프체인 (3)",
    "section": "특징3을 위한 약간의 해설",
    "text": "특징3을 위한 약간의 해설\n편의상 \\({\\bf P}^{\\star}={\\bf P}^{\\infty}\\) 라고 하자. 이미 살펴본 것 처럼\n\n\\({\\bf P}^\\star {\\bf P} = {\\bf P}^\\star\\)\n\n가 성립한다. 특징2에서 살펴본것 처럼 임의의 \\({\\boldsymbol \\mu}\\)에 대하여 \\({\\boldsymbol \\mu}^\\top {\\bf P}^{\\star} = {\\boldsymbol \\pi}^\\top\\) 가 항상 성립함을 확인할 수 있다. 이 수식을 살짝 변형하면\n\n\\({\\boldsymbol \\mu}^\\top {\\bf P}^{\\star} = {\\boldsymbol \\pi}^\\top\\)\n\\(\\Rightarrow ({\\boldsymbol \\mu}^\\top{\\bf P}^{\\star}){\\bf P} = {\\boldsymbol \\pi}^\\top\\)\n\\(\\Rightarrow {\\boldsymbol \\pi}^\\top{\\bf P} = {\\boldsymbol \\pi}^\\top\\)\n\n이다. 따라서 특징3이 유도된다."
  },
  {
    "objectID": "posts/2. 마코프체인/2023-03-30-5wk-1.html",
    "href": "posts/2. 마코프체인/2023-03-30-5wk-1.html",
    "title": "05wk-1: 마코프체인 (1)",
    "section": "",
    "text": "youtube: https://youtube.com/playlist?list=PLQqh36zP38-xlV_TS7zhmYyyYNKv8np4W"
  },
  {
    "objectID": "posts/2. 마코프체인/2023-03-30-5wk-1.html#확률변수의-평균",
    "href": "posts/2. 마코프체인/2023-03-30-5wk-1.html#확률변수의-평균",
    "title": "05wk-1: 마코프체인 (1)",
    "section": "확률변수의 평균",
    "text": "확률변수의 평균\n- 예제1: 동전을 던지는 예제\n\n\n\n\\(\\omega\\)\n\\(x=X(\\omega)\\)\n\\(P(X=x)\\)\n\n\n\n\n\\(\\omega_1\\)\n\\(0\\)\n\\(\\frac{1}{2}\\)\n\n\n\\(\\omega_2\\)\n\\(1\\)\n\\(\\frac{1}{2}\\)\n\n\n\n\\[\\therefore E(X)=\\sum_{x=0}^{1}x P(X=x) = \\big(0\\times \\frac{1}{2} + 1 \\times \\frac{1}{2} \\big)=\\frac{1}{2}(0+1)\\]\n- 예제2: 주사위를 던지는 예제\n\n\n\n\\(\\omega\\)\n\\(x=X(\\omega)\\)\n\\(P(X=x)\\)\n\n\n\n\n\\(\\omega_1\\)\n\\(1\\)\n\\(\\frac{1}{6}\\)\n\n\n\\(\\omega_2\\)\n\\(2\\)\n\\(\\frac{1}{6}\\)\n\n\n\\(\\omega_3\\)\n\\(3\\)\n\\(\\frac{1}{6}\\)\n\n\n\\(\\omega_4\\)\n\\(4\\)\n\\(\\frac{1}{6}\\)\n\n\n\\(\\omega_5\\)\n\\(5\\)\n\\(\\frac{1}{6}\\)\n\n\n\\(\\omega_6\\)\n\\(6\\)\n\\(\\frac{1}{6}\\)\n\n\n\n\\[\\therefore E(X)=\\sum_{x=1}^{6}xP(X=x)=\\frac{1}{6}(1+2+3+4+5+6)=3\\]"
  },
  {
    "objectID": "posts/2. 마코프체인/2023-03-30-5wk-1.html#확률벡터의-평균",
    "href": "posts/2. 마코프체인/2023-03-30-5wk-1.html#확률벡터의-평균",
    "title": "05wk-1: 마코프체인 (1)",
    "section": "확률벡터의 평균",
    "text": "확률벡터의 평균\n- 예제1: 동전을 2회 던지는 예제\n\n\n\n\n\n\n\n\n\\(\\omega\\)\n\\({\\boldsymbol x}={\\boldsymbol X}(\\omega)\\)\n\\(P({\\boldsymbol X}={\\boldsymbol x})\\)\n\n\n\n\n\\(\\omega_1\\)\n\\(\\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}\\)\n\\(\\frac{1}{4}\\)\n\n\n\\(\\omega_2\\)\n\\(\\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}\\)\n\\(\\frac{1}{4}\\)\n\n\n\\(\\omega_1\\)\n\\(\\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}\\)\n\\(\\frac{1}{4}\\)\n\n\n\\(\\omega_2\\)\n\\(\\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}\\)\n\\(\\frac{1}{4}\\)\n\n\n\n\\[\\therefore E({\\boldsymbol X})=\\frac{1}{4}\\left(\\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}+\\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}+\\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}+\\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}\\right)=\\begin{bmatrix} \\frac{1}{2} \\\\ \\frac{1}{2} \\end{bmatrix} = \\begin{bmatrix} E(X_1)\\\\ E(X_2) \\end{bmatrix}\\]\n\n\\(E(X_1)=E(X_2)\\)인 이유?? iid 이니까~\n\n- 예제2: 동전을 10회 던지는 예제\n\n\n\n\n\n\n\n\n\\(\\omega\\)\n\\({\\boldsymbol x}={\\boldsymbol X}(\\omega)\\)\n\\(P({\\boldsymbol X}={\\boldsymbol x})\\)\n\n\n\n\n\\(\\omega_1\\)\n\\([0,0,\\dots,0]^\\top\\)\n\\(\\frac{1}{2^{10}}\\)\n\n\n\\(\\omega_2\\)\n\\([0,0,\\dots,1]^\\top\\)\n\\(\\frac{1}{2^{10}}\\)\n\n\n\\(\\dots\\)\n\\(\\dots\\)\n\\(\\dots\\)\n\n\n\\(\\omega_{1024}\\)\n\\([1,1,\\dots,1]^\\top\\)\n\\(\\frac{1}{2^{10}}\\)\n\n\n\n\\[\\therefore E({\\boldsymbol X})=\\begin{bmatrix} \\frac{1}{2} \\\\ \\frac{1}{2} \\\\ \\dots \\\\ \\frac{1}{2} \\end{bmatrix} = \\begin{bmatrix} E(X_1)\\\\ E(X_2) \\\\ \\dots \\\\ E(X_{10}) \\end{bmatrix}\\]"
  },
  {
    "objectID": "posts/2. 마코프체인/2023-03-30-5wk-1.html#motivating-example",
    "href": "posts/2. 마코프체인/2023-03-30-5wk-1.html#motivating-example",
    "title": "05wk-1: 마코프체인 (1)",
    "section": "motivating example",
    "text": "motivating example\n- 예제1: 동전을 1000번 던지는 예제를 상상하자. 앞면이 나올 확률은 \\(p\\)이며 이 \\(p\\)는 0.5인지 모른다고 가정하자.\n\nimport numpy as np \n\n\nunknown_probability = np.random.rand()\n\n\nx = np.random.binomial(n=1,p=unknown_probability,size=1000) # X(ω) for some ω\nx\n\narray([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0,\n       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n       1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0,\n       1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n       1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1,\n       1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0,\n       1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n       1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1,\n       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1,\n       1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1,\n       1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1,\n       1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n       1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0,\n       1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0,\n       1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1,\n       1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1,\n       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1,\n       1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n       1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n       1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0,\n       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0,\n       1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n       1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1,\n       1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n       1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0,\n       0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1,\n       1, 1, 1, 0, 1, 1, 1, 0, 1, 1])\n\n\n\n이것은 적당한 \\(\\omega\\)에 맵핑되어있는 하나의 realization 이다.\n\n- 질문: unknown_probability는 얼마일까??\n\nnp.mean(x), unknown_probability\n\n(0.796, 0.7863482228867129)\n\n\n- 비판: 문제 이상하게 푼다?\n\n\n\n\n\n\n\n\n\\(\\omega\\)\n\\({\\boldsymbol x}={\\boldsymbol X}(\\omega)\\)\n\\(P({\\boldsymbol X}={\\boldsymbol x})\\)\n\n\n\n\n\\(\\omega_1\\)\n\\([0,0,\\dots,0]^\\top\\)\n\\(\\frac{1}{2^{1000}}\\)\n\n\n\\(\\omega_2\\)\n\\([0,0,\\dots,1]^\\top\\)\n\\(\\frac{1}{2^{1000}}\\)\n\n\n\\(\\dots\\)\n\\(\\dots\\)\n\\(\\dots\\)\n\n\n\\(\\omega_{2^{1000}}\\)\n\\([1,1,\\dots,1]^\\top\\)\n\\(\\frac{1}{2^{1000}}\\)\n\n\n\n\\[\\therefore E({\\boldsymbol X})= \\begin{bmatrix} E(X_1)\\\\ E(X_2) \\\\ \\dots \\\\ E(X_{1000}) \\end{bmatrix}\\]\n\n\\(E(X_{1000})=\\frac{1}{2^{1000}}\\big(\\text{대충 0 혹은 1이 있는 숫자들을 더한것}\\big)=p\\)\n\n\nx[-1] # 이게 하나의 X_{1000} 에 대한 하나의 실현치일 뿐임. \n\n1\n\n\n따라서 개념상으로는 아래와 같이 시뮬레이션하여 구하는게 옳음\n\nsample1 = np.random.binomial(n=1,p=unknown_probability,size=1000) \nsample2 = np.random.binomial(n=1,p=unknown_probability,size=1000) \nsample3 = np.random.binomial(n=1,p=unknown_probability,size=1000) \nsample4 = np.random.binomial(n=1,p=unknown_probability,size=1000) \nsample5 = np.random.binomial(n=1,p=unknown_probability,size=1000) \nsample6 = np.random.binomial(n=1,p=unknown_probability,size=1000) \nsample7 = np.random.binomial(n=1,p=unknown_probability,size=1000) \n\n\n(sample1[-1]+sample2[-1]+sample3[-1]+sample4[-1]+sample5[-1]+sample6[-1]+sample7[-1])/7\n\n0.8571428571428571\n\n\n\nunknown_probability\n\n0.7863482228867129\n\n\n좀 더 많이…\n\nsamples = np.stack([np.random.binomial(n=1,p=unknown_probability,size=1000) for i in range(43052)])\nsamples\n\narray([[1, 1, 1, ..., 1, 0, 1],\n       [1, 0, 1, ..., 0, 1, 1],\n       [1, 0, 0, ..., 1, 1, 1],\n       ...,\n       [1, 1, 1, ..., 1, 1, 0],\n       [0, 1, 0, ..., 1, 1, 1],\n       [1, 0, 1, ..., 1, 1, 1]])\n\n\n\nsamples.shape\n\n(43052, 1000)\n\n\n\nnp.mean(samples[:,-1]) # E(X_{1000})을 근사한것\n\n0.7862120226702592"
  },
  {
    "objectID": "posts/2. 마코프체인/2023-03-30-5wk-1.html#용어정리의-시간",
    "href": "posts/2. 마코프체인/2023-03-30-5wk-1.html#용어정리의-시간",
    "title": "05wk-1: 마코프체인 (1)",
    "section": "용어정리의 시간",
    "text": "용어정리의 시간\n- 확률변수열을 표현할 때 \\(i\\)대신 \\(t\\)로 바꾼다면?\n\n\\(X_1,X_2,X_3,\\dots, X_i, \\dots, X_n\\) \\(\\Rightarrow\\) \\(X_1,X_2,X_3\\dots,X_t,\\dots X_T\\)\n\\(E(X_i)\\) \\(\\Rightarrow\\) \\(E(X_t)\\)\n\\(\\frac{1}{n}\\sum_{i=1}^{n}X_i\\) \\(\\Rightarrow\\) \\(\\frac{1}{T}\\sum_{t=1}^{T}X_t\\)\n\n- 용어: \\(E(X_t)\\)를 앙상블평균 (ensemble average) 이라고 하고, \\(\\frac{1}{T}\\sum_{t=1}^{T}X_t\\)를 시간평균 (time average) 이라고 한다."
  },
  {
    "objectID": "posts/2. 마코프체인/2023-03-30-5wk-1.html#생각의-시간-1",
    "href": "posts/2. 마코프체인/2023-03-30-5wk-1.html#생각의-시간-1",
    "title": "05wk-1: 마코프체인 (1)",
    "section": "생각의 시간 (1)",
    "text": "생각의 시간 (1)\n- 원래 \\(E(X_{1000})\\)은 \\(\\frac{1}{T}\\sum_{t=1}^{T}X_t\\)와 같은 방식으로 근사계산할 수 없긴해. (말도 안되는 소리임..)\n- 예제1: 아래와 같은 확률변수열를 고려하자.\n\n\\(X_1 \\sim Ber(0.5)\\).\n\\(X_t= X_{t-1}\\) for \\(t=2,3,4,\\dots, 1000\\).\n\n\\(E(X_{1000})\\)을 구하여라. \\(E(X_{1000})\\)을 \\(\\frac{1}{T}\\sum_{t=1}^T X_t\\)와 같은 방식으로 근사할 수 있는가?\n(풀이)\n\\(E(X_{1000})=0.5\\)임. 하지만 \\(\\frac{1}{T}\\sum_{t=1}^{T}X_t\\)로 \\(E(X_{1000})\\)을 근사할 수 없음.\n시뮬1 – calculating time average of one-sample \\((x_1,\\dots,x_{1000})\\)\n\nx1 = np.random.binomial(n=1,p=0.5,size=1).item()\nx1\n\n0\n\n\n\none_sample = np.array([x1]*1000)\none_sample\n\narray([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n\n\n\nnp.mean(one_sample)\n\n0.0\n\n\n시뮬2 – approximating ensemble average with 43052 samples\n\nsamples = np.array([[np.random.binomial(n=1,p=0.5,size=1).item()] * 1000 for i in range(43052)])\nsamples \n\narray([[1, 1, 1, ..., 1, 1, 1],\n       [0, 0, 0, ..., 0, 0, 0],\n       [1, 1, 1, ..., 1, 1, 1],\n       ...,\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       [1, 1, 1, ..., 1, 1, 1]])\n\n\n\nnp.mean(samples[:,-1])\n\n0.5003251881445694\n\n\n- 하지만 사실 iid가정이 있다면 앙상블평균을 시간평균으로 추정해도 문제 없어.\n- 예제2: 서로 독립인 1000개의 확률변수를 \\(N(0,1)\\)에서 뽑는다고 하자.\n\n\\(X_t=\\epsilon_t \\overset{i.i.d.}{\\sim} N(0,1)\\)\n\n이때는 \\(E(X_{1000})\\)을 \\(\\frac{1}{T}\\sum_{t=1}^T X_t\\)와 같은 방식으로 근사할 수 있다.\n시뮬1 – calculating time average of one-sample \\((x_1,\\dots,x_{1000})\\)\n\none_sample = np.random.binomial(1,0.5,1000)\nnp.mean(one_sample)\n\n0.536\n\n\n시뮬2 – approximating ensemble average with 43052 samples\n\nnp.stack([np.random.binomial(1,0.5,1000) for i in range(43052)])[:,-1].mean()\n\n0.4999535445507758\n\n\n- 결론: 원래 time-average와 ensemble-average는 “전혀” 다른 개념이다. 그런데, 확률변수열이 iid일 경우는 time-average로 ensemble-average를 근사계산 할 수 있다.\n- 아래의 그림은 time-average와 ensemble-average의 차이를 파악하기 용이한 예제이다.\n\n\n\n그림1: Davidson (1994) 에서 발췌한 그림."
  },
  {
    "objectID": "posts/2. 마코프체인/2023-03-30-5wk-1.html#ar1",
    "href": "posts/2. 마코프체인/2023-03-30-5wk-1.html#ar1",
    "title": "05wk-1: 마코프체인 (1)",
    "section": "AR(1)",
    "text": "AR(1)\n- 예제3: \\(\\epsilon_t \\overset{i.i.d.}{\\sim} N(0,1)\\) 일 때, 아래와 같은 확률변수 열을 고려하자.\n\n\\(X_1=\\epsilon_1\\)\n\\(X_t=\\frac{7}{8}X_{t-1} + \\epsilon_t\\) for \\(t=2,3,\\dots,T\\)\n\n\neps = np.random.randn(1000)\nx = np.zeros(1000)\nx[0] = eps[0]\nfor t in range(1,1000):\n    x[t] = (7/8)*x[t-1] +eps[t]\n\n\nimport matplotlib.pyplot as plt \n\n\nplt.plot(x,'--o',alpha=0.5)\n\n\n\n\n이때 \\(E(X_{T})\\)을 \\(\\frac{1}{T}\\sum_{t=1}^T X_t\\)와 같은 방식으로 근사할 수 있을까?\n(풀이)\n우선 독립인지 아닌지 체크해보자.\ncheck: \\(X_t\\)와 \\(X_{t-1}\\)은 독립??\n\nplt.plot(x[:-1],x[1:],'o',alpha=0.2)\n\n\n\n\n\ncorr이 있음.. \\(\\Rightarrow\\) 독립아님 \\(\\Rightarrow\\) ensemble-average를 time-average로 근사할 수 없다??\n\n\n참고로 독립이라면~\n\nplt.plot(eps,'--o',alpha=0.5)\n\n\n\n\n\nplt.plot(eps[1:],eps[:-1],'o',alpha=0.2)\n\n\n\n\n\n시뮬1 – calculating time average of one-sample \\((x_1,\\dots,x_{T})\\)\n\ndef gen(T=1000):\n    eps = np.random.randn(T)\n    x = np.zeros(T)\n    x[0] = eps[0]\n    for t in range(1,T):\n        x[t] = (7/8)*x[t-1] +eps[t]\n    return x\n\n\none_sample = gen()\nnp.mean(one_sample)\n\n-0.04427929741501683\n\n\n시뮬2 – approximating ensemble average with 43052 samples\n\nsamples = np.stack([gen() for ω in range(43052)])\n\n\nnp.mean(samples[:,-1])\n\n-0.001607068412044872\n\n\n근사 되는 것 같은데..?"
  },
  {
    "objectID": "posts/2. 마코프체인/2023-03-30-5wk-1.html#생각의-시간-2",
    "href": "posts/2. 마코프체인/2023-03-30-5wk-1.html#생각의-시간-2",
    "title": "05wk-1: 마코프체인 (1)",
    "section": "생각의 시간 (2)",
    "text": "생각의 시간 (2)\n- 확률변수는 값이 랜덤으로 바뀌는 변수느낌이 아니라 \\(X: \\Omega \\to \\mathbb{R}\\) 인 잴 수 있는 함수임.\n- 확률벡터는 값이 랜덤으로 바뀌는 벡터느낌이 아니라 \\(X: \\Omega \\to \\mathbb{R}^d\\) 인 잴 수 있는 함수임.\n- 동전을 반복하여 던져서 관측한 아래와 같은 확률변수열(=확률벡터)\n\\[0,1,0,0,1,1,\\dots,1\\]\n은 어떠한 \\(\\omega \\in \\Omega\\)에 대응하는 하나의 realization \\({\\boldsymbol X}(\\omega)={\\boldsymbol x}\\) 임. (즉 one-sample임)\n- 그런데 확률변수열을 독립으로 얻었다면 이러한 one-sample을 쪼개서 마치 여러개의 샘플을 얻은것처럼 생각할 수 있으며 이때\n\\[E(X_T)\\approx \\frac{1}{T}\\sum_{t=1}^{T}X_t\\]\n와 같은 방식으로 근사할 수 있음.\n- 사실상 \\(E(X_1)=E(X_2)=\\dots=E(X_T) \\approx \\frac{1}{T}\\sum_{t=1}^{T}X_t\\) 이므로 (\\(\\because\\) iid) 결국 아직 관측되지 않은 미래시점 \\(T+1\\)의 값에 대해서도\n\\[E(X_{T+1}) \\approx \\frac{1}{T}\\sum_{t=1}^T X_t\\]\n라고 주장할 수 있음.\n- 이렇게 one-sample을 여러개의 조각으로 쪼개는 기법은 iid에서만 성립할 것 같음. 만약에 iid가정이 없다면 (시뮬2)와 같은 방식으로 여러샘플을 통하여 ensemble-average를 근사시켜야 함. 정리하면 아래와 같음.\n\none-sample만 관측가능, iid 조건 만족 \\(\\Rightarrow\\) 분석가능\n여러개의 sample 관측가능 , iid 조건 만족 \\(\\Rightarrow\\) 분석가능\none-sample만 관측가능, iid 조건 만족하지 않음 \\(\\Rightarrow\\) 분석불가능??\n여러개의 sample 관측가능 , iid 조건 만족하지 않음 \\(\\Rightarrow\\) 분석가능\n\n- 문제: 그런데 실제로 우리가 다루고 싶은 자료의 형태는 3의 경우가 많다.\n- 소망: 그래서 iid가 아니지만 마치 iid인것 처럼 one-sample을 가지고 분석하고 싶다.\n\n앞으로 해야 할 것: 독립인듯 독립아닌 독립같은 확률과정은 없을까?\n\n\n독립인듯 독립아닌 독립같은 확률과정\n\nfig, ax = plt.subplots(3,3,figsize=(10,10))\nax[0][0].plot(x[:-1],x[1:],'o',alpha=0.1)\nax[0][1].plot(x[:-2],x[2:],'o',alpha=0.1)\nax[0][2].plot(x[:-3],x[3:],'o',alpha=0.1)\nax[1][0].plot(x[:-4],x[4:],'o',alpha=0.1)\nax[1][1].plot(x[:-5],x[5:],'o',alpha=0.1)\nax[1][2].plot(x[:-6],x[6:],'o',alpha=0.1)\nax[2][0].plot(x[:-7],x[7:],'o',alpha=0.1)\nax[2][1].plot(x[:-8],x[8:],'o',alpha=0.1)\nax[2][2].plot(x[:-9],x[9:],'o',alpha=0.1)"
  },
  {
    "objectID": "posts/2. 마코프체인/2023-05-09-10wk-2.html",
    "href": "posts/2. 마코프체인/2023-05-09-10wk-2.html",
    "title": "10wk-2: 마코프체인 (7)",
    "section": "",
    "text": "youtube: https://youtube.com/playlist?list=PLQqh36zP38-yMXZ2TSGxoh-rIjn8vp6cV"
  },
  {
    "objectID": "posts/2. 마코프체인/2023-05-09-10wk-2.html#예제1-단위행렬",
    "href": "posts/2. 마코프체인/2023-05-09-10wk-2.html#예제1-단위행렬",
    "title": "10wk-2: 마코프체인 (7)",
    "section": "예제1: 단위행렬",
    "text": "예제1: 단위행렬\nHMC \\(\\{X_t\\}\\)의 전이행렬이 아래와 같다고 하자.\n\nP = np.array([[1,0],\n              [0,1]])\nP\n\narray([[1, 0],\n       [0, 1]])\n\n\n\\(\\{X_t\\}\\)는 유일한 정상분포를 가지는가? 가진다면 시간평균을 이용하여 정상분포를 근사하라.\n(풀이)\n이 경우는 IRR 조건이 만족되지 않으므로 유일한 정상분포가 존재하지 않음. 그래서 에르고딕정리를 이용할 수 없다."
  },
  {
    "objectID": "posts/2. 마코프체인/2023-05-09-10wk-2.html#예제2-순환이동",
    "href": "posts/2. 마코프체인/2023-05-09-10wk-2.html#예제2-순환이동",
    "title": "10wk-2: 마코프체인 (7)",
    "section": "예제2: 순환이동",
    "text": "예제2: 순환이동\nHMC \\(\\{X_t\\}\\)의 전이행렬이 아래와 같다고 하자.\n\nP = np.array([[0,1],\n              [1,0]])\nP\n\narray([[0, 1],\n       [1, 0]])\n\n\n\\(\\{X_t\\}\\)는 유일한 정상분포를 가지는가? 가진다면 시간평균을 이용하여 정상분포를 구하여라.\n(풀이)\n\\(\\{X_t\\}\\)는 finite and irreducible HMC 이므로 유일한 정상분포를 가진다. 시뮬레이션을 한다면\n\n\\(0,1,0,1,0,1,0, \\dots\\)\n\\(1,0,1,0,1,0,1, \\dots\\)\n\n중 하나의 열(array)이 관찰 될 것이고 두 경우 모두\n\n\\(\\big(\\frac{1}{T}\\sum_{t=0}^{T-1}I(X_t=0),\\frac{1}{T}\\sum_{t=0}^{T-1}I(X_t=1)\\big)=(\\hat{\\pi}_0,\\hat{\\pi}_1)\\approx (1/2,1/2)\\)\n\n와 같이 구할 수 있음"
  },
  {
    "objectID": "posts/2. 마코프체인/2023-05-09-10wk-2.html#예제3-비가-온다-안온다",
    "href": "posts/2. 마코프체인/2023-05-09-10wk-2.html#예제3-비가-온다-안온다",
    "title": "10wk-2: 마코프체인 (7)",
    "section": "예제3: 비가 온다, 안온다",
    "text": "예제3: 비가 온다, 안온다\nHMC \\(\\{X_t\\}\\)의 전이행렬이 아래와 같다고 하자.\n\nP = np.array([[0.4,0.6],\n              [0.7,0.3]])\nP\n\narray([[0.4, 0.6],\n       [0.7, 0.3]])\n\n\n\\(\\{X_t\\}\\)는 유일한 정상분포를 가지는가? 가진다면 시간평균을 이용하여 정상분포를 구하여라.\n(풀이) 이 강의노트의 풀이4\n\ndef rain(before):\n    if before == True: # 비가 왔음 \n        after = np.random.rand() < 0.3\n    else: # 비가 안왔음 \n        after = np.random.rand() < 0.6 \n    return after \n\n\ndef doctor_strange(today):\n    lst = [today]\n    for i in range(10000): \n        lst.append(rain(lst[i]))\n    return lst \n\n\nnp.mean(doctor_strange(True)[1:])\n\n0.4616"
  },
  {
    "objectID": "posts/2. 마코프체인/2023-04-25-8wk-2.html",
    "href": "posts/2. 마코프체인/2023-04-25-8wk-2.html",
    "title": "08wk-2: 마코프체인 (5)",
    "section": "",
    "text": "youtube: https://youtube.com/playlist?list=PLQqh36zP38-zHbA2xrF58wfGjzkhNzxnL"
  },
  {
    "objectID": "posts/2. 마코프체인/2023-04-25-8wk-2.html#motivating-examples",
    "href": "posts/2. 마코프체인/2023-04-25-8wk-2.html#motivating-examples",
    "title": "08wk-2: 마코프체인 (5)",
    "section": "Motivating Examples",
    "text": "Motivating Examples\n\n예제1\n- 아래의 전이확률을 고려하자.\n\nP =np.array([0.5, 0.5, 0.0, 0.0, \n             0.5, 0.5, 0.0, 0.0,\n             0.0, 0.0, 0.5, 0.5,\n             0.0, 0.0, 0.5, 0.5]).reshape(4,4)\nP\n\narray([[0.5, 0.5, 0. , 0. ],\n       [0.5, 0.5, 0. , 0. ],\n       [0. , 0. , 0.5, 0.5],\n       [0. , 0. , 0.5, 0.5]])\n\n\n- 특징1: \\({\\bf P}\\)는 수렴함\n\nP@P@P\n\narray([[0.5, 0.5, 0. , 0. ],\n       [0.5, 0.5, 0. , 0. ],\n       [0. , 0. , 0.5, 0.5],\n       [0. , 0. , 0.5, 0.5]])\n\n\n- 특징2: 모든 row가 같은건 아님\n- 특징3: 정상분포는 유일하게 존재하지 않음\n\nπ = np.array([1/4, 1/4, 1/4, 1/4]).reshape(4,1)\nπ\n\narray([[0.25],\n       [0.25],\n       [0.25],\n       [0.25]])\n\n\n\nπ.T @ P, π.T \n\n(array([[0.25, 0.25, 0.25, 0.25]]), array([[0.25, 0.25, 0.25, 0.25]]))\n\n\n\nπ = np.array([1/2, 1/2, 0, 0]).reshape(4,1)\nπ\n\narray([[0.5],\n       [0.5],\n       [0. ],\n       [0. ]])\n\n\n\nπ.T @ P, π.T \n\n(array([[0.5, 0.5, 0. , 0. ]]), array([[0.5, 0.5, 0. , 0. ]]))\n\n\n\nπ = np.array([1/6, 1/6, 2/6, 2/6]).reshape(4,1)\nπ\n\narray([[0.16666667],\n       [0.16666667],\n       [0.33333333],\n       [0.33333333]])\n\n\n\nπ.T @ P, π.T \n\n(array([[0.16666667, 0.16666667, 0.33333333, 0.33333333]]),\n array([[0.16666667, 0.16666667, 0.33333333, 0.33333333]]))\n\n\n- 특징4: 초기분포가 정상분포라면 정상확률과정\n- 특징5: 상태공간 \\(E\\) 에 equivalence class 가 2개 있는 느낌\n\n\n예제2\n- 아래의 전이확률을 고려하자.\n\nP =np.array([1/4, 1/4, 0.0, 1/2, \n             1/4, 1/4, 0.0, 1/2,\n             0.0, 0.0, 1.0, 0.0,\n             1/2, 1/4, 0.0, 1/4]).reshape(4,4)\nP\n\narray([[0.25, 0.25, 0.  , 0.5 ],\n       [0.25, 0.25, 0.  , 0.5 ],\n       [0.  , 0.  , 1.  , 0.  ],\n       [0.5 , 0.25, 0.  , 0.25]])\n\n\n- 특징1: \\({\\bf P}\\)는 수렴함\n\nnp.matrix(P)**500\n\nmatrix([[0.35, 0.25, 0.  , 0.4 ],\n        [0.35, 0.25, 0.  , 0.4 ],\n        [0.  , 0.  , 1.  , 0.  ],\n        [0.35, 0.25, 0.  , 0.4 ]])\n\n\n- 특징2: 모든 row가 같지는 않음\n- 특징3: 유일한 정상분포를 가지는건 아님\n\nc1 = 0.2 # 상태 0,1,3 \nc2 = 0.8 # 상태 2 \nπ = np.array([0.35*c1, 0.25*c1, 1.0*c2 ,0.4*c1]).reshape(4,1)\nπ\n\narray([[0.07],\n       [0.05],\n       [0.8 ],\n       [0.08]])\n\n\n\nπ.T @ P, π.T \n\n(array([[0.07, 0.05, 0.8 , 0.08]]), array([[0.07, 0.05, 0.8 , 0.08]]))\n\n\n- 특징4: 초기분포가 정상분포라면 정상확률과정\n- 특징5: 상태공간 \\(E\\)에 equivalence class 가 2개 있는 느낌"
  },
  {
    "objectID": "posts/2. 마코프체인/2023-04-25-8wk-2.html#정의-및-이론",
    "href": "posts/2. 마코프체인/2023-04-25-8wk-2.html#정의-및-이론",
    "title": "08wk-2: 마코프체인 (5)",
    "section": "정의 및 이론",
    "text": "정의 및 이론\n- 용어\n\nirreducible (기약) // reducible (비기약)\n(strongly) connected\n\n- 정의\n- 느낌\n\n연결되어있는 느낌. 즉 모든 \\(x,y \\in E\\)에 대하여 \\(x\\to \\cdots \\to y\\) 인 path 나 \\(y \\to \\cdots \\to x\\) 인 path 가 존재함\n겉도는 그룹이 없음 (상태공간 \\(E\\)에 단 하나의 equivalence class가 존재함)\n\n- Thm: HMC \\(\\{X_t\\}\\) 가 (1) finite state space 를 가지고 (2) irreducible 이라면 \\(\\{X_t\\}\\)의 유일한 정상분포 \\({\\boldsymbol \\pi}\\)가 존재하며 모든 state에 대한 확률은 양수이다."
  },
  {
    "objectID": "posts/2. 마코프체인/2023-04-25-8wk-2.html#motivating-examples-1",
    "href": "posts/2. 마코프체인/2023-04-25-8wk-2.html#motivating-examples-1",
    "title": "08wk-2: 마코프체인 (5)",
    "section": "Motivating Examples",
    "text": "Motivating Examples\n\n예제1\n- 아래와 같은 전이확률을 고려하자.\n\nP = np.array([0.0, 1.0, 0.0,\n              0.0, 0.0, 1.0,\n              1.0, 0.0, 0.0]).reshape(3,3)\nP\n\narray([[0., 1., 0.],\n       [0., 0., 1.],\n       [1., 0., 0.]])\n\n\n- 다이어그램\n\n\n\n\nflowchart LR\n  0 -->|1| 1\n  1 -->|1| 2\n  2 -->|1| 0\n\n\n\n\n\n\n\n\n- 특징1: \\({\\bf P}\\)는 수렴안함\n\nP@P@P\n\narray([[1., 0., 0.],\n       [0., 1., 0.],\n       [0., 0., 1.]])\n\n\n- 특징2:\n- 특징3: 정상분포는 유일하게 존재함.\n\nπ = np.array([1/3,1/3,1/3]).reshape(3,1)\nπ\n\narray([[0.33333333],\n       [0.33333333],\n       [0.33333333]])\n\n\n\nπ.T @ P, π.T\n\n(array([[0.33333333, 0.33333333, 0.33333333]]),\n array([[0.33333333, 0.33333333, 0.33333333]]))\n\n\n- 특징4: 초기분포가 정상분포라면 정상확률과정\n- 특징5: 상태공간 \\(E\\)에 equivalence class 가 1개\n- 특징6: 주기성을 가짐 (주기는 3)\n\n관찰: 어떠한 상태 \\(x \\in E\\) 에 있더라도 반드시 3번 안에는 원래 상태로 되돌아옴.\n\n\n\n예제2\n- 아래와 같은 전이확률을 고려하자.\n\nP = np.array([0.0, 1.0, 0.0, 0.0,\n              0.0, 0.0, 0.0, 1.0,\n              0.0, 1.0, 0.0, 0.0,\n              1/3, 0.0, 2/3, 0.0]).reshape(4,4)\nP\n\narray([[0.        , 1.        , 0.        , 0.        ],\n       [0.        , 0.        , 0.        , 1.        ],\n       [0.        , 1.        , 0.        , 0.        ],\n       [0.33333333, 0.        , 0.66666667, 0.        ]])\n\n\n- 다이어그램\n\n\n\n\nflowchart LR\n  0 -->|1| 1\n  1 -->|1| 3\n  2 -->|1| 1\n  3 -->|1/3| 0 \n  3 -->|2/3| 2\n\n\n\n\n\n\n\n\n- 특징1: \\({\\bf P}\\)는 수렴안함\n\nP@P@P@P\n\narray([[0.        , 1.        , 0.        , 0.        ],\n       [0.        , 0.        , 0.        , 1.        ],\n       [0.        , 1.        , 0.        , 0.        ],\n       [0.33333333, 0.        , 0.66666667, 0.        ]])\n\n\n- 특징2: Pass\n- 특징3: 정상분포는 유일하게 존재함.\n\nπ = (np.array([1,3,2,3])/9).reshape(4,1)\nπ\n\narray([[0.11111111],\n       [0.33333333],\n       [0.22222222],\n       [0.33333333]])\n\n\n\nπ.T @ P, π.T \n\n(array([[0.11111111, 0.33333333, 0.22222222, 0.33333333]]),\n array([[0.11111111, 0.33333333, 0.22222222, 0.33333333]]))\n\n\n어떻게 찾음?\n\neig_value, eig_vector_matrix = np.linalg.eig(P.T)\n\n\neig_value[2]\n\n(1.000000000000001+0j)\n\n\n\nπ = abs(eig_vector_matrix[:,2])\nπ = π/π.sum()\nπ\n\narray([0.11111111, 0.33333333, 0.22222222, 0.33333333])\n\n\n- 특징4: 초기분포가 정상분포라면 정상확률과정\n- 특징5: irr\n- 특징6: 주기성을 가짐 (주기는3)\n\n\n\n\nflowchart LR\n  0 -->|1| 1\n  1 -->|1| 3\n  2 -->|1| 1\n  3 -->|1/3| 0 \n  3 -->|2/3| 2\n\n\n\n\n\n\n\n\n0에서 시작한다면?\n\n\\(0 \\to 1 \\to 3 \\to 0\\)\n\\(0 \\to 1 \\to 3 \\to 2 \\to 1 \\to 3 \\to 0\\)\n\\(0 \\to 1 \\to 3 \\to 2 \\to 1 \\to 3 \\to 2 \\to \\cdots\\)\n\n\n3번만에 되돌아오거나, 6번만에 되돌아오거나, 9번만에 되돌아오거나 … \\(\\Rightarrow\\) 주기는 3 (3,6,9의 최대공약수는 3)\n\n1에서 시작한다면?\n\n\\(1 \\to 3 \\to 0 \\to 1\\)\n\\(1 \\to 3 \\to 2 \\to 1 \\to 3 \\to 0 \\to 1\\)\n\\(\\dots\\)\n\n2에서 시작한다면?\n3에서 시작한다면?\n\n꿀팁: HMC \\(\\{X_t\\}\\)가 irreducible 이라면 모든 \\(x \\in E\\) 는 같은 주기를 가진다."
  },
  {
    "objectID": "posts/2. 마코프체인/2023-04-20-8wk-1.html",
    "href": "posts/2. 마코프체인/2023-04-20-8wk-1.html",
    "title": "08wk-1: 마코프체인 (4)",
    "section": "",
    "text": "강의영상\n\nyoutube: https://youtube.com/playlist?list=PLQqh36zP38-yapWz131weSlgUlgS-0T98\n\n\n영상2는 추후 재촬영예정임\n\n\n\nimports\n\nimport numpy as np\n\n\n\nMarkovchain, Transition Matrix\n- 정의: 카운터블한 상태공간 \\(E\\)을 가지는 이산시간 확률과정 \\(\\{X_t\\}_{t\\geq 0}\\)을 고려하자. 아래가 성립한다면 확률과정 \\(\\{X_t\\}\\)을 마코프체인(Markov chain, MC)라고 한다.\n\n\\(\\forall t\\geq 0, \\forall i_0,i_1,\\dots,i_{n-1},i,j \\in E\\):\n\n\\[\\mathbb{P}(X_{t+1}=j | X_t=i, X_{t-1}=i_{t-1}, \\dots, X_0=i_0) = \\mathbb{P}(X_{t+1}=j|X_t=i)\\]\n만약에 \\(P(X_{t+1} =j | X_t=i)\\)가 모든 \\(t\\)에 대하여 일정하다면 \\(\\{X_t\\}\\)를 균질마코프체인1(homogeneous Markov chain, HMC) 라고 한다.\n- 정의: 아래의 수식을 마코프성질 (Markov property) 이라고 한다.\n\n\\(\\forall t\\geq 0, \\forall i_0,i_1,\\dots,i_{n-1},i,j \\in E\\):\n\n\\[\\mathbb{P}(X_{t+1}=j | X_t=i, X_{t-1}=i_{t-1}, \\dots, X_0=i_0) = \\mathbb{P}(X_{t+1}=j|X_t=i)\\]\n- 정의: 카운터블한 상태공간 \\(E\\)를 가지는 HMC \\(\\{X_t\\}_{t\\geq 0}\\)를 고려하자. 상태 \\(i\\)에서 상태 \\(j\\)로 바뀌는 조건부 확률\n\\[p_{ij}=\\mathbb{P}(X_{t+1}=j | X_t=0)\\]\n를 \\(\\{X_t\\}_{t\\geq 0}\\)의 전이확률(transition probability)라고 한다.\n- 전이확률의 특징: 이때 전이확률은 아래의 특징을 가진다.\n\n\\(p_{ij} \\geq 0\\)\n\n\\(\\sum_{j\\in E}p_{ij}=1\\)\n\n첫번째 식은 확률이 양수이어야 한다는 내용이고2 두번째 식은 임의의 시점에서 상태 \\(i\\)에 존재할 경우, 그 다음시점에서 상태집합 \\(V\\) 중 어딘가로는 이동해야한다는 의미이다.\n- 정의: 카운터블한 상태공간 \\(V\\)를 가지는 HMC \\(\\{X_t\\}_{t \\geq 0}\\)를 고려하자. \\(p_{ij}\\)를 \\(\\{X_t\\}_{t\\geq 0}\\)의 전이확률이라고 하자. \\((i,j)\\)-th 원소를 \\(p_{ij}\\)로 가지는 행렬 \\({\\bf P}\\)를 전이확률행렬 (transition probability matrix) 혹은 줄여서 전이행렬 (transition matrix) 이라고 한다.\n- 참고(\\(\\star\\)): 상태공간 \\(V\\)의 원소수가 무한일 수도 있으므로, 원래 \\({\\bf P}\\)를 행렬이라고 하기에는 무리가 있다. 하지만 행렬의 덧셈, 행렬의 곱셈과 같은 연산들은 일반적으로 잘 정의되므로 \\({\\bf P}\\)를 행렬로 생각할 수 있다. 이러한 \\({\\bf P}\\)는 row와 col이 무한대로 있다고 생각하면 된다.\n\n\\(|E|=\\infty\\) 인 경우 \\({\\bf P}\\)의 예시: \\({\\bf P}=\\begin{bmatrix} p_{00} & p_{01} & \\cdots \\\\ p_{10} & p_{11} & \\cdots \\\\ \\cdots & \\cdots & \\cdots \\end{bmatrix}\\)\n\n- 전이행렬의 특징: 모든 row의 합이 1이다.\n\n\\(\\sum_{j \\in E}p_{ij} = 1\\) 이어야 하므로\n\n\n\nDistribution, Distribution Function\n- 예제1: 동전예제\n선언1: \\((\\Omega, 2^{\\Omega}, \\mathbb{P})\\) 를 확률공간이라고 하자. 여기에서 확률 \\(\\mathbb{P}\\)은 아래와 같이 정의되는 set function 이다.\n\n\\(\\mathbb{P}(\\emptyset) = 0\\)\n\\(\\mathbb{P}(\\{H\\}) = 1/2\\)\n\\(\\mathbb{P}(\\{T\\}) = 1/2\\)\n\\(\\mathbb{P}(\\Omega) = 1\\)\n\n선언2: 확률변수 \\(X: (\\Omega, 2^\\Omega) \\to (V,2^V)\\)를 아래와 같이 선언하자. (단, \\(V=\\{0,1\\}\\))\n\n\\(X(H) = 0\\)\n\\(X(T) = 1\\)\n\n생각: 이제 \\(B \\in 2^V\\) 에 대하여 아래와 같은 표현들을 고려하자.\n\n표현1: \\(\\mathbb{P}(X \\in B)\\) // 고등학교 부터 쓰던 그 표현\n표현2: \\(\\mathbb{P}(\\{\\omega: X(\\omega) \\in B\\})\\) // 이번에 배운 표현, 표현1의 정확한 버전\n표현3: \\(\\mathbb{P}(X^{-1}(B))\\) // 표현2의 다른 버전, inverse image의 느낌이 확 살아 있음\n표현4: \\((\\mathbb{P} \\circ X^{-1})(B)\\) // 생각해보니까 이것도 가능함. \\(\\mathbb{P}\\), \\(X\\) 모두 함수였잖아?\n\n새로운 함수 \\(\\mu:= \\mathbb{P}\\circ X^{-1}\\)는 이 경우 어떻게 정의할 수 있을까?\n\n\\(\\mu(\\emptyset) = 0\\)\n\\(\\mu(\\{0\\}) = \\frac{1}{2}\\)\n\\(\\mu(\\{1\\}) = \\frac{1}{2}\\)\n\\(\\mu(\\{0,1\\}) = 1\\)\n\n표현1과 4만 모아서 살펴보면 아래와 같다.\n\n\\(\\mu(\\emptyset) = 0\\) \\(\\Leftrightarrow\\) \\(\\mathbb{P}(X \\notin \\{0,1\\})=0\\)\n\\(\\mu(\\{0\\}) = \\frac{1}{2}\\) \\(\\Leftrightarrow\\) \\(\\mathbb{P}(X=0)\\)\n\n\\(\\mu(\\{1\\}) = \\frac{1}{2}\\) \\(\\Leftrightarrow\\) \\(\\mathbb{P}(X=1\\})\\)\n\\(\\mu(\\{0,1\\}) = \\frac{1}{2}\\) \\(\\Leftrightarrow\\) \\(\\mathbb{P}(X\\in \\{0,1\\})\\) \\(\\Leftrightarrow\\) \\(\\mathbb{P}(X\\leq 1)\\)\n\n- 예제2: 동전예제(2)\n\\((V,2^V)\\) 대신에 \\((\\mathbb{R},{\\cal R})\\) 으로 바꾸어도 위의 동전예제는 잘 정의된다.\n선언1: \\((\\Omega, 2^{\\Omega}, \\mathbb{P})\\) 를 확률공간이라고 하자. 여기에서 확률 \\(\\mathbb{P}\\)은 아래와 같이 정의되는 set function 이다.\n\n\\(\\mathbb{P}(\\emptyset) = 0\\)\n\\(\\mathbb{P}(\\{H\\}) = 1/2\\)\n\\(\\mathbb{P}(\\{T\\}) = 1/2\\)\n\\(\\mathbb{P}(\\Omega) = 1\\)\n\n선언2: 확률변수 \\(X: (\\Omega, 2^\\Omega) \\to (\\mathbb{R},{\\cal R})\\)를 아래와 같이 선언하자.\n\n\\(X(H) = 0\\)\n\\(X(T) = 1\\)\n\n생각: 이제 \\(B \\in {\\cal R}\\) 에 대한 표현들. 편의상 \\(B=\\{b: b\\leq 0.5\\}\\) 라고 가정하자.\n\n표현1: \\(\\mathbb{P}(X \\in B)=\\mathbb{P}(X\\leq 0.5)=\\mathbb{P}(X=0)=\\frac{1}{2}\\)\n표현2: 생략\n표현3: 생략\n표현4: \\((\\mathbb{P} \\circ X^{-1})((-\\infty,0.5])\\)\n\n표현1과 4만 모아서 살펴보면 아래와 같다.\n\n\\(\\mu((-\\infty,x])\\) \\(\\Leftrightarrow\\) \\(\\mathbb{P}(X \\leq x)\\)\n\\(\\mu(A)\\) \\(\\Leftrightarrow\\) \\(\\mathbb{P}(X\\in A)\\)\n\n- 생각의 시간\n\\((\\Omega,{\\cal F}, \\mathbb{P})\\)가 확률공간이고 \\(X \\to \\mathbb{R}\\)이 확률변수라면, \\(\\mu\\)는 언제나 잘 정의된다.\n\n모든 \\(B \\in {\\cal R}\\)에 대하여 \\(X^{-1}(B)\\)가 시그마필드의 원소가 아닐 수 없다. (만약 그렇다면 \\(X\\)는 확률변수가 아닌걸?)\n모든 \\(B \\in {\\cal R}\\)에 대하여 \\(\\mathbb{P}(X^{-1}(B))\\)의 값을 모순되게 정의할 수 없다. (만약 그렇다면 \\((\\Omega, {\\cal F}, \\mathbb{P})\\)는 확률공간이 아닌걸?)\n\n결론: \\(\\mu\\)는 안전해!\n- \\(\\mu\\)도 메져의 조건을 만족한다.\n\n정의역이 시그마필드임\n\\(\\forall B \\in {\\cal R}:~ \\mu(B)\\geq 0\\).\n\\(\\forall B_1,B_2,\\dots \\in {\\cal R}\\) such that \\(B_1,B_2 \\dots\\) are disjoint: \\(\\sum_{i=1}^{n}\\mu(B_i) = \\mu(\\uplus_{i=1}^{\\infty}B_i)\\)\n\n- \\(\\mu\\)를 부르는 용어 (\\(\\star\\star\\star\\)): \\(X\\)를 확률공간 \\((\\Omega, {\\cal F}, \\mathbb{P})\\)에서 정의된 확률변수라고 하자. 이때 \\(X^{-1}\\circ \\mathbb{P}\\)로 정의가능한 함수 \\(\\mu: {\\cal R} \\to [0,1]\\) 를 \\(X\\)의 distribution 이라고 부른다.\n- \\(F(x)\\)의 정의: \\(X\\)를 확률공간 \\((\\Omega, {\\cal F}, \\mathbb{P})\\)에서 정의된 확률변수라고 하자. \\(F: \\mathbb{R} \\to [0,1]\\) 인 함수를 아래와 같이 정의하자.\n\\[F(x) = \\mu((-\\infty, x])\\]\n이러한 함수 \\(F\\)는 아래와 같이 표현할 수 있다.\n\\[F(x) = \\mathbb{P}(X \\leq x)\\]\n함수 \\(F\\)를 확률변수 \\(X\\)의 distribution function 이라고 한다.\n- 참고사항 (그냥 교양임, 시험에 안냄):\n\n\\(\\mu\\)가 언제나 잘 정의되므로 \\(F(x)\\)도 언제나 잘 정의된다.\n\\(F(x)\\)는 어떠한 성질들을 가진다. (비감소함수, 오른쪽연속 등..)\n\\(F(x)\\)는 \\(F(x)= F_c(x) + F_s(x) + F_d(x)\\) 와 같이 분해가능하다.\n\\(F(x)=F_c(x)\\)라면 \\(F(x)\\)는 연속형확률변수의 cdf가 된다. \\(F(x)=F_d(x)\\)라면, \\(F(x)\\)는 이산형확률변수의 cdf가 된다.\n\\(F(x)=F_c(x)+F_d(X)\\)라면 혼합형확률변수의 cdf가 된다.\n\\(F(x)=F_s(x)\\)인 경우는 pdf, pmf가 존재하지 않는다.\n\n- Borel sets (어떤 학생이 헷갈려해서.. 제가 헷갈리게 설명해서..)\n\n\\(\\Omega=\\mathbb{R}\\) 일때 \\(2^{\\mathbb{R}}\\) 역시 시그마필드임.\n따라서 적당한 메져가 존재하여 \\(2^\\mathbb{R}\\)의 모든 집합을 잴 수 있음. (모든 원소를 0으로 측정하는 메져라든가..)\n하지만 르벡메져는 \\(2^{\\mathbb{R}}\\)의 모든 원소를 잴 수 없음. 따라서 \\(2^{\\mathbb{R}}\\)의 모든 원소에서 확률을 정의하는 것이 불가능함.\n그러나 \\(\\Omega=\\mathbb{R}\\)일때 \\({\\cal R}\\)이라는 시그마필드는 모든 원소에서 확률을 정의할 수 있음.\n\\({\\cal R}\\)을 Borel sets 이라고 부름.\n\n- \\(\\mathbb{R}\\)을 포함하는 Borel sets 은 \\({\\cal B}(\\mathbb{R})\\)로 표현하기도 함. 즉 \\({\\cal R} = {\\cal B}(\\mathbb{R})\\) 이다.\n\n\nThe Stationary Distribution of an HMC\n- 정의: stationary distribution (정확한 버전)\n\\((E,{\\cal B}(E))\\)를 잴 수 있는 공간이라고 하고 \\(\\mu\\)를 \\((E,{\\cal B}(E))\\)에서의 distribution 이라고 하자. 만약에 아래식을 만족하면 \\(\\mu\\) 를 stationary distribution 이라고 한다.\n\\[\\mu p = \\mu\\]\n여기에서 \\(\\mu p(\\{x\\}):= \\sum_{y \\in E} \\mu(\\{y\\})p_{yx}\\) 를 의미한다.\n- 정의: stationary distribution (쉬운버전)\n아래식을 만족하는 distribution \\({\\boldsymbol \\mu}\\) 를 stationary distribution 이라고 한다.\n\\[{\\boldsymbol \\mu}^\\top{\\bf P} = {\\boldsymbol \\mu}^\\top\\]\n- 예시1: 아래와 같은 transition matrix를 고려하자.\n\nP = np.array([[0.2,0.8],\n              [0.3,0.7]])\nP\n\narray([[0.2, 0.8],\n       [0.3, 0.7]])\n\n\n수렴할까?\n\nnp.linalg.matrix_power(P,50)\n\narray([[0.27272727, 0.72727273],\n       [0.27272727, 0.72727273]])\n\n\n결과분석\n\n특징1: \\({\\bf P}^{\\star}\\)로 수렴한다.\n특징2: 수렴한 매트릭스를 세로로 읽으면 값이 같다. \\(\\Rightarrow\\) … \\(\\Rightarrow\\) \\({\\bf P}^{\\star}\\)의 아무 row나 가져오면 정상분포가 된다.\n특징3: \\({\\boldsymbol \\pi}^\\top {\\bf P} = {\\boldsymbol \\pi}^\\top\\) \\(\\Leftarrow\\) \\(({\\boldsymbol \\mu}^\\top{\\bf P}^\\star) {\\bf P} ={\\boldsymbol \\pi}^\\top\\)\n특징4: 초기분포에 \\({\\boldsymbol \\pi}^\\top\\)을 대입하면 \\(\\{X_t\\}\\)는 동일한 분포를 가진다.\n\n- 예시2: 아래와 같은 transition matrix를 고려하자.\n\nP = np.array([[0.4,0.6],\n              [0.9,0.1]])\nP\n\narray([[0.4, 0.6],\n       [0.9, 0.1]])\n\n\n수렴할까?\n\nnp.linalg.matrix_power(P,50)\n\narray([[0.6, 0.4],\n       [0.6, 0.4]])\n\n\n결과분석\n\n특징1: \\({\\bf P}^{\\star}\\)로 수렴한다.\n특징2: 수렴한 매트릭스를 세로로 읽으면 값이 같다. \\(\\Rightarrow\\) … \\(\\Rightarrow\\) \\({\\bf P}^{\\star}\\)의 아무 row나 가져오면 정상분포가 된다.\n특징3: \\({\\boldsymbol \\pi}^\\top {\\bf P} = {\\boldsymbol \\pi}^\\top\\) \\(\\Leftarrow\\) \\(({\\boldsymbol \\mu}^\\top{\\bf P}^\\star) {\\bf P} ={\\boldsymbol \\pi}^\\top\\)\n특징4: 초기분포에 \\({\\boldsymbol \\pi}^\\top\\)을 대입하면 \\(\\{X_t\\}\\)는 동일한 분포를 가진다.\n\n- 예시3: 어지간하면 다 수렴할 것 같으니까 아래와 같이 특이한 transition matrix를 고려하자.\n\nP = np.array([[1.0, 0.0],\n              [0.05,0.95]])\nP\n\narray([[1.  , 0.  ],\n       [0.05, 0.95]])\n\n\n\nnp.linalg.matrix_power(P,50)\n\narray([[1.        , 0.        ],\n       [0.92305502, 0.07694498]])\n\n\n수렴안하나?\n\nnp.linalg.matrix_power(P,100)\n\narray([[1.        , 0.        ],\n       [0.99407947, 0.00592053]])\n\n\n\nnp.linalg.matrix_power(P,500)\n\narray([[1.00000000e+00, 0.00000000e+00],\n       [1.00000000e+00, 7.27449156e-12]])\n\n\n결국에는 한다.\n결과분석\n\n특징1: \\({\\bf P}^{\\star}\\)로 수렴한다.\n특징2: 수렴한 매트릭스를 세로로 읽으면 값이 같다. \\(\\Rightarrow\\) … \\(\\Rightarrow\\) \\({\\bf P}^{\\star}\\)의 아무 row나 가져오면 정상분포가 된다.\n특징3: \\({\\boldsymbol \\pi}^\\top {\\bf P} = {\\boldsymbol \\pi}^\\top\\) \\(\\Leftarrow\\) \\(({\\boldsymbol \\mu}^\\top{\\bf P}^\\star) {\\bf P} ={\\boldsymbol \\pi}^\\top\\)\n특징4: 초기분포에 \\({\\boldsymbol \\pi}^\\top\\)을 대입하면 \\(\\{X_t\\}\\)는 동일한 분포를 가진다.\n\n- 공식 (쓸모없는): transition matrix 가 아래와 같은 (2,2)-matrix이라고 하자.\n\n\\({\\bf P} = \\begin{bmatrix} 1-a & a \\\\ b & 1-b \\end{bmatrix}\\)\n\n그러면 대응하는 정상확률분포는 아래와 같다.\n\n\\(\\pi_0= \\frac{b}{a+b}\\)\n\\(\\pi_1= \\frac{a}{a+b}\\)\n\n예시1의 경우를 이 공식에 넣으면\n\n0.3/(0.8+0.3),0.8/(0.8+0.3)\n\n(0.2727272727272727, 0.7272727272727273)\n\n\n예시2의 경우를 이 공식에 넣으면\n\n0.9/(0.6+0.9), 0.6/(0.6+0.9)\n\n(0.6, 0.39999999999999997)\n\n\n예시3의 경우를 이 공식에 넣으면\n\n0.05/(0+0.05) , 0/(0+0.05)\n\n(1.0, 0.0)\n\n\n- 예시4: \\(a+b=0\\) 이라면?\n\nP = np.array([[1.0, 0.0],\n              [0.0, 1.0]])\nP\n\narray([[1., 0.],\n       [0., 1.]])\n\n\n수렴은 할텐데..\n결과분석\n\n특징1: \\({\\bf P}^{\\star}\\)로 수렴한다.\n특징2: 수렴한 매트릭스를 세로로 읽으면 값이 다르다?\n특징3: 어?\n특징4: 어????? (이건 그냥 되는데?)\n\n특징3: 정상분포\n일단 모든 \\({\\boldsymbol \\mu}\\)에 대하여 아래가 성립하긴한다.\n\\[{\\boldsymbol \\mu}^\\top {\\bf P} =  {\\boldsymbol \\mu}^\\top\\]\n따라서 이 경우 모든 확률측도 \\({\\boldsymbol \\mu}\\)는 정상분포가 된다. 유일한 정상분포를 가지지 않는다!!\n특징4: 정상확률과정\n\\({\\bf P}= {\\bf I}\\) 이므로 당연히 \\(\\{X_t\\}\\)는 모든 \\(t\\geq 0\\)에 대하여 동일한 분포를 가진다.\n- 예시5 (\\(\\star\\star\\star\\))\n\nP = np.array([[0.0, 1.0],\n              [1.0, 0.0]])\nP\n\narray([[0., 1.],\n       [1., 0.]])\n\n\n\nP@P\n\narray([[1., 0.],\n       [0., 1.]])\n\n\n\nP@P@P\n\narray([[0., 1.],\n       [1., 0.]])\n\n\n결과분석\n\n특징1: 수렴을 안하는데?\n특징2:\n특징3:\n특징4:\n\n특징3: 정상분포\n만약에 \\({\\boldsymbol \\pi}=\\begin{bmatrix} 1/2 \\\\ 1/2 \\end{bmatrix}\\) 로 설정한다면 아래가 성립한다.\n\\[{\\boldsymbol \\pi}^\\top {\\bf P} =  {\\boldsymbol \\pi}^\\top\\]\n따라서 \\({\\boldsymbol \\pi}\\)는 정상분포가 된다.\n특징4: 정상확률과정\n만약에 \\({\\boldsymbol \\pi}=\\begin{bmatrix} 1/2 \\\\ 1/2 \\end{bmatrix}\\) 로 설정한다면 \\(\\{X_t\\}\\)는 모든 \\(t\\geq 0\\)에 대하여 동일한 분포를 가진다.\n- 생각의 시간\n\n\n\n\n특징1(수렴)\n특징2(동일row)\n특징3(정상분포)\n특징4(정상과정)\n\n\n\n\n예시1(나이스)\nO\nO\n존재O, 유일O\nO\n\n\n예시2(나이스)\nO\nO\n존재O, 유일O\nO\n\n\n예시3(흡수)\nO\nO\n존재O, 유일O\nO\n\n\n예시4(단위행렬)\nO\nX\n존재O, 유일X\nO\n\n\n예시5(주기)\nX\nNA\n존재O, 유일O\nO\n\n\n\n특징3에서 정상분포가 존재하면 특징4는 그냥 성립한다. 지금까지 살펴본 예제에서는 모두 정상분포가 존재했다. 혹시 정상분포가 존재하지 않을 수도 있을까?\n- Thm: finite state를 가지는 HMC는 정상분포가 최소한 1개는 존재한다.\n\n\n\n\n\nFootnotes\n\n\n진짜 억지로 변형한것, 마땅한 한글용어가 없음↩︎\n쓸모없는 내용↩︎"
  },
  {
    "objectID": "posts/2. 마코프체인/2023-05-11-11wk-1.html#약한조건-약한정리-강한조건-강한정리",
    "href": "posts/2. 마코프체인/2023-05-11-11wk-1.html#약한조건-약한정리-강한조건-강한정리",
    "title": "11wk-1: 마코프체인 (8)",
    "section": "약한조건, 약한정리, 강한조건, 강한정리",
    "text": "약한조건, 약한정리, 강한조건, 강한정리\n- 정리: 어떠한 조건을 만족하면, 어떠한 결론이 나온다.\n\n결론: 우리가 원하는 것.\n조건: 우리가 원하는 것을 얻기 위한 고난과정.\n\n- 결론이 동일하다면 조건이 약할 수록 유리하다.\n\n정리1: 수업에 온라인으로 참석하거나 오프라인으로 참석한다면 모두 출석으로 인정한다.\n정리2: 수업에 오프라인으로 참석할때만 출석으로 인정한다.\n\n\n정리2의 조건이 만족되면 정리1의 조건은 자동으로 만족된다. 따라서 정리2의 조건이 더 강한 조건이다. 조건이 강할수록 불리하므로 정리2가 더 불리하다.\n\n- 조건이 동일하다면 결론이 강한 쪽이 유리하다.\n\n정리1: 중간고사와 기말고사를 모두 응시한다면, B학점 이상이다.\n정리2: 중간고사와 기말고사를 모두 응시한다면, A학점 이상이다.\n\n\n정리2의 결론이 만족되면 정리1의 결론은 자동으로 만족되므로 정리2의 결론이 더 강하다. 결론은 강할수록 유리하므로 정리2가 더 유리하다."
  },
  {
    "objectID": "posts/2. 마코프체인/2023-05-11-11wk-1.html#헷갈리는-표현-infty의-포함",
    "href": "posts/2. 마코프체인/2023-05-11-11wk-1.html#헷갈리는-표현-infty의-포함",
    "title": "11wk-1: 마코프체인 (8)",
    "section": "헷갈리는 표현: \\(\\infty\\)의 포함",
    "text": "헷갈리는 표현: \\(\\infty\\)의 포함\n- 자연수집합 \\(\\mathbb{N}\\)은 \\(\\{\\infty\\}\\)를 포함하지 않는다. 마찬가지로 실수집합 \\(\\mathbb{R}\\) 역시 \\(\\{-\\infty\\}, \\{\\infty\\}\\)를 포함하지 않는다. 만약에 이를 포함하고 싶을 경우는 아래와 같이 표현한다.\n\n\\(\\mathbb{R} \\cup \\{-\\infty\\} \\cup \\{\\infty\\} = \\bar{\\mathbb{R}}\\)\n\\(\\mathbb{N} \\cup \\{-\\infty\\}\\)\n\n여기에서 \\(\\bar{\\mathbb{R}}\\)은 확장된 실수라고 부르는데 교재에따라 사용하기도 하고 사용하지 않기도 한다.\n- 만약에 \\(\\mathbb{N}\\)이 \\(\\{\\infty\\}\\)를 포함한다면\n\n\\(\\forall n \\in \\mathbb{N}:~ 0<\\frac{1}{n} \\leq 1\\)\n\n와 같은 표현은 불가능할 것이다.\n- 구간에 대한 표현들: 구간에 대한 몇가지 표현을 정리하면 아래와 같다.\n\n\\((-\\infty, b] = \\{x: x\\leq b, ~x,b \\in \\mathbb{R}\\}\\)\n\\((-\\infty, b) = \\{x: x < b,~ x,b \\in \\mathbb{R}\\}\\)"
  },
  {
    "objectID": "posts/2. 마코프체인/2023-05-11-11wk-1.html#이론의-정리",
    "href": "posts/2. 마코프체인/2023-05-11-11wk-1.html#이론의-정리",
    "title": "11wk-1: 마코프체인 (8)",
    "section": "이론의 정리",
    "text": "이론의 정리\n- \\(\\{X_t\\}\\)는 HMC 라고 하자.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCaseNO\n대표예제\nFINITE\nIRR(연결)\nAP(비주기)\n\\({\\bf P}\\)의 수렴\n극한분포유일존재\n정상분포존재\n정상분포유일\n에르고딕정리를 만족\n에르고딕\n\n\n\n\n1\n\nO\nX\nX\nX\nX\nO\nX\nX\nX\n\n\n2\n단위행렬\nO\nX\nO\nO\nX\nO\nX\nX\nX\n\n\n3\n순환이동\nO\nO\nX\nX\nX\nO\nO\nO\nX\n\n\n4\n나이스\nO\nO\nO\nO\nO\nO\nO\nO\nO\n\n\n\n- CaseNO==1 의 예제"
  },
  {
    "objectID": "posts/2. 마코프체인/2023-05-11-11wk-1.html#emprical-분포-정상분포-극한분포",
    "href": "posts/2. 마코프체인/2023-05-11-11wk-1.html#emprical-분포-정상분포-극한분포",
    "title": "11wk-1: 마코프체인 (8)",
    "section": "Emprical 분포, 정상분포, 극한분포",
    "text": "Emprical 분포, 정상분포, 극한분포\n- Emprical distribution, 정상분포, 극한분포\n\n\\(\\bar{\\boldsymbol \\pi}^\\top\\): 하나의 \\(\\omega\\)에 대한 확률변수열 \\(\\{X_t\\}\\)의 emprical distribution (time average로 분포를 추정)\n\\({\\boldsymbol \\pi}^\\top\\): 모든 \\(\\omega\\)를 고려하였을 경우 확률변수열 \\(\\{X_t\\}\\)의 정상분포.\n\\({\\bf p}_{\\star}^\\top\\): \\(\\omega\\)와 무관하게 \\({\\bf P}\\)의 극한으로 얻어지는 \\(\\{X_t\\}\\)의 극한분포. // 마코프체인에 특화\n\n- 표로 정리하면 아래와 같다.\n\n\n\n\n\n\n\n\n\n\nEmpirical 분포\n정상분포\n극한분포\n\n\n\n\n용어가 통용되는 범위\n모든 확률과정\n모든 확률과정\n마코프체인\n\n\n기호\n\\(\\bar{\\boldsymbol \\pi} = \\frac{1}{T}\\begin{bmatrix}{\\tt sum}(X_t==0) \\\\ {\\tt sum}(X_t==1)\\end{bmatrix}\\)\n\\({\\boldsymbol \\pi}=\\begin{bmatrix}\\mathbb{E}(I(X=0))\\\\ \\mathbb{E}(I(X=1)) \\end{bmatrix}\\)\n\\({\\bf p}_{\\star}= \\lim_{t\\to \\infty}\\begin{bmatrix}p_{?0}^{(t)} \\\\ p_{?1}^{(t)} \\end{bmatrix}\\)\n\n\n\\(\\omega\\)의 고려\n하나의 \\(\\omega\\)만 고려해 계산\n모든 \\(\\omega\\) 고려해 계산\n\\(\\omega\\)를 고려하지 않고 계산\n\n\n통계느낌(분포느낌?)\nO\nO\nX\n\n\n이론적인값?\nX\nO\nO\n\n\n데이터와 관련\nO\nX\nX\n\n\n극한과 관련\nO\nX\nO\n\n\nLLN과 관련\nO\nO\nX\n\n\n느낌\n데이터로 계산한 평균값\n이론적인 기대값\n이론적인 수렴값"
  },
  {
    "objectID": "posts/2. 마코프체인/2023-05-11-11wk-1.html#이론들의-의미를-다시-고찰",
    "href": "posts/2. 마코프체인/2023-05-11-11wk-1.html#이론들의-의미를-다시-고찰",
    "title": "11wk-1: 마코프체인 (8)",
    "section": "이론들의 의미를 다시 고찰",
    "text": "이론들의 의미를 다시 고찰\n- 에르고딕정리: 임피리컬분포와 정상분포에 관련한 정리 (LLN보다 더 약한 조건을 가짐)\n\n의미1: 에르고딕 정리를 만족하지 못하는 경우 하나의 확률변수열을 이용한 추론이 불가능\n\n\n## 예시\nP =np.array([[1,1,0,0],\n             [1,1,0,0],\n             [0,0,1,1],\n             [0,0,1,1]])/2\nP\n\narray([[0.5, 0.5, 0. , 0. ],\n       [0.5, 0.5, 0. , 0. ],\n       [0. , 0. , 0.5, 0.5],\n       [0. , 0. , 0.5, 0.5]])\n\n\n\n의미2: 에르고딕 정리를 만족하는 경우 \\(X_1,X_2,\\dots\\)이 동일한 분포를 가지지 않지만 무시하고 \\(\\pi\\)를 추정할 수있다.\n\n- 극한분포와 관련된 이론: 극한분포의 느낌은 초기값에 대한 삭제임\n\n극한분포는 어차피 \\(\\omega\\)를 신경안씀\n\\({\\boldsymbol \\mu}_0\\)는 아무상관이 없음\n결국 극한분포가 존재한다면 시간의존성이 삭제된다는 의미임"
  },
  {
    "objectID": "posts/2. 마코프체인/2023-05-11-11wk-1.html#스토리정리",
    "href": "posts/2. 마코프체인/2023-05-11-11wk-1.html#스토리정리",
    "title": "11wk-1: 마코프체인 (8)",
    "section": "스토리정리",
    "text": "스토리정리\n- FINITE HMC는 일단 정상분포라는게 존재함. 그런데 유일하지 않을 수 있음.\n- FINITE HMC는 크게보면 IRR인 케이스와 IRR 아닌 케이스로 나누어짐\n\n그런데 IRR이 아닌 케이스는 IRR인 케이스들의 조합으로 나누어 생각할 수 있음\n그래서 어차피 신경쓸 필요 없음.\n따라서 모든 마코프체인은 IRR이라고 가정해버려도 무방\n\n- 만약에 HMC가 (1) FINITE (2) IRR 이면 유일한 정상분포가 존재.\n\n심지어 이 조건에서는 에르고딕정리를 이용해서 임피리컬 분포로 정상분포를 estimate 할 수 있음.\n\n- 그러면 HMC가 (1) FINITE (2) IRR 이면 다 끝?\n\n언뜻 생각하면 그런거 같음.\n그런데 에르고딕 정리를 만족한다고 해서 초기분포에 대한 기억이 사라지는건 아님\n몇 가지 응용예제에서는 초기분포에 대한 의존성을 삭제시키는 것이 매우 중요함.\n이걸 위해서는 AP조건이 추가되어야 함.\n\n- HMC가 (1) FINITE (2) IRR (3) AP 라면 아주 좋음."
  },
  {
    "objectID": "posts/2. 마코프체인/2023-04-13-7wk-1.html",
    "href": "posts/2. 마코프체인/2023-04-13-7wk-1.html",
    "title": "07wk-1: 마코프체인 (2)",
    "section": "",
    "text": "강의영상\n\nyoutube: https://youtube.com/playlist?list=PLQqh36zP38-wi47mCKi03xoqvwIzkxG0H\n\n\n\nimport\n\nimport numpy as np\n\n\n\n확률과정\n- 동전을 무한히 던지는 시행을 생각하자. 동전을 10번 던져서 결과를 관찰했다고 하자. 동전을 30번째 던져서 앞면이 나올지 뒷면이 나올지 알고 싶다면?\n- 현재 삼성전자 주가는 66000이다. 20일뒤의 삼성전자 주가가 얼마일지 알고 싶다면?\n- 원래 미래를 예측하기 위해서 해야하는 과정\n\n\n\n그림1: 1400만개의 미래를 탐색중인 Doctor Strange\n\n\n- 하지만 현실적으로는 이게 너무 힘들지 않을까?\n\n\n날씨예측\n- 아래와 같이 세상의 법칙이 있다고 하자.\n\n어제 맑음 \\(\\to\\) 오늘도 맑음: 40% // 오늘은 비: 60%\n어제 비 \\(\\to\\) 오늘은 맑음: 70% // 오늘도 비 30%\n\n- 모든 \\(t\\)에 대하여 확률변수 \\(X_t\\)를 아래와 같이 정의하자.\n\n\\(X_t=\\begin{cases} 0 & \\text{맑음} \\\\ 1 & \\text{비} \\end{cases}\\)\n\n- 오늘 (2023년4월13일) 비가 왔다고 치자. 10000일 뒤에도 비가 올 확률은 얼마일까?\n\n\n풀이1\n- \\(X_t=0\\) 이라면? (\\(t\\)시점에 비가 오지 않았다면?)\n\nnp.random.rand() < 0.6 \n\nFalse\n\n\n- \\(X_t=1\\) 이라면? (\\(t\\)시점에 비가 왔다면?)\n\nnp.random.rand(0) < 0.3\n\narray([], dtype=bool)\n\n\n- 두 코드를 합쳐보자.\n\ndef rain(before):\n    if before == True: # 비가 왔음 \n        after = np.random.rand() < 0.3\n    else: # 비가 안왔음 \n        after = np.random.rand() < 0.6 \n    return after \n\n- 테스트\n\n# 비가 왔음, Xt = 1 \nsum([rain(1) for i in range(100)])\n\n30\n\n\n\n# 비가 안왔음, Xt = 0 \nsum([rain(0) for i in range(100)])\n\n60\n\n\n- 하나의 \\(\\omega\\)에 대응하는 길이가 10000인 확률과정을 관찰\n\ndef doctor_strange(today):\n    lst = [today]\n    for i in range(10000): \n        lst.append(rain(lst[i]))\n    return lst \n\n\ntoday = True # 오늘 비가 왔다는 뜻 \narr = doctor_strange(today)\n\n\nlen(arr)\n\n10001\n\n\n- 4305개의 \\(\\omega\\)에 대응하는 길이가 10000인 확률과정을 관찰\n\ntoday = True # 오늘 비가 왔다는 뜻 \narr = np.array([doctor_strange(today) for ω in range(4305)])\n\n\narr[:,-1].mean()\n\n0.4662020905923345\n\n\n- 10000일 뒤에도 비가 올 확률은 약 46% 정도 인듯\n\n\n풀이2\n- 세상의 법칙을 다시 정리해보자.\n\n\\(X_{t-1}=0 \\Rightarrow X_t \\sim Ber(0.6)\\)\n\\(X_{t-1}=1 \\Rightarrow X_t \\sim Ber(0.3)\\)\n\n- 정리하면\n\n\\(P(X_t=0)= P(X_{t-1}=0) \\times 0.4 + P(X_{t-1}=1) \\times 0.7\\)\n\\(P(X_t=1)= P(X_{t-1}=0) \\times 0.6 + P(X_{t-1}=1) \\times 0.3\\)\n\n- 매트릭스형태로 표현하면\n\n\\(\\begin{bmatrix} P(X_t=0) \\\\ P(X_t=1) \\end{bmatrix}= \\begin{bmatrix} 0.4 & 0.7 \\\\ 0.6 & 0.3 \\end{bmatrix} \\begin{bmatrix} P(X_{t-1}=0) \\\\ P(X_{t-1}=1) \\end{bmatrix}\\)\n\\({\\boldsymbol \\mu}_t = {\\bf P} {\\boldsymbol \\mu}_{t-1}\\)\n\n- 이렇게 놓고 보니까\n\n\\({\\boldsymbol \\mu}_1 ={\\bf P}{\\boldsymbol \\mu}_0\\)\n\\({\\boldsymbol \\mu}_2 ={\\bf P}{\\boldsymbol \\mu}_1={\\bf P}^2{\\boldsymbol \\mu}_0\\)\n\\(\\dots\\)\n\\({\\boldsymbol \\mu}_{10000} ={\\bf P}^{10000}{\\boldsymbol \\mu}_0\\)\n\n- 이제 계산을 해보자.\n\nμ0 = np.array([[0],[1]])\nμ0\n\narray([[0],\n       [1]])\n\n\n\nP = np.array([[0.4,0.7],[0.6,0.3]])\nP\n\narray([[0.4, 0.7],\n       [0.6, 0.3]])\n\n\n\nP@P # P의 제곱\n\narray([[0.58, 0.49],\n       [0.42, 0.51]])\n\n\n\nP@P@P@P # P의 4제곱\n\narray([[0.5422, 0.5341],\n       [0.4578, 0.4659]])\n\n\n\nP@P@P@P @ P@P@P@P # P의 8제곱 \n\narray([[0.53849182, 0.53842621],\n       [0.46150818, 0.46157379]])\n\n\n\nP@P@P@P@P@P@P@P @ P@P@P@P@P@P@P@P # P의 16제곱 \n\narray([[0.53846154, 0.53846154],\n       [0.46153846, 0.46153846]])\n\n\n\\({\\bf P}\\)가 수렴하는거 같지 않어?\n\nP@P@P@P@P@P@P@P@P@P@P@P@P@P@P@P @ P@P@P@P@P@P@P@P@P@P@P@P@P@P@P@P \n\narray([[0.53846154, 0.53846154],\n       [0.46153846, 0.46153846]])\n\n\n대충 \\({\\bf P}^{10000} \\approx {\\bf P}^{32}\\)\n\nPlim = P@P@P@P@P@P@P@P@P@P@P@P@P@P@P@P @ P@P@P@P@P@P@P@P@P@P@P@P@P@P@P@P \nPlim \n\narray([[0.53846154, 0.53846154],\n       [0.46153846, 0.46153846]])\n\n\n\nPlim @ μ0\n\narray([[0.53846154],\n       [0.46153846]])\n\n\n- 이 풀이에 따르면 10000일 뒤에 비가 올 확률은 46% 정도이다.\n\n\n풀이3\n- 세상의 법칙을 다시 정리해보자.\n\n\\(X_{t-1}=0 \\Rightarrow X_t \\sim Ber(0.6)\\)\n\\(X_{t-1}=1 \\Rightarrow X_t \\sim Ber(0.3)\\)\n\n- 추측: 10000일 뒤에 비가 올 확률이 \\(p\\)라고 치자. 그렇다면 9999일 뒤에 비가 올 확률도 \\(p\\) 아닐까?\n이걸 가정하고 계산해보자\n1. 9999일 뒤에 비가 안 올 확률 \\(1-p\\)\n\n9999일 뒤에 비가 안오고, 10000일 뒤에는 비가 올 확률: \\(0.6(1-p)\\)\n9999일 뒤에 비가 안오고, 10000일 뒤에는 비가 안 올 확률: \\(0.4(1-p)\\)\n\n2. 9999일 뒤에 비가 올 확률 \\(p\\)\n\n9999일 뒤에 비가 오고, 10000일 뒤에도 비가 올 확률: \\(0.3p\\)\n9999일 뒤에 비가 오고, 10000일 뒤에는 비가 안 올 확률: \\(0.7p\\)\n\n따라서 \\(0.6(1-p) + 0.3p = p\\)\n풀어보면 \\(0.6/1.3 =p\\)\n\n0.6/1.3\n\n0.4615384615384615\n\n\n\n\n풀이4\n\nnp.mean(doctor_strange(True)[1:])\n\n0.462"
  },
  {
    "objectID": "posts/1. 측도론/2023-03-28-4wk-2.html",
    "href": "posts/1. 측도론/2023-03-28-4wk-2.html",
    "title": "04wk-2: 측도론 intro (6)",
    "section": "",
    "text": "youtube: https://youtube.com/playlist?list=PLQqh36zP38-x7Z5LJZOG4At6NWHs757XG"
  },
  {
    "objectID": "posts/1. 측도론/2023-03-28-4wk-2.html#셀-수-있는",
    "href": "posts/1. 측도론/2023-03-28-4wk-2.html#셀-수-있는",
    "title": "04wk-2: 측도론 intro (6)",
    "section": "셀 수 있는",
    "text": "셀 수 있는\n- 셀 수 있는 집합과 셀 수 없는 집합.\n\ncountable: finite, countable many\nuncountable: uncountable many\n\n- 예시1: countable set, uncountable set\n\n\\(\\{1,2,3,4,5\\}\\)는 셀 수 있는 집합이다.\n\\(\\mathbb{N}\\)은 셀 수 있는 집합이다.\n\\(\\mathbb{Z}\\)는 셀 수 있는 집합이다.\n\\(\\mathbb{Q}\\)는 셀 수 있는 집합이다.\n\\(\\mathbb{R}\\)은 셀 수 없는 집합이다.\n\n- 예시2: countable sum: 아래는 모두 countable sum을 의미한다.\n\n\\(\\sum_{i=1}^{n}a_i\\).\n\\(\\sum_{i \\in I} a_i\\), where \\(I=\\{1,2,3,\\dots,10\\}\\).\n\\(\\sum_{i=1}^{\\infty} a_i\\), \\(\\sum_{i=0}^{\\infty} a_i\\).\n\\(\\sum_{i \\in \\mathbb{N}}a_i\\).\n\\(\\sum_{x \\in \\mathbb{Q}}m(\\{x\\})\\), where \\(m\\) is Lebesgue measure\n\n- 예시3: countable union: 아래는 countalbe union을 의미한다.\n\n\\(\\cup_{i=1}^n A_i\\)\n\\(\\cup_{i=1}^{\\infty} A_i\\)\n\\(\\cup_{x \\in \\mathbb{Q}} \\{x\\}\\)\n\n- 예시4: 아래는 uncountable sum을 의미한다.\n\n\\(\\sum_{x \\in [0,1]}m(\\{x\\})\\), where \\(m\\) is Lebesgue measure\n\n- 예시5: 아래는 uncountable union을 의미한다.\n\n\\(\\cup_{x \\in [0,1]} \\{x\\}\\)"
  },
  {
    "objectID": "posts/1. 측도론/2023-03-28-4wk-2.html#여러가지-집합",
    "href": "posts/1. 측도론/2023-03-28-4wk-2.html#여러가지-집합",
    "title": "04wk-2: 측도론 intro (6)",
    "section": "여러가지 집합",
    "text": "여러가지 집합\n\n\n\n집합 (\\(\\mathbb{R}\\)의 부분집합)\n카디널리티\n분류\n르벡메져\n\n\n\n\n\\(\\{1,2,3\\}\\)\n3\n가산집합\n0\n\n\n\\(\\mathbb{N}\\)\n\\(\\aleph_0\\)\n가산집합\n0\n\n\n\\(\\mathbb{Z}\\)\n\\(\\aleph_0\\)\n가산집합\n0\n\n\n\\(\\mathbb{Q}\\)\n\\(\\aleph_0\\)\n가산집합\n0\n\n\n\\([0,1]\\)\n\\(2^{\\aleph_0}\\)\n비가산집합\n1\n\n\n\\([0,1]\\cap \\mathbb{Q}\\)\n\\(\\aleph_0\\)\n가산집합\n0\n\n\n\\([0,1]\\cup \\mathbb{Q}\\)\n\\(2^{\\aleph_0}\\)\n비가산집합\n1\n\n\n\\([0,1]\\cap \\mathbb{Q}^c\\)\n\\(2^{\\aleph_0}\\)\n비가산집합\n1\n\n\n\\([0,\\infty)\\)\n\\(2^{\\aleph_0}\\)\n비가산집합\n\\(\\infty\\)\n\n\n비탈리집합\n\\(2^{\\aleph_0}\\)\n비가산집합\nNA\n\n\n칸토어집합\n\\(2^{\\aleph_0}\\)\n비가산집합\n0"
  },
  {
    "objectID": "posts/1. 측도론/2023-03-28-4wk-2.html#확률변수의-엄밀한-정의",
    "href": "posts/1. 측도론/2023-03-28-4wk-2.html#확률변수의-엄밀한-정의",
    "title": "04wk-2: 측도론 intro (6)",
    "section": "확률변수의 엄밀한 정의",
    "text": "확률변수의 엄밀한 정의\n- 확률변수 (머리속): \\(X:\\Omega \\to \\mathbb{R}\\) 인 잴 수 있는 함수.\n- 확률변수 (엄밀하게): 두 개의 잴 수 있는 공간 \\((\\Omega,{\\cal F})\\)와 \\((\\mathbb{R}, {\\cal R})\\)이 있다고 하자. 확률변수 \\(X\\)는 아래를 만족하는 함수 \\(X:\\Omega \\to \\mathbb{R}\\) 이다.\n\\[\\forall B \\in {\\cal R}: X^{-1}(B) = \\{\\omega:X(\\omega)\\in B \\} \\in {\\cal F}\\]\n\nNote1: \\(\\{\\omega:X(\\omega)\\in B \\} \\in {\\cal F}\\) for all \\(B \\in {\\cal R}\\) 이라 쓰기도 함. 쓰는사람 마음~\n\n\nNote2: \\({\\cal R}\\)은 Borel sets라고 부른다. 의미는 \\(\\mathbb{R}\\)의 부분집합중 잴 수 있는 부분집합의 모임이라는 뜻이다. (즉 \\({\\cal F}\\)의 의미와 같다) \\({\\cal B}\\)의 원소는 Borel set이라고 부른다.\n\n- 왜 정의가 아래와 같지 않을까?\n\\[\\forall B \\subset \\mathbb{R}: X^{-1}(B) = \\{\\omega:X(\\omega)\\in B \\} \\in {\\cal F}\\]\n\n위의 질문을 위한 보충학습\n(예제) 바늘이 하나 있는 시계\n1. outcomes: \\(0,1,\\frac{\\pi}{3},\\frac{2\\pi}{5},\\pi\\dots\\)\n2. sample space: \\(\\Omega = (0,2\\pi]\\)\n3. event: \\(\\emptyset\\), \\([0,\\frac{2}{\\pi})\\), \\(\\{2\\pi\\}\\), \\(\\dots\\)\n4. \\(\\sigma\\)-field: \\({\\cal F}\\). \\(\\Omega\\)의 부분집합 중 잴 수 있는 집합의 모임.\n5. probability measure function: \\(P: \\Omega \\to [0,1]\\) such that\n\n\\(P(\\emptyset) = 0\\)\n\\(P([0,\\frac{2}{\\pi}) = \\frac{1}{4}\\)\n\\(P(\\{2\\pi\\}) = 0\\)\n\\(P(\\Omega) = 1\\)\n\n6. random variable: \\(X: \\Omega \\to \\mathbb{R}\\) such that \\(X(\\omega)=\\omega\\). // 사실 \\(X: (0,2\\pi] \\to (0,2\\pi]\\)\n6을 주목하자. 만약에 비탈리집합 \\(V \\subset \\mathbb{R}\\)에 대한 inverse image는 비탈리집합 그 자체가 된다. 따라서 아래와 같이 된다.\n\\[P(X \\in V)=P\\big(\\{\\omega: X(\\omega) \\in V\\}\\big)=P(V)\\]\n\\(V\\)는 잴 수 없는 집합이므로 \\(P(V)\\)와 같은 표현을 불가함.\n결론: 확률변수 \\(X\\)를 고려할때 정의역의 치역 양쪽의 measurable space를 고려해야함.\n\n- 교재의 정의1\n\n\n\n그림1: Durret에서 긁어온 확률변수의 정의\n\n\n- 교재의 정의2\n\n\n\n그림2: Durret에서 긁어온 확률변수의 정의2\n\n\n- \\(X\\)가 랜덤변수라는 것을 기호로 간단하게 \\(X \\in {\\cal F}\\) 혹은 \\(X : (\\Omega, {\\cal F}) \\to (\\mathbb{R},{\\cal R})\\)라고 쓴다.\n\n사실 \\(X: (\\Omega,{\\cal F}) \\to (\\mathbb{R}, {\\cal R})\\)은 \\(X\\)가 잴 수 있는 함수 (measurable function, measurable map) 임을 나타내는 기호이다.\n\n- “\\(X\\)를 확률변수라고 하자.” 라는 의미? 지금 까지 해온 모든 논의가 압축된 표현…\n\n확률이라는건 원래 모든 \\(\\Omega\\)에서는 잘 정의되지 않음.\n그래도 \\(\\Omega\\)의 부분집합중 잴 수 있는 집합이라는 것이 있는데 그게 \\({\\cal F}\\)야.\n이 두개를 세트로 묶어서 \\((\\Omega,{\\cal F})\\) 이라고 하고 이를 잴 수 있는 공간이라고 하자.\n이 잴 수 있는 공간 \\((\\Omega, {\\cal F})\\) 에서는 이제 확률 \\(P\\)를 정의 할 수 있어.\n한편 \\(\\Omega\\)의 원소는 숫자로 되어있지 않으니까 이를 숫자화시키는 어떠한 함수가 필요한데 이것을 우리는 \\(X\\)라고 할 것임.\n그런데 \\(P(X=1)\\)와 같은 표현이 가능하려면 \\(X\\)의 inverse image가 \\({\\cal F}\\)의 원소이어야 하는데 이게 항상 가능한 것은 아니므로 \\(X\\)를 잴 수 있는 함수라고 추가가정 해야 함.\n\n\n“\\(X\\)를 확률변수라고 하자” 라고 선언하는 것은 아래의 효과를 가진다. (1) \\(\\Omega\\)에 대응하는 \\({\\cal F}\\)가 잘 정의되어 있다고 하자. (2) \\(P\\) 역시 잘 정의되어 있다고 하자. (3) \\(\\mathbb{R}\\)와 \\({\\cal R}\\)이 잘 정의되어 있다고 하자. (4) \\(X: (\\Omega,{\\cal F}) \\to (\\mathbb{R},{\\cal R})\\) 이 잘 정의되어 있다고 하자."
  },
  {
    "objectID": "posts/1. 측도론/2023-03-28-4wk-2.html#헷갈려-2-starstarstar",
    "href": "posts/1. 측도론/2023-03-28-4wk-2.html#헷갈려-2-starstarstar",
    "title": "04wk-2: 측도론 intro (6)",
    "section": "헷갈려 (2) (\\(\\star\\star\\star\\))",
    "text": "헷갈려 (2) (\\(\\star\\star\\star\\))\n- 확률변수에 대한 오해1: 학률변수 = 값이 랜덤으로 바뀌는 변수??\n\n함수: \\(y=f(x)\\), \\(f\\): function, \\(x\\): input \\(y\\): output\n확률변수: \\(x=X(\\omega)\\), \\(X\\): function, \\(\\omega\\): outcome1, \\(x\\): realization\n확률변수는 함수이지만 보통 \\(X(\\omega)\\)와 같이 쓰지 않고 \\(X\\)라고 쓴다. \\(\\Rightarrow\\) 혼란의 이유\n\n- 확률변수에 대한 오해2: 확률변수는 결과가 랜덤으로 변한다??\n\n확률변수는 함수일 뿐임. 입력이 정해지면 출력이 고정임!\n동전예제: 입력이 \\(\\omega=H\\)이면 출력은 \\(X(\\omega)=1\\), 입력이 \\(\\omega=T\\)이면 출력은 \\(X(\\omega)=0\\)으로 고정임!\n\n- 확률변수에 대한 오해3: 아니야.. 확률변수는 결과가 랜덤으로 바뀌는 느낌이 맞아. 아래의 예시를 봐!\n\\[X = \\begin{cases} 0 & w.p. \\frac{1}{2} \\\\ 1 & w.p. \\frac{1}{2} \\end{cases}\\]\n\n\\(X\\)는 진짜 변수처럼 보이긴함.\n심지어 변수의 값이 랜덤으로 변하는 것 같음.\n\n(해설)\n정확하게는 아래 표현이 맞다.\n\\[X(\\omega) = \\begin{cases} 0 & \\omega \\in \\{H\\} \\\\ 1 & \\omega \\in \\{T\\} \\end{cases} \\quad \\text{where } P(\\{H\\}) = P(\\{T\\}) = \\frac{1}{2}.\\]\n- 확률변수에 대한 오해2에 대한 추가설명\n\n확률변수는 결과가 랜덤으로 변하는 함수가 아님, 확률변수는 함수일 뿐임. 입력이 정해지면 출력이 고정임!\n동전예제: 입력이 \\(\\omega=H\\)이면 출력은 \\(X(\\omega)=1\\), 입력이 \\(\\omega=T\\)이면 출력은 \\(X(\\omega)=0\\)으로 고정임!\n단지 입력 outcome이 실험에 따라 랜덤으로 변할 수 있는 것임!!\n\n- 요약해보면,\n\n확률변수는 확률과 관련없다.\n간접적으로는 관련이 있다. \\(\\because\\) X의 역상 = \\(\\Omega\\)의 부분집합 = \\(P\\)의 정의역\n\n- 표현연습: \\(P(X=1), P(X \\in \\{0,1\\}),\\dots ...\\)"
  },
  {
    "objectID": "posts/1. 측도론/2023-03-21-3wk-2.html",
    "href": "posts/1. 측도론/2023-03-21-3wk-2.html",
    "title": "03wk-2: 측도론 intro (4)",
    "section": "",
    "text": "강의영상\n\nyoutube: https://youtube.com/playlist?list=PLQqh36zP38-yaBxW0S3fsO1d-kYIqZa62\n\n\n\n시그마필드 motivation (1)\n(예제1) – 잴 수 있는 집합의 모임\n\\(\\Omega=\\{H,T\\}\\)라고 하자. 아래집합들은 모두 확률을 정의할 수 있는 집합들이다.\n\\[\\emptyset, \\{H\\}, \\{T\\}, \\Omega\\]\n따라서 \\({\\cal F}\\)을 아래와 같이 정의한다면 묶음 \\({\\cal F}\\)가 합리적일 것이다.\n\\[{\\cal F}=\\big\\{\\emptyset, \\{H\\}, \\{T\\}, \\Omega\\big\\}\\]\n\n이때 \\({\\cal F}\\)는 집합들의 집합인데, 이러한 집합을 collection 이라고 한다.\n\n(예제2) – 집합 \\(A\\)를 잴 수 있다면, 집합 \\(A^c\\)도 잴 수 있어~\n\\(\\Omega=\\{H,T\\}\\)라고 하자. \\({\\cal F}\\)을 아래와 같이 정의한다면 묶음 \\({\\cal F}\\)는 합리적이지 않다.\n\\[{\\cal F}=\\big\\{\\emptyset, \\{H\\}, \\Omega\\big\\}\\]\n(해설1)\n이러한 묶음이 의미하는건 “앞면이 나올 확률은 모순없이 정의할 수 있지만, 뒷면이 나오는 확률은 모순없이 정의하는게 불가능해~” 라는 뜻이다. 그런데 뒷면이 나올 확률은 “1-앞면이 나올 확률” 로 모순없이 정의할 수 있으므로 “앞면이 나올 확률이 모순없이 정의되면서” 동시에 “뒷면이 나올 확률이 모순없이 정의되지 않는” 상황은 없다.\n(해설2)\n\\(\\Omega\\)의 어떠한 부분집합 \\(A\\)에 확률이 모순없이 정의된다면 그 집합의 여집합인 \\(A^c\\)에 대하여서도 확률이 모순없이 정의되어야 한다.\n\\(\\Leftrightarrow\\) \\(\\forall A \\subset {\\Omega}: ~ A \\in {\\cal F} \\Rightarrow A^c \\in {\\cal F}\\)\n(예제3) – 전체집합이 잴 수 있는 집합이니까 공집합도 잴 수 있는 집합이야\n\\(\\Omega=\\{H,T\\}\\)라고 하자. \\({\\cal F}\\)를 아래와 같이 정의한다면 묶음 \\({\\cal F}\\)는 합리적이지 않다.\n\\[{\\cal F}=\\big\\{ \\{H\\}, \\{T\\}, \\Omega\\big\\}\\]\n(해설)\n전체집합의 확률은 \\(P(\\Omega)=1\\)로 정의할 수 있다. 그런데 전체집합의 여집합인 공집합의 확률을 정의할 수 없는건 말이 안되므로 공집합은 \\(\\cal F\\)에 포함되어야 한다.\n(예제4) – 원소의 수가 유한한 경우 \\({\\cal F}=2^\\Omega\\)은 잴 수 있는 집합의 모임이야.\n\\(\\Omega=\\{1,2,3,4,5,6\\}\\)이라고 하자. \\({\\cal F}\\)을 아래와 같이 정의한다고 하자. 이러한 묶음은 \\({\\cal F}\\)은 합리적이다.\n\\[{\\cal F}=\\text{all subset of $\\Omega$}= 2^\\Omega = \\big\\{ \\emptyset, \\{1\\}, \\{2\\}, \\dots, \\{6\\}, \\dots, \\{1,2,3,4,5\\} \\dots \\Omega\\big\\}\\]\n(해설)\n\\(\\Omega\\)의 모든 부분집합에 대하여 확률을 모순없이 정의할 수 있다. 예를들면\n\n\\(P(\\Omega)=1\\), \\(P(\\emptyset)=0\\)\n\\(P(\\{1\\})=\\frac{1}{6}\\)\n\\(P(\\{1,2,4\\})=\\frac{3}{6}\\)\n\\(P(\\{2,3,4,5,6\\})=\\frac{5}{6}\\)\n\\(\\dots\\)\n\n이런식으로 정의할 수 있다.\n(예제5) – 동일한 \\(\\Omega\\)에 대하여 잴 수 있는 집합의 모임 \\({\\cal F}\\)는 유니크하지 않음.\n\\(\\Omega=\\{1,2,3,4,5,6\\}\\)이라고 하자. \\({\\cal F}\\)을 아래와 같이 정의한다고 하자. 이러한 묶음 \\({\\cal F}\\)는 합리적이다.\n\\[{\\cal F}=\\big\\{\\emptyset, \\{6\\}, \\{1,2,3,4,5\\},\\Omega \\big\\}\\]\n(해설)\n어떠한 특수한 상황을 가정하자. 주사위를 던져야하는데 6이 나오면 살수 있고 6이 나오지 않으면 죽는다고 하자. 따라서 던지는 사람 입장에서는 주사위를 던져서 6이 나오는지 안나오는지만 관심있을 것이다. 이 사람의 머리속에서 순간적으로 떠오르는 확률들은 아래와 같다.1\n\n살수있다 => 1/6\n죽는다 => 5/6\n살거나 죽는다 => 1\n살지도 죽지도 않는다 => 0\n\n이러한 확률은 합리적이다. 즉 아래의 집합들만 확률을 정의한다고 해도, 확률을 잘 정의할 수 있을 것 같다.\n\\[\\emptyset, \\{6\\}, \\{1,2,3,4,5\\}, \\Omega\\]\n(예제6) – \\(\\Omega\\)를 어떠한 사건의 집합으로 보느냐에 따라서 \\({\\cal F}\\)를 달리 구성할 수 있다.\n\\(\\Omega=\\{1,2,3,4,5,6\\}\\)이라고 하자. \\({\\cal F}\\)을 아래와 같이 정의한다고 하자. 이러한 묶음 \\({\\cal F}\\)는 합리적이다.\n\\[{\\cal F}=\\big\\{\\emptyset, \\{1,3,5\\}, \\{2,4,6\\},\\Omega \\big\\}\\]\n(해설)\n전체사건을 “주사위를 던져서 짝이 나오는 사건”, “주사위를 던져서 홀이 나오는 사건” 정도만 구분하겠다는 의미\n(예제7) – \\(A\\in {\\cal F} \\Rightarrow A^c \\in {\\cal F}\\)\n\\(\\Omega=\\{1,2,3,4,5,6\\}\\)이라고 하자. \\({\\cal F}\\)을 아래와 같이 정의한다고 하자. 이러한 묶음 \\({\\cal F}\\)는 합리적이지 않다.\n\\[{\\cal F}=\\big\\{\\emptyset, \\{1,3,5\\}, \\Omega \\big\\}\\]\n(해설)\n“주사위를 던져서 홀수가 나올 사건”에 대한 확률을 정의할 수 있는데, 짝수가 나올 사건에 대한 확률을 정의할 수 없다는건 말이 안되는 소리임.\n(예제8) – trivial \\(\\sigma\\)-field\n\\(\\Omega=\\{1,2,3,4,5,6\\}\\)이라고 하자. \\({\\cal F}\\)을 아래와 같이 정의한다고 하자. 이러한 묶음 \\({\\cal F}\\)는 합리적이다.\n\\[{\\cal F}=\\{\\emptyset, \\Omega \\}\\]\n(해설)\n아예 이렇게 잡으면 모순이 일어나진 않음. (쓸모가 없겠지)\n(예제9) – 서로소인 두 집합의 합, 포함관계에 있는 집합의 차\n\\(\\Omega=\\{1,2,3,4\\}\\)이라고 하자. 어떠한 필요에 따라서 1이 나올 확률과 2가 나올 확률에만 관심이 있고 나머지는 별로 관심이 없다고 하자. 그래서 \\({\\cal F}\\)을 아래와 같이 정의했다고 하자. 이러한 묶음 \\({\\cal F}\\)는 합리적이지 않다.\n\\[{\\cal F}=\\{\\emptyset, \\{1\\}, \\{2\\}, \\{2,3,4\\}, \\{1,3,4\\}, \\Omega \\}\\]\n(해설1)\n\\({\\cal F}\\)은 전체집합과 공집합을 포함하고 여집합에 닫혀있으므로 언뜻 생각해보면 합리적인듯 보이지만 그렇지 않다. 왜냐하면 \\(\\{1,2\\}\\)이 빠졌기 때문이다. 1이 나올 확률 \\(P(\\{1\\})\\)와 2가 나올 확률 \\(P(\\{2\\})\\)를 각각 정의할 수 있는데, 1 또는 2가 나올 확률 \\(P(\\{1,2\\})\\)을 정의할 때 모순이 발생한다는 것은 합리적이지 못하다. 왜냐하면 \\(\\{1\\} \\cap \\{2\\} = \\emptyset\\) 이므로\n\\[P(\\{1\\} \\cup \\{2\\})=P(\\{1\\}) + P(\\{2\\})\\]\n와 같이 정의가능하기 때문이다. 따라서 집합이 아래와 같이 수정되어야 한다.\n\\[{\\cal F}=\\{\\emptyset, \\{1\\}, \\{2\\}, \\{2,3,4\\}, \\{1,3,4\\}, \\Omega, \\{1,2\\}, \\{3,4\\} \\}\\]\n(해설2)\n생각해보니까 \\(\\{2\\}\\)는 \\(\\{2,3,4\\}\\)의 부분집합이다. 그런데 \\(P(\\{2\\})\\)와 \\(P(\\{2,3,4\\})\\)를 각각 정의할 수 있는데\n\\[P(\\{2,3,4\\} - \\{2\\}) = P(\\{3,4\\})\\]\n를 정의할 수 없는건 말이 안된다. 따라서 \\({\\cal F}\\)를 아래와 같이 수정해야 한다.\n\\[{\\cal F}=\\{\\emptyset, \\{1\\}, \\{2\\}, \\{2,3,4\\}, \\{1,3,4\\}, \\Omega, \\{3,4\\}, \\{1,2\\} \\}\\]\n(해설3)\n\\(\\Omega\\)의 어떠한 두 부분집합 \\(A\\), \\(B\\)가 서로소라고 상상하자. 집합 \\(A\\), \\(B\\)에 대한 확률이 각각 무모순으로 정의된다면, 집합 \\(A\\cup B\\)에 대한 확률도 무모순으로 정의되어야 한다.\n\\(\\Leftrightarrow\\) \\(\\forall A,B \\subset \\Omega\\) such that \\(A \\cap B =\\emptyset\\): \\(A,B \\in {\\cal F} \\Rightarrow A \\cup B \\in {\\cal F}\\)\n또한 \\(\\Omega\\)의 임의의 두 부분집합이 \\(A \\subset B\\)와 같은 포함관계가 성립할때, 집합 \\(A\\), \\(B\\)에 대한 확률이 각각 무모순으로 정의된다면, 집합 \\(B-A\\)에 대한 확률로 무모순으로 정의되어야 한다.\n\\(\\Leftrightarrow\\) \\(\\forall A,B \\subset \\Omega\\) such that \\(A \\subset B\\): \\(A,B \\in {\\cal F} \\Rightarrow B-A \\in {\\cal F}\\)\n(예제10) – \\({\\cal A}=\\{\\{1\\},\\{2\\}\\}\\) 일때, \\(\\sigma({\\cal A})\\) 를 구하는 문제\n\\(\\Omega=\\{1,2,3,4\\}\\)이라고 하자. 내가 관심이 있는 확률은 \\(P(\\{1\\})\\), \\(P(\\{2\\})\\) 밖에 없다고 하자. 이러한 확률들이 무모순으로 정의되기 위한 최소한의 \\({\\cal F}\\)를 정의하라.\n(해설) – 좀 귀찮네..?\n0차수정: \\({\\cal A} = \\big\\{\\{1\\}, \\{2\\}\\big\\}\\)\n1차수정: \\(\\big\\{\\emptyset, \\{1\\}, \\{2\\}, \\Omega \\big\\}\\)\n2차수정: \\(\\big\\{\\emptyset, \\{1\\}, \\{2\\}, \\{2,3,4\\}, \\{1,3,4\\}, \\Omega \\big\\}\\)\n3차수정: \\(\\big\\{\\emptyset, \\{1\\}, \\{2\\}, \\{2,3,4\\}, \\{1,3,4\\}, \\Omega, \\{1,2\\}, \\{3,4\\} \\big\\}\\)\n\n사실 우리가 관심 있는건 \\({\\cal A} = \\{ \\{1\\}, \\{2\\} \\}\\) 뿐 이었음. 그런데 뭔가 \\(P(\\{1\\})\\)와 \\(P(\\{2\\})\\)를 합리적으로 정의하기 위해서 필연적으로 발생하는 어떠한 집합들을 모두 생각하는건 매우 피곤하고 귀찮은 일임. 그래서 “아 모르겠고, \\(\\{1\\}\\) 와 \\(\\{2\\}\\)를 포함하고 확률의 뜻에 모순되지 않게 만드는 최소한의 \\({\\cal F}\\)가 있을텐데, 거기서만 확률을 정의할래!” 라고 쉽게 생각하고 싶은 사람들이 생김. 그러한 공간을 \\(\\sigma({\\cal A})\\)라는 기호로 약속하고 smallest \\(\\sigma\\)-field containing \\({\\cal A}\\) 라는 용어로 부름.\n\n\n\n\n\n\nFootnotes\n\n\n공평한 주사위라고 하자..↩︎"
  },
  {
    "objectID": "posts/1. 측도론/2023-03-14-2wk-2.html",
    "href": "posts/1. 측도론/2023-03-14-2wk-2.html",
    "title": "02wk-2: 측도론 intro (2)",
    "section": "",
    "text": "강의영상\n\nhttps://youtube.com/playlist?list=PLQqh36zP38-zQoiFje77DtmGx03QS339J\n\n\n\n예비개념1: 귀류법\n- 귀류법: 니 논리 대로면… <- 인터넷 댓글에 많음..\n님 논리대로면..\n- XXX가 문제 없으면 서울 전체가 문제가 없고 (애초에 서울은 문제도 아니라는데 왜 이소리는 하고 계신지 모르겠지만)\n- 수도권 모 대학이 문제가 없으면 전체가 문제가 없겠네요?\n- 지방도 1개 대학이 문제가 없으니 전체가 문제 없겠네요?\n와우! 모든 문제가 해결되었습니다! 출산율 감소로 인한 한국대학의 위기가 해결되었.. 아니 애초에 위기가 없었군요!.\n어휴.. ㅠㅠ\n\nref: 하이브레인넷\n\n\n\n예비개념2: 일반화\n- 연필의 정의: 필기도구의 하나. 흑연과 점토의 혼합물을 구워 만든 가느다란 심을 속에 넣고, 겉은 나무로 둘러싸서 만든다. 1565년에 영국에서 처음으로 만들었다.\n- 질문: 아래는 연필인가?\n\n\n\n애플펜슬!\n\n\n\n\ncardinality\n\nref: https://en.wikipedia.org/wiki/Cardinality\n\n- \\(A=\\{2,4,6\\}\\) \\(\\Rightarrow\\) \\(|A|=3\\), \\(A\\) has a cardinality of 3.\n- \\(A=\\{1,2,3,4,\\dots\\}=\\mathbb{N}\\) \\(\\Rightarrow\\) \\(|A|=?\\)\n\nCardinal number: 유한집합에서의 “갯수”라는 개념을 좀 더 일반화 하여 무한집합으로 적용하고 싶다.\n유한집합: 우리가 친숙한 size 와 그 뜻이 같음\n무한집합: 무한집합의 경우는 그 동작원리가 조금 더 복잡함\n\n- 질문: \\(|\\mathbb{Q}| < |\\mathbb{Q}^c|\\) ??\nBijection, injection and surjection (예비학습)\n\nref: https://en.wikipedia.org/wiki/Bijection,_injection_and_surjection\n\n\n- 용어 정리\n\nsurjective = onto = 전사 = 위로의 함수\ninjective = one-to-one = 단사 = 일대일 함수\nbijective = one-to-one and onto, one-to-one correspondence = 전단사 = 일대일 대응\n\n- 따지는 방법:\n\n단사: 함수 \\(f\\)는 \\(X\\)에서 \\(Y\\)로 향하는 단사함수이다. \\(\\Leftrightarrow\\) \\(\\forall x_1,x_2 \\in X\\): \\(x_1\\neq x_2 \\Rightarrow f(x_1)\\neq f(x_2)\\)\n전사: 함수 \\(f\\)는 \\(X\\)에서 \\(Y\\)로 향하는 전사함수이다. \\(\\Leftrightarrow\\) \\(\\forall y \\in Y ~\\exists x \\in X\\) such that \\(f(x)=y\\).\n\n- 성질1: 어떤함수가 전사함수 & 단사함수 \\(\\Rightarrow\\) 전단사함수\n- 성질2:\n\n집합 \\(X\\)에서 집합 \\(Y\\)로 가는 단사함수 \\(f\\)가 존재한다. \\(\\Rightarrow\\) \\(|X| \\leq |Y|\\)\n집합 \\(X\\)에서 집합 \\(Y\\)로 가는 전사함수 \\(f\\)가 존재한다. \\(\\Rightarrow\\) \\(|X| \\geq |Y|\\)\n\n(예비학습 끝)\n- 성질1~2로 유추하면 아래와 같은 사실을 주장 할 수 있지 않을까?\n\n집합 \\(X\\)에서 집합 \\(Y\\)로 향하는 전단사함수가 존재한다 \\(\\Rightarrow\\) \\(|X|=|Y|\\)\n\n- 그렇다면 우리가 주장하고 싶은 것은 아래와 같이 된다.\n\n유리수집합의 무리수집합의 cardinality는 다르다.\n유리수집합과 무리수집합사이의 전단사함수는 존재할 수 없다.\n\n\n\n유리수집합의 카디널리티\n- 우리가 궁극적으로 궁금한 것\n\n유리수집합과 무리수집합의 카디널리티는 다를까?\n\n- 그냥 궁금한 것\n\n자연수의 집합, 비음인 정수의 집합, 음의 정수의 집합, 정수의 집합, 짝수의 집합, 홀수의 집합의 카디널리티는 어떠할까?\n\n- (예제1)\n집합 \\(X=\\{1,2,3\\}\\), \\(Y=\\{2,4,6\\}\\)을 생각하자. 적당한 함수 \\(f\\)를 아래와 같이 정의하자.\n\n\\(f(1)=2\\)\n\\(f(2)=4\\)\n\\(f(3)=6\\)\n\n아래의 질문에 대답해보자.\n\n(단사) \\(\\forall x_1,x_2 \\in X\\), \\(x_1\\neq x_2\\) \\(\\Rightarrow\\) \\(f(x_1)\\neq f(x_2)\\)?\n(전사) \\(\\forall y \\in Y~ \\exists x \\in X\\) such that \\(f(x)=y\\)?\n\n1의 질문과 2의 질문이 모두 맞으므로 함수 \\(f\\)는 전단사 함수이다. 집합 \\(X\\)에서 집합 \\(Y\\)로 가는 전단사 함수가 존재하므로 집합 \\(X\\)와 집합 \\(Y\\)의 카디널리티는 동일하다.\n- (예제2)\n집합 \\(X=\\{1,2,3,\\dots \\}\\), \\(Y=\\{2,4,6,\\dots \\}\\)을 생각하자. 적당한 함수 \\(f\\)를 아래와 같이 정의하자.\n\n\\(f(1)=2\\)\n\\(f(2)=4\\)\n\\(f(3)=6\\)\n\\(\\dots\\)\n\n아래의 질문에 대답해보자.\n\n(단사) \\(\\forall x_1,x_2 \\in X\\), \\(x_1\\neq x_2\\) \\(\\Rightarrow\\) \\(f(x_1)\\neq f(x_2)\\)?\n(전사) \\(\\forall y \\in Y~ \\exists x \\in X\\) such that \\(f(x)=y\\)?\n\n1의 질문과 2의 질문이 모두 맞으므로 함수 \\(f\\)는 전단사함수이다. 집합 \\(X\\)에서 집합 \\(Y\\)로 가는 전단사 함수가 존재하므로 집합 \\(X\\)와 집합 \\(Y\\)의 카디널리티는 동일하다.\n- \\(\\aleph_0\\) (알레프 널, 혹은 알레프 제로라고 읽음)\n\n자연수집합 \\(\\mathbb{N}\\)의 카디널리티는 \\(\\aleph_0\\)이다. 즉 \\(|\\mathbb{N}|=\\aleph_0\\).\n짝수인 자연수 집합의 카디널리티는 \\(\\aleph_0\\)이고, 홀수인 자연수 집합의 카디널리티는 \\(\\aleph_0\\)이다.\n정수집합 \\(\\mathbb{Z}\\)의 카디널리티는 \\(\\aleph_0\\)이다. 즉 \\(|\\mathbb{Z}|=\\aleph_0\\).\n\n- 느낌: \\(\\aleph_0\\)를 2배,3배,4배 하여도 \\(\\aleph_0\\)이다.\n\n즉 무한집합의 경우, 본인과 카디널넘버가 같은 진 부분집합이 존재할 수 있다. (유한집합에서는 불가능하겠지)\n무한집합의 정의: 집합 \\(A\\)가 무한집합이다. \\(\\Leftrightarrow\\) \\(A\\)와 동일한 카디널리티를 가지는 \\(A\\)의 진 부분집합이 존재한다.\n\n- (예제3)\n원소의 수가 \\(n\\)인 임의의 유한집합 \\(A\\)에 대하여 \\(|A|=n\\) 이다.\n- (예제4)\n유리수집합의 카디널리티는 얼마인가? (ref: https://en.wikipedia.org/wiki/Rational_number)\n집합 \\(X\\)를 자연수의 집합이라고 하자. 집합 \\(Y\\)를 아래그림에 있는 숫자들의 집합이라고 하자.1\n\n예를들어 집합 \\(X\\)와 집합 \\(Y\\)를 앞의 몇개만 써보면\n\n\\(X=\\{1,2,3,4,5,6,\\dots\\}\\)\n\\(Y=\\{1,\\frac{2}{1},\\frac{1}{2},\\frac{3}{1},\\frac{2}{2},\\frac{1}{3},\\dots \\}\\)\n\n함수 \\(f\\)를 아래와 같이 정의하자.\n\n\\(f(1)=1\\)\n\\(f(2)=2/1\\)\n\\(f(3)=1/2\\)\n\\(f(4)=3/1\\)\n\\(f(5)=2/2\\)\n\\(f(6)=1/3\\)\n\\(\\dots\\)\n\n함수 \\(f\\)는 \\(X\\)에서 \\(Y\\)로 향하는 전단사함수이다. \\(\\Rightarrow\\) \\(|X|=\\aleph_0=|Y|\\)\n(관찰) 임의의 양의 유리수의 집합 \\(\\mathbb{Q}^+\\)는 모두 \\(Y\\)에 포함되어 있다. \\(\\Rightarrow\\) \\(X \\subset \\mathbb{Q}^+ \\subset Y\\) \\(\\Rightarrow\\) \\(|\\mathbb{Q}^+|=\\aleph_0\\)\n(생각) 그럼 음의 유리수의 집합 \\(\\mathbb{Q}^-\\)의 카디널넘버 역시 \\(\\aleph_0\\)이다. 즉 \\(|\\mathbb{Q}^-|=\\aleph_0\\).\n(결론) 그럼 유리수의 카디널넘버는 \\(\\aleph_0\\)이다.2 좀 더 자극적으로 말하면 “자연수의 갯수와 유리수의 갯수는 같다” 라고 말할 수 있다.\n- 조금 무식하게 쓰면 아래와 같이 쓸 수 있다.\n\n\\(\\aleph_0 + 1 = \\aleph_0\\)\n\\(\\aleph_0 \\times 2 = \\aleph_0\\)\n\\(\\aleph_0 \\times \\aleph_0 = \\aleph_0^2 = \\aleph_0\\)\n\n\n\n\n\n\nFootnotes\n\n\n그래서 일단 집합 \\(Y\\)는 양의 유리수의 집합을 포함한다↩︎\n\\(\\mathbb{Q} = \\mathbb{Q}^+ \\cup \\{0\\} \\cup \\mathbb{Q}^-\\)↩︎"
  },
  {
    "objectID": "posts/1. 측도론/2023-03-09-2wk-1.html",
    "href": "posts/1. 측도론/2023-03-09-2wk-1.html",
    "title": "02wk-1: 측도론 intro (1)",
    "section": "",
    "text": "강의영상\n\nyoutube: https://youtube.com/playlist?list=PLQqh36zP38-yPGeQuQgZaqhpUJujTtP4g\n\n\n\n예제1: 동전\n- \\(\\Omega =\\{H,T\\}\\): sample space\n- \\(P(\\{H\\})=P(\\{T\\})=\\frac{1}{2}\\): prob\n- 질문: \\(\\Omega\\)의 임의의(=모든) 부분 집합 \\(\\Omega^*\\)에 대하여 \\(P(\\Omega^*)\\)를 모순없이 정의할 수 있을까?\n\n당연한거 아냐?\n이게 왜 안돼?\n\n- 질문에 대한 대답\n\n\\(\\Omega\\)의 부분집합: \\(\\emptyset, \\Omega, \\{H\\},\\{T\\}\\)\n\\(P(\\{H\\})=\\frac{1}{2}\\), \\(P(\\{T\\})=\\frac{1}{2}\\), \\(P(\\Omega)=P(\\{H,T\\})=1\\), \\(P(\\emptyset)=0\\)\n\n- 모순없이의 의미?\n\n우리가 상식적으로 확률에 적용가능한 어떠한 연산들이 있음. (확률의 공리 + 기본성질) // 네이버검색\n이러한 연산을 적용해도 상식적인 수준에서 납득이 가야함\n\n(상식적인 연산 적용 예시1)\n\\(\\{H\\} \\subset \\Omega \\Rightarrow P(\\{H\\})<P(\\Omega)\\)\n\n집합 \\(\\{H\\}\\)은 집합 \\(\\Omega\\)보다 작은 집합임\n상식적으로 작은집합이 일어날 확률이 큰 집합이 일어날 확률보다 클 수 없음\n동전 예제의 경우 모든 \\(A,B \\subset \\Omega\\) 에 대하여, \\(A\\subset B\\) 이라면 \\(P(A) < P(B)\\) 가 성립함\n\n(상식적인 연산 적용 예시2)\n\\(\\{H\\} \\cap \\{T\\} = \\emptyset \\Rightarrow P(\\{H\\} \\cup \\{T\\})=P(\\{H\\}) + P(\\{T\\}) =1\\)\n\n우리의 상식에 따르면 \\(A,B\\)가 서로소인 사건이라면 \\(P(A)+P(B)\\)이어야 함.1\n이 예제는 실제로 그러함.\n사실 이 예제의 경우 \\(P(\\{H\\} \\cup \\{T\\})=P(\\Omega)=1\\) 와 같이 계산할 수도 있음.\n하지만 어떠한 방식으로 계산해도 모순이 없음.\n\n\n\n예제2: 바늘이 하나만 있는 시계\n- \\(\\Omega = [0,2\\pi)\\)\n\n시계바늘을 돌려서 나오는 각도를 재는일 \\(\\Leftrightarrow\\) \\([0,2\\pi)\\)사이의 숫자중에 하나를 뽑는 일\n\n- 질문: 바늘을 랜덤으로 돌렸을때 12시-6시 사이에 바늘이 있을 확률? \\(\\frac{1}{2}\\)\n\n\\(\\Omega^* = [0,\\pi)\\)\n\\(P(\\Omega^*)= \\frac{1}{2}\\)\n\n- 계산하는 방법? 아래와 같이 계산하면 가능!!\n\\[\\forall \\Omega^* \\subset \\Omega, \\quad P(\\Omega^*)=\\frac{m(\\Omega^*)}{m(\\Omega)}\\]\n단 여기에서 \\(m\\)은 구간의 길이를 재는 함수라고 하자.\n연습: \\(m\\)의 사용\n\n\\(m(\\Omega)=m\\big([0,2\\pi)\\big)=2\\pi\\)\n\\(m(\\Omega^*) = m\\big([0,\\pi)\\big)= \\pi\\)\n\n- 위와 같은 방식으로 확률을 정의하면 잘 정의될까? 이게 쉽지 않음. 왜냐하면 확률을 잘 정의하기 위해서는\n\n\\(\\Omega\\)의 모든 부분집합 \\(\\Omega^*\\)에 대하여 \\(P(\\Omega^*)\\)를 모순없이\n\n정의할 수 있어야 하는데, 이게 쉬운일이 아님.\n(질문0) 그냥 몸풀기 용 질문\n\n\\(\\Omega^*=\\emptyset\\) 일 확률이 얼마인가?\n\n(답변)\n\n0 이야2\n\n(질문1) 첫번째 도전적인 질문\n\n\\(\\Omega^* =\\{0\\}\\)일 확률이 얼마인가?\n\n(답변)\n\n즉 바늘침이 정확하게 12시를 가르킬 확률이 얼마냐는 것\n한 점으로 이루어진 집합 \\(\\{0\\}\\)은 분명히 \\(\\Omega=[0,2\\pi)\\)의 부분집합 이므로 앞서 논의한대로라면 이러한 집합에 대한 확률을 명확하게, 모순없이 정의할 수 있어야 함\n많은 사람들이 이 질문에 대한 답은 \\(0\\) 이라고 알고 있고 그 이유를 “점의 길이는 0 이니까” 라고 이해하고 있음.3\n\n답변이 사실 좀 찝찝해. 바늘침이 정확하게 12시를 가르키는 것은 우리가 분명 하루에 한번씩은 경험하는 사건임. 그런데 그 사건이 일어날 확률은 0이다?4\n(참견질문) 생각해보니까 이런게 있었잖아?\n\\[A \\subset B \\Rightarrow P(A)<P(B)\\]\n그런데 \\(\\emptyset \\subset \\{0\\}\\) 인데 \\(P(\\emptyset)=P(\\{0\\})\\) 이다..?\n(답변)\n\n원래식은 이거임: \\(A \\subset B \\Rightarrow P(A)\\leq P(B)\\).\n즉 \\(A\\)가 \\(B\\)의 진 부분집합이더라도 \\(P(A)=P(B)\\)인 경우가 존재함.\n\n(질문2) 두번째 질문은 아래와 같다.\n\n그렇다면 사건 \\(\\{0,\\pi\\}\\)가 일어날 확률은 얼마인가?\n\n(답변)\n\n질문을 다시 풀어쓰면 바늘침이 정확하게 12시를 가르키거나 혹은 정확하게 6시를 가르킬 확률이 얼마냐는 것\n따라서 이 질문에 대한 대답은 \\(0+0=0\\) 이므로 \\(0\\)이라고 주장할 수 있음.\n\n(질문3) 세번째 질문은 아래와 같다.\n\n구간 \\([0,2\\pi)\\)는 무수히 많은 점들이 모여서 만들어지는 집합이다. 그런데 점 하나의 길이는 0이다. 0을 무수히 더해도 0이다. 그러므로 구간 \\([0,2\\pi)\\)의 길이도 0이 되어야 한다. 이것은 모순아닌가?\n\n(답변)\n\n까다롭다.\n\\(m([0,2\\pi))=0\\) 임을 인정하면 전체확률은 1이어야 한다는 기본상식5에 어긋나 모순이 생김.\n질문의 논리는 타당해보임. 이 논리의 약점은 딱히 없어보임. 굳이 약점이 있다면 “무한”이라는 개념?\n어쩔수없이 직관에 근거한 약간의 약속을 또 다시 해야할 것 같음. 예를들면 “점들을 유한번 합치면 그냥 많은 점들이지만 무한히 합치면 이것은 선분이 된다. 따라서 길이가 생긴다.” 와 같이.\n우리는 이 약속을 “무한번의 기적”이라고 칭하자.\n\n(질문4) 그렇다면 아래의 질문은 어떻게 대답할 수 있을까?\n\n\\([0,\\pi)\\) 에서 유리수만 뽑아낸 집합이 있다고 생각하자. 편의상 이 집합을 \\(\\mathbb{Q}\\) 라고 하자. 이 집합은 분명히 무한개의 점을 포함하고 있다. 그렇다면 이 집합도 길이가 있는가? 있다면 얼마인가?\n\n(답변)\n\n이미 점들의 길이를 무한번 더하면 길이가 생긴다고 주장한 상태이므로 (무한번의 기적) 길이가 0이라고 주장할 수 없다. 따라서 길이가 있다고 주장해야 한다.\n\\(\\pi\\)말고 딱히 떠오르는 수가 없는데 단순히 길이가 \\(\\pi\\)라고 주장한다면 바로 모순에 빠짐을 알 수 있다.6\n길이는 일단 0보다 커야하고 \\(\\pi\\)보다 작아야함은 자명하므로 그 사이에 있는 어떤 값이 길이라고 주장하자.7\n따라서 (질문4)에 대한 답은 ‘’구체적으로 얼마인지는 모르겠지만 길이가 분명 존재하고 그 길이는 0 보다 크고 \\(\\pi\\) 보다는 작은 어떠한 값 \\(a\\)이다.’’ 정도로 정리할 수 있다.\n즉 \\(m(\\mathbb{Q})=a\\), where \\(0<a<\\pi\\).\n\n(질문5) – 외통수\n질문4로부터 만들어지는 논리는 빌드업1-3으로 이어지는 콤보질문을 적절하게 대답하지 못한다. (질문이 좀 길어서 나누어서 설명합니다)\n(빌드업1) – 평행이동은 길이를 변화시키지 않아, 그렇지?\n\n\\(\\mathbb{Q}\\)의 모든점에 \\(\\sqrt{2}\\)를 더한다. 이 점들로 집합을 만들어 \\(\\mathbb{Q}_{\\sqrt{2}}\\)를 만든다.\n여기에서 \\(\\mathbb{Q}_{\\sqrt{2}}\\)는 \\(\\Omega\\)의 부분집합 \\(\\Rightarrow\\) \\(\\mathbb{Q}_{\\sqrt{2}}\\)는 길이를 명확하고 모순없이 정의할 수 있어야 함\n\\(\\mathbb{Q}_{\\sqrt{2}}\\)의 길이는 사실 쉽게 \\(a\\)라고 정의할 수 있음8. 즉, \\(m(\\mathbb{Q}_{\\sqrt{2}})=a\\).\n\n(빌드업2) – 겹치지 않게 평행이동 시킨다음에 길이를 더한다면?\n이제 \\(\\mathbb{Q}_{\\sqrt{2}},\\mathbb{Q}_{\\sqrt{2}/2},\\mathbb{Q}_{\\sqrt{2}/3}\\)를 생각하자. 아래의 성질을 관찰할 수 있다.\n\n\\(\\mathbb{Q}_{\\sqrt{2}},\\mathbb{Q}_{\\sqrt{2}/2},\\mathbb{Q}_{\\sqrt{2}/3}\\)는 모두 \\(\\Omega\\)의 부분집합 \\(\\Rightarrow\\) 따라서 길이를 명확하고 모순없이 정의할 수 있어야 함\n\\(\\mathbb{Q}_{\\sqrt{2}},\\mathbb{Q}_{\\sqrt{2}/2},\\mathbb{Q}_{\\sqrt{2}/3}\\)의 길이는 각각 \\(a\\)로 정의할 수 있다.9\n\\(P(\\mathbb{Q}_{\\sqrt{2}} \\cup \\mathbb{Q}_{\\sqrt{2}/2} \\cup \\mathbb{Q}_{\\sqrt{2}/3})=P(\\mathbb{Q}_{\\sqrt{2}}) + P(\\mathbb{Q}_{\\sqrt{2}/2})+ P(\\mathbb{Q}_{\\sqrt{2}/3})\\)10\n\n굳이 \\(P(\\mathbb{Q}_{\\sqrt{2}}) + P(\\mathbb{Q}_{\\sqrt{2}/2})+ P(\\mathbb{Q}_{\\sqrt{2}/3})\\)를 계산하면 아래와 같이 계산할 수 있겠다.\n\\[P(\\mathbb{Q}_{\\sqrt{2}}) + P(\\mathbb{Q}_{\\sqrt{2}/2})+ P(\\mathbb{Q}_{\\sqrt{2}/3})=\\frac{a}{2\\pi}+\\frac{a}{2\\pi}+\\frac{a}{2\\pi}=3 \\times \\frac{a}{2\\pi}\\]\n(빌드업3) – 그런데 난 겹치지않게 평행이동시킬 방법을 무한대로 알고 있는데?\n눈 여겨볼 점은 아래 식이 성립해야 한다는 것이다. (\\(\\because\\) 확률의 공리)11\n\\[P\\big(\\mathbb{Q}_{\\sqrt{2}} \\cup \\mathbb{Q}_{\\sqrt{2}/2} \\cup \\mathbb{Q}_{\\sqrt{2}/3}\\big) = 3 \\times \\frac{a}{2\\pi} \\leq 1 \\quad \\cdots (\\star)\\]\n\n그런데 \\((\\star)\\)에서 좌변의 값은 편의에 따라서 값을 임의로 키울 수 있다.\n이렇게 임의로 키워진 좌변의 값이라도 항상 그 값은 1보다 작아야 하는데 (확률의 공리), 이게 가능하려면 \\(a=0\\)인 경우 말고 없다.\n그런데 \\(a=0\\) 이 된다면 “무한번 더해서 일어나는 기적”은 허구가 되므로 질문3 의 대답에 모순이 된다.\n\n그런데 임의로 좌변의 값을 키워도 항상 그 값은 1보다 작아야 하는데 이러한 \\(a\\)는 0이외에 불가능하다.\n그런데 \\(a=0\\) 이 된다면 “무한번 더해서 일어나는 기적”은 허구가 되므로 질문3 의 대답에 모순이 된다.\n\n\n르벡메져\n- 예제2에서의 마지막 질문은 지금까지 제시한 논리로 방어가 불가능. 이처럼 논리적 모순없는 체계를 만드는 것은 매우 어려운 일임.\n- 결론적으로 말하면 길이를 재는 함수 \\(m\\)을 아래와 가정하면 위의 모든 질문에 대한 대답을 논리적 모순없이 설계할 수 있다.\n\n한 점에 대한 길이는 \\(0\\) 이다.\n\\([0,2\\pi)\\) 사이의 모든 유리수를 더한 집합은 그 길이가 \\(0\\)이다.\n\\([0,2\\pi)\\) 사이의 모든 무리수를 더한 집합은 그 길이가 \\(2\\pi\\)이다.\n\n참고로 르벡측도(Lebesgue measure)를 사용하면 위의 성질을 만족한다.12 따라서 르벡측도를 활용하여 확률을 정의하는 것이 모순을 최대한 피할 수 있다.\n\n\n\n\n\nFootnotes\n\n\n확률의 공리↩︎\n이걸 좀 더 엄밀하게 따질수도 있는데 일단 직관적으로 0이라 생각하고 넘어가자↩︎\n이해 안되면 약속이라고 생각하자.↩︎\n자연어에서는 “확률=0” 와 “불가능” 은 동일하지만 여기서는 아니다.↩︎\n심지어 이건 확률의 공리↩︎\n왜 모순에 빠지냐면 \\([0,\\pi)\\)에서 무리수만 뽑아낸 집합의 길이가 뭐냐고 물을경우 0이라고 말해야함↩︎\n구체적으로 어떤값인지는 모른다고 하자.↩︎\n평행이동은 길이를 변화시킬 수 없으니까↩︎\n평행이동은 길이를 변화시키지 않으니까↩︎\n\\(\\mathbb{Q}_{\\sqrt{2}},\\mathbb{Q}_{\\sqrt{2}/2},\\mathbb{Q}_{\\sqrt{2}/3}\\)는 모두 서로소 임을 이용↩︎\n첫 등호는 서로소인 사건에 대한 공리, 그다음 부등호는 확률의 총합은 1보다 같거나 작다라는 공리↩︎\n물론 르벡측도의 정의가 위와 같지는 않다↩︎"
  },
  {
    "objectID": "posts/1. 측도론/2023-03-23-4wk-1.html",
    "href": "posts/1. 측도론/2023-03-23-4wk-1.html",
    "title": "04wk-1: 측도론 intro (5)",
    "section": "",
    "text": "youtube: https://youtube.com/playlist?list=PLQqh36zP38-yTpksFFUby_Twan5kFTFdm"
  },
  {
    "objectID": "posts/1. 측도론/2023-03-23-4wk-1.html#불완전한-정의",
    "href": "posts/1. 측도론/2023-03-23-4wk-1.html#불완전한-정의",
    "title": "04wk-1: 측도론 intro (5)",
    "section": "불완전한 정의",
    "text": "불완전한 정의\n- 확률변수: \\(X:\\Omega \\to \\mathbb{R}\\)인 조금 특별한 성질을 가진 함수\n\n정의역: \\(\\Omega\\)\n치역: \\(\\mathbb{R}\\)\n\n(예제1) 동전예제\n1. outcomes31: \\(H\\),\\(T\\).\n2. sample space: \\(\\Omega = \\{H,T\\}\\)\n3. event32: \\(\\emptyset\\), \\(\\{H\\}\\), \\(\\{T\\}\\), \\(\\{H,T\\}\\).\n4. \\(\\sigma\\)-field: \\({\\cal F}=\\) \\(\\Omega\\)의 모든 부분집합의 모임\n5. probability measure function: \\(P: {\\cal F} \\to [0,1]\\) such that\n\n\\(P(\\emptyset) = 0\\)\n\\(P(\\{H\\}) = \\frac{1}{2}\\)\n\\(P(\\{T\\}) = \\frac{1}{2}\\)\n\\(P(\\Omega) = 1\\)\n\n6. random variable: \\(X: \\Omega \\to \\mathbb{R}\\) such that\n\n\\(X(H)=1\\)\n\\(X(T)=0\\)\n\n만약에 편의상 \\(\\Omega=\\{H,T\\}=\\{\\omega_1,\\omega_2\\}\\)와 같이 사용한다면\n\n\\(X(\\omega_1)=1\\)\n\\(X(\\omega_2)=0\\)"
  },
  {
    "objectID": "posts/1. 측도론/2023-03-23-4wk-1.html#헷갈려-1-starstarstar",
    "href": "posts/1. 측도론/2023-03-23-4wk-1.html#헷갈려-1-starstarstar",
    "title": "04wk-1: 측도론 intro (5)",
    "section": "헷갈려 (1) (\\(\\star\\star\\star\\))",
    "text": "헷갈려 (1) (\\(\\star\\star\\star\\))\n- 질문1: 아래의 표현 중 옳은 것은?\n\n\\(X(H)=0\\)33\n\\(P(\\{H\\})=\\frac{1}{2}\\)34\n\\(P(\\{\\omega_1\\})=\\frac{1}{2}\\)35\n\\(P(H)=\\frac{1}{2}\\)36\n\\(P(\\{H,T\\})=1\\)37\n\\(P(\\omega_1)=\\frac{1}{2}\\)38\n\n- 질문2: 질문1의 4번의 표현을 많이 본적 있다. 예를들어서 고등학교에서 두 사건의 독립에 대해 배울때 아래와 같은 방식으로 표현했었다. // 출처: 네이버 블로그\n\n두 사건 \\(A\\), \\(B\\)에 대하여 \\(P(B|A) =P(B|A^c) =P(B)\\) 이면 두 사건이 독립이라고 한다~~\n\n그렇다면 이 표현은 틀린걸까?\n(해설)\n여기에서 사건 \\(A\\), \\(B\\)는 event을 의미하며 outcome을 의미하는게 아님. 즉 \\(A\\), \\(B\\)는 집합임.\n암기: 확률은 항상 집합을 입력으로 받아야 함!!\n- 질문3(\\(\\star\\star\\star\\)): 수리통계 시간에서 아래와 같은 표현 본 적 있다.\n\\[P(X=1)=\\frac{1}{2}\\]\n그런데 \\(P\\)의 입력으로는 집합이 들어가야하는데, \\(X=1\\)은 그냥 수식임. 그렇다면 이 표현은 틀린 표현일까??\n(해설)\n사실 \\(P(X=1)\\)의 의미는 아래와 같은 표현의 축약형이다.\n\\[P\\big(\\{\\omega: X(\\omega)=1 \\} \\big)\\]\n\\(\\{\\omega: X(\\omega)=1\\} = \\{\\omega_1\\} = \\{H\\}\\) 를 의미하므로 결국\n\\[P(X=1)=P(\\{\\omega: X(\\omega)=1\\})=P(\\{H\\})\\]\n이 된다. 따라서 옳은 표현이다."
  },
  {
    "objectID": "posts/1. 측도론/2023-03-23-4wk-1.html#확률변수에-대한-통찰-1",
    "href": "posts/1. 측도론/2023-03-23-4wk-1.html#확률변수에-대한-통찰-1",
    "title": "04wk-1: 측도론 intro (5)",
    "section": "확률변수에 대한 통찰 (1)",
    "text": "확률변수에 대한 통찰 (1)\n- 아래와 같은 표현을 다시 관찰하자.\n\\[P(X=1)=P(\\{\\omega: X(\\omega)=1\\})=P(\\{H\\})\\]\n통찰1. 확률변수가 “함수”라는 사실을 떠올리고 \\(1\\)이라는 값이 확률변수의 “상(image)” 라는 사실을 떠올리면, \\(\\{\\omega: X(\\omega)=1\\}\\)은 1에 대한 “역상(inverse image)”이라고 해석할 수 있다.39\n통찰2. 확률변수의 상은 \\(\\mathbb{R}\\)에 맺히게 되고, 확률변수의 역상은 \\(\\Omega\\)의 부분집합 중 하나에 맺히게 된다.\n통찰3. 문제는 확률변수의 역상이 항상 잴 수 있는 집합에 맺힌다는 보장이 있냐라는 것이다… 즉 이 예제로 한정하면\n\\[\\{\\omega: X(\\omega)=1\\} \\in {\\cal F}\\]\n임을 보장해야 한다는 것이다.\n통찰4. 당연히 이러한 보장을 할 수는 없어보인다. 따라서 \\(X\\)를 단지 그냥\n\n\\(X: \\mathbb{\\Omega} \\to \\mathbb{R}\\)로 가는 함수\n\n가 아니라\n\n\\(X: \\mathbb{\\Omega} \\to \\mathbb{R}\\)로 가는 함수 & 역상이 항상 잴 수 있는 집합이어야 함.\n\n이라는 조건이 필요하다.\n- 역상이 잴 수 있는 집합인 함수를 간단히 잴 수 있는 함수 (measurable function) 라고 한다."
  },
  {
    "objectID": "posts/1. 측도론/2023-03-29-5wk-2-hw1.html",
    "href": "posts/1. 측도론/2023-03-29-5wk-2-hw1.html",
    "title": "05wk-2: HW1",
    "section": "",
    "text": "강의영상\n\nyoutube: https://youtube.com/playlist?list=PLQqh36zP38-xsTHLqiyPTgay2jwnssbnC\n\n\n\n배점\n\n\n\n문항\n점수\n\n\n\n\n1-(1)\n15\n\n\n1-(2)\n15\n\n\n2-(1)\n5\n\n\n2-(2)\n5\n\n\n2-(3)\n10\n\n\n2-(4)\n10\n\n\n3-(1)\n20\n\n\n3-(2)\n20\n\n\n\n\n\n1. Cardinality\n(1) \\(\\mathbb{Q}\\)의 cardinality가 \\(\\aleph_0\\)임을 증명하라.\n(풀이) 생략\n(2) \\(\\mathbb{R}\\)의 cardinality가 \\(\\aleph_0\\)이 아님을 보여라.\n(풀이) 생략\n\n\n2. \\(\\sigma\\)-field\n(1) \\(\\Omega=\\{H,T\\}\\)일 때, 다음 중 시그마필드의 정의를 만족하는 집합을 모두 골라라.\n\n\\({\\cal F}=\\{\\emptyset\\}\\)\n\\({\\cal F}=\\{\\Omega\\}\\)\n\\({\\cal F}=\\{\\emptyset, \\Omega\\}\\)\n\\({\\cal F}=\\{\\{H\\}\\}\\)\n\\({\\cal F}=\\{\\{H\\}, \\{T\\}\\}\\)\n\\({\\cal F}=\\{\\emptyset, \\{H\\}, \\Omega\\}\\)\n\\({\\cal F}=\\{\\emptyset, \\{T\\}, \\Omega\\}\\)\n\\({\\cal F}=\\{\\emptyset, \\{H\\}, \\{T\\}, \\Omega\\}\\)\n\n(풀이) 3,8 이 시그마필드이다. // 시그마필드가 아닌이유를 서술할 필요없음. 답만 쓰면 인정함.\n(2) \\(\\Omega=\\{1,2,3,4\\}\\) 일 때,\n\\[{\\cal A}=\\{ \\{1\\}, \\{1,2\\}\\}\\]\n이라고 하자. \\(\\sigma({\\cal A})\\)를 구하여라.\n(풀이) // 이 문제역시 답만 써도 인정\n\\(\\sigma({\\cal A}) = \\{\\emptyset, \\{1\\},\\{2\\},\\{3,4\\}, \\{1,2\\},\\{1,3,4\\}, \\{2,3,4\\}, \\Omega\\}\\)\n\n요령: \\(\\{3,4\\}\\)를 한세트로 보면 편리하다. 즉 전체사건을 \\(\\{1\\},\\{2\\},\\{3,4\\}\\)로 쪼갠뒤에 3개의 원소만 있다고 생각하고 모든 부분집합을 쓰면 된다.\n\n(3) \\(\\Omega=\\{1,2,3,4,\\dots,100\\}\\) 일 때,\n\\[{\\cal A}=\\{ \\{1\\}, \\{1,2\\}, \\{1,2,3\\},\\{1,2,3,4\\}\\}\\]\n이라고 하자. 아래의 물음에 답하여라.\n\n\\(\\{2\\} \\in \\sigma({\\cal A})\\) 인가?\n\\(\\{2,3,4\\} \\in \\sigma({\\cal A})\\) 인가?\n\\(\\{3,4,5\\} \\in \\sigma({\\cal A})\\) 인가?\n\\(\\Omega - \\{1,2,3\\} \\in \\sigma({\\cal A})\\) 인가?\n\n(풀이) // 답만쓰면 인정하지 않음.\n시그마필드의 정의는 아래와 같다.\n\n시그마필드 \\({\\cal F} \\subset 2^\\Omega\\) 는 1. 전체집합을 포함하고, 2. 여집합에 닫혀있고 3. 가산합집합에 닫혀있는 collection 이다.\n\n먼저 강의노트를 참고하여 아래의 사실을 보이자.\n\n\\(A,B \\in {\\cal F} \\Rightarrow A \\cap B \\in {\\cal F}\\)\n\\(A,B \\in {\\cal F} \\Rightarrow A - B \\in {\\cal F}\\)\n\n이제 풀어보자.\n1번\n\n\\(\\{1,2\\} \\in \\sigma({\\cal A})\\), \\(\\{1\\} \\in \\sigma({\\cal A})\\)\n\\(\\Rightarrow\\) \\(\\{1,2\\} - \\{1\\} = \\{2\\} \\in \\sigma({\\cal A})\\) (\\(\\because\\) (b))\n\n2번\n\n\\(\\{1,2\\}-\\{1\\} = \\{2\\} \\in \\sigma({\\cal A})\\), \\(\\{1,2,3\\} - \\{1,2\\} = \\{3\\} \\in \\sigma({\\cal A})\\), \\(\\{1,2,3,4\\} - \\{1,2,3\\} = \\{4\\} \\in \\sigma({\\cal A})\\).\n\\(\\Rightarrow\\) \\(\\{2\\}\\cup \\{3\\} \\cup \\{4\\} = \\{2,3,4\\} \\in \\sigma({\\cal A})\\)\n\n3번\n\n\\(\\{3,4,5\\} \\not \\in \\sigma({\\cal A})\\)\n\n4번\n\n\\(\\{1,2,3\\}\\in \\sigma({\\cal A})\\)\n\\(\\Rightarrow \\{1,2,3\\}^c \\in \\sigma({\\cal A})\\)\n\n(4) \\(\\Omega=[0,2\\pi)\\) 일 때,\n\\[{\\cal A}=\\{ [a,b): 0\\leq a< b\\leq 2\\pi\\}\\]\n이라고 하자. 아래의 물음에 답하여라.\n\n\\([\\frac{\\pi}{2},\\pi) \\in \\sigma({\\cal A})\\) 인가?\n\\(\\{\\pi\\} \\in \\sigma({\\cal A})\\) 인가?\n\\(\\{0,\\frac{\\pi}{2},\\pi,\\frac{3\\pi}{2}\\} \\in \\sigma({\\cal A})\\) 인가?\n\\((\\frac{\\pi}{2},\\pi) \\in \\sigma({\\cal A})\\) 인가?\n\n\n수업시간에 2번문제 잘못해설했어요. (문제도 잘못냈어요, 너무 어렵게 냈어요. )\n\n(풀이)\n\n\\(a=\\frac{\\pi}{2}\\), \\(b=\\pi\\)\n\\([0,\\pi)~ \\bigcup ~\\cup_{i=1}^{\\infty}[\\pi+\\frac{1}{n}, 2\\pi) = [0,\\pi) \\cup (\\pi,2\\pi)\\) \\(\\Rightarrow\\) \\(\\Omega - \\big([0,\\pi) \\cup (\\pi,2\\pi) \\big) = \\{\\pi\\} \\in \\sigma({\\cal A})\\)\n\n\n\\([\\pi+\\frac{1}{n}, 2\\pi)\\)는 각각 잴 수 있는 집합이므로 \\(\\cup_{i=1}^{\\infty}[\\pi+\\frac{1}{n}, 2\\pi)\\) 역시 잴 수 있는 집합이다.\n여기에서 \\(\\cup_{i=1}^{\\infty}[\\pi+\\frac{1}{n}, 2\\pi)=(\\pi,2\\pi)\\) 로 볼 수 있는데, 그 이유는 \\(\\cup_{i=1}^{\\infty}[\\pi+\\frac{1}{n}, 2\\pi)\\)는 \\(\\pi\\)보다 큰 모든수를 포함하지만 \\(\\pi\\)는 포함할 수 없기 때문이다.\n\\([0, \\pi)\\)도 당연히 잴 수 있는 집합이다.\n잴 수 있는 집합의 교집합은 잴 수 있으므로 \\([0,\\pi)~ \\cup ~(\\pi,2\\pi)\\) 역시 잴 수 있는 집합이다.\n따라서 \\([0,2\\pi) - \\big([0,\\pi) \\cup (\\pi,2\\pi) \\big)\\) 역시 잴 수 있다.\n\n\n\\(\\{\\pi\\}\\)를 잴수 있다는 것과 동일한 논리전개로 \\(\\{0\\},\\{\\frac{\\pi}{2}\\}, \\{\\frac{3\\pi}{2}\\}\\) 모두 잴 수 있는 집합이고, 따라서 이들의 합집합도 잴 수 있다.\n\\([\\frac{\\pi}{2}, \\pi)\\)를 잴 수 있고 \\(\\{\\frac{\\pi}{2}\\}\\)를 잴 수 있으므로 \\([\\frac{\\pi}{2}, \\pi) - \\{\\frac{\\pi}{2}\\}\\) 역시 잴 수 있다.\n\n\n\n3. 확률과 확률변수\n(1) 아래와 같은 measurable space \\((\\Omega, {\\cal F})\\)를 고려하자.\n\n\\(\\Omega=\\{a,b,c,d\\}\\)\n\\({\\cal F}=2^\\Omega\\)\n\n아래와 같은 확률변수 \\(X: \\Omega \\to \\{1,2,3,4\\}\\) 를 고려하자. 다음중 올바른 표현은?\n\n\\(X(a)\\)\n\\(X(\\{a\\})\\)\n\\(P(a)\\)\n\\(P(\\{a\\})\\)\n\\(P(X=1)\\)\n\\(X = \\begin{cases} 1 & w.p.~\\frac{1}{2} \\\\ 2 & w.p. ~\\frac{1}{6} \\\\ 3 & w.p. ~\\frac{1}{6} \\\\ 4 & w.p. ~\\frac{1}{6} \\end{cases}\\)\n\n(풀이) 생략 (이 문제는 그대로 낼거라서요, 풀이 생략합니다. 스스로 해보세요. 시험에서는 답만쓰면 정답으로 인정합니다)\n(2) 아래와 같은 measurable space를 고려하자.\n\n\\(\\Omega=\\{a,b,c,d\\}\\)\n\\({\\cal F} =\\sigma({\\cal A})\\) where \\({\\cal A} = \\{\\{a\\}\\}\\).\n\n아래와 같은 function \\(X:\\Omega \\to A:=\\{1,2,3,4\\}\\), \\(Y:\\Omega \\to B:=\\{1,2\\}\\)을 고려하자.\n\n\\(X(a)=1, X(b)=2, X(c)=3, X(d)=4\\)\n\\(Y(a)=1, Y(b)=2, Y(c)=2, Y(c)=2\\)\n\n아래의 물음에 답하라.\n\n\\(X\\)는 \\((\\Omega,{\\cal F}) \\to (A,2^{A})\\) 인가? 즉 \\(X\\)는 \\((\\Omega,{\\cal F})\\) 에서의 확률변수인가?\n\\(Y\\)는 \\((\\Omega,{\\cal F}) \\to (B,2^{B})\\) 인가? 즉 \\(Y\\)는 \\((\\Omega,{\\cal F})\\) 에서의 확률변수인가?\n\n(풀이)\n\\(X\\)는 확률변수가 아님\n집합 \\(\\{2\\} \\subset 2^A\\)에 대하여 \\(\\{\\omega: X(\\omega) \\in \\{2\\}\\}=\\{b\\} \\not \\in \\sigma({\\cal A})\\) 이므로 \\(X\\)는 확률변수가 아님\n\\(Y\\)는 확률변수임\n\\(2^B = \\{\\emptyset,\\{1\\},\\{2\\},B\\}\\) 의 모든 부분집합 \\(B^\\ast\\)에 대하여 \\(\\{\\omega: X(\\omega) \\in B^\\ast\\} \\in \\sigma({\\cal A})\\) 이 성립함.\n\n\\(\\{\\omega: X(\\omega) \\in \\emptyset\\} = \\emptyset \\in \\sigma({\\cal A})\\)\n\\(\\{\\omega: X(\\omega) \\in \\{1\\}\\} = \\{a\\} \\in \\sigma({\\cal A})\\)\n\\(\\{\\omega: X(\\omega) \\in \\{2\\}\\} = \\{b,c,d\\} \\in \\sigma({\\cal A})\\)\n\\(\\{\\omega: X(\\omega) \\in B\\} = \\{a,b,c,d\\} \\in \\sigma({\\cal A})\\)"
  },
  {
    "objectID": "posts/1. 측도론/2023-03-16-3wk-1.html",
    "href": "posts/1. 측도론/2023-03-16-3wk-1.html",
    "title": "03wk-1: 측도론 intro (3)",
    "section": "",
    "text": "https://youtube.com/playlist?list=PLQqh36zP38-y_-OXU_IFt6uH3oo61swW4"
  },
  {
    "objectID": "posts/1. 측도론/2023-03-16-3wk-1.html#전사-단사-전단사",
    "href": "posts/1. 측도론/2023-03-16-3wk-1.html#전사-단사-전단사",
    "title": "03wk-1: 측도론 intro (3)",
    "section": "전사, 단사, 전단사",
    "text": "전사, 단사, 전단사\n함수 \\(f: X \\to Y\\) 를 상상하자.\n- 단사함수(일대일함수,인젝티브한 함수): \\(\\forall x_1,x_2 \\in X: ~ x_1 \\neq x_2 \\Rightarrow f(x_1)\\neq f(x_2)\\)\n\n암기 (고등학교): 입력이 다르면 출력이 달라\n느낌: 화살표가 팍 퍼지는 느낌\n그래프를 이용한 판단 (고등학교): 수평선을 그어서 교점이 2개 이상이면 단사함수가 아님\n\n- 전사함수(위로의함수,서젝티브한 함수): \\(\\forall y \\in Y~ \\exists x \\in X\\) such that \\(f(x)=y\\)\n\n암기 (고등학교): 치역 = 공역\n암기 (대학교): inverse image가 정의역에 있어야함 (\\(\\star\\))\n느낌: 화살표가 모이는 느낌\n그래프를 이용한 판단 (고등학교): 모양으로 판단하기 애매함..1\n\n- 전단사함수(일대일대응함수,바이젝티브한 함수)"
  },
  {
    "objectID": "posts/1. 측도론/2023-03-16-3wk-1.html#예제-finite-cases",
    "href": "posts/1. 측도론/2023-03-16-3wk-1.html#예제-finite-cases",
    "title": "03wk-1: 측도론 intro (3)",
    "section": "예제 (finite cases)",
    "text": "예제 (finite cases)\n\n예시1\n\n\n\n그림1: 단사함수 O, 전사함수 X\n\n\n- 단사함수임을 따져보자!\n\\(\\forall x_1,x_2 \\in X: x_1\\neq x_2 \\Rightarrow f(x_1)\\neq f(x_2)\\)\n\n\n\n\\(x_1\\)\n\\(x_2\\)\n\\(f(x_1)\\)\n\\(f(x_2)\\)\n\n\n\n\n1\n2\nD\nB\n\n\n1\n3\nD\nA\n\n\n2\n1\nB\nD\n\n\n2\n3\nB\nA\n\n\n3\n1\nA\nD\n\n\n3\n2\nA\nB\n\n\n\n- 전사함수임을 따져보자!\n\\(\\forall y \\in Y ~ \\exists x \\in X\\) such that \\(f(x)=y\\)\n\n\n\n\\(y\\)\n\\(x\\) such that \\(f(x)=y\\)\n\n\n\n\nD\n1\n\n\nB\n2\n\n\nC\n?\n\n\nA\n3\n\n\n\n\n\n예시2\n\n\n\n그림2: 단사함수 X, 전사함수 O\n\n\n- 단사함수임을 따져보자!\n\\(\\forall x_1,x_2 \\in X: x_1\\neq x_2 \\Rightarrow f(x_1)\\neq f(x_2)\\)\n\n\n\n\\(x_1\\)\n\\(x_2\\)\n\\(f(x_1)\\)\n\\(f(x_2)\\)\n\n\n\n\n1\n2\nD\nB\n\n\n1\n3\nD\nC\n\n\n1\n4\nD\nC\n\n\n2\n1\nB\nD\n\n\n2\n3\nB\nC\n\n\n2\n4\nB\nC\n\n\n3\n1\nC\nD\n\n\n3\n2\nC\nB\n\n\n3\n4\nC\nC\n\n\n4\n1\nC\nD\n\n\n4\n2\nC\nB\n\n\n4\n3\nC\nC\n\n\n\n- 전사함수임을 따져보자!\n\\(\\forall y \\in Y ~ \\exists x \\in X\\) such that \\(f(x)=y\\)\n\n\n\n\\(y\\)\n\\(x\\) such that \\(f(x)=y\\)\n\n\n\n\nD\n1\n\n\nB\n2\n\n\nC\n3,4\n\n\n\n\n\n예시3\n\n\n\n그림3: 단사함수 X, 전사함수 X\n\n\n- 단사함수임을 따져보자!\n\\(\\forall x_1,x_2 \\in X: x_1\\neq x_2 \\Rightarrow f(x_1)\\neq f(x_2)\\)\n\n\n\n\\(x_1\\)\n\\(x_2\\)\n\\(f(x_1)\\)\n\\(f(x_2)\\)\n\n\n\n\n1\n2\nd\nd\n\n\n1\n3\nd\nc\n\n\n2\n1\nd\nd\n\n\n2\n3\nd\nc\n\n\n3\n1\nc\nd\n\n\n3\n2\nc\nd\n\n\n\n- 전사함수임을 따져보자!\n\\(\\forall y \\in Y ~ \\exists x \\in X\\) such that \\(f(x)=y\\)\n\n\n\n\\(y\\)\n\\(x\\) such that \\(f(x)=y\\)\n\n\n\n\na\n?\n\n\nd\n1,2\n\n\nb\n?\n\n\nc\n3"
  },
  {
    "objectID": "posts/1. 측도론/2023-03-16-3wk-1.html#예제-infinite-cases",
    "href": "posts/1. 측도론/2023-03-16-3wk-1.html#예제-infinite-cases",
    "title": "03wk-1: 측도론 intro (3)",
    "section": "예제 (infinite cases)",
    "text": "예제 (infinite cases)\n\n예시1\n- 아래를 판단해보자.\n\n\\(f:\\mathbb{R} \\to \\mathbb{R}\\) defined by \\(f(x)=2x+1\\). // 답2\n\\(f:\\mathbb{R} \\to \\mathbb{R}\\) defined by \\(f(x)=x^2\\). // 답3\n\\(f:\\mathbb{R} \\to \\mathbb{R}_{\\geq 0}\\) defined by \\(f(x)=x^2\\). // 답4\n\\(f:\\mathbb{Z} \\to \\{0,1\\}\\) defined by \\(f(x)= x ~\\text{mod}~ 2\\). // 답5\n\\(f:\\mathbb{N} \\to \\mathbb{N} \\cup \\{0\\}\\) defined by \\(f(x)= x-1\\). // 답6\n\\(f:\\mathbb{N} \\to \\mathbb{N}^-\\) defined by \\(f(k)= -k\\). // 답7\n\n여기에서 \\(\\mathbb{N}^-\\{-1,-2,\\dots,\\}\\) 으로 정의\n\n\n\n\n예시2\n- 집합 \\(X\\)가 집합 \\(Y\\)의 부분집합이라면 항상 \\(X\\)에서 \\(Y\\)로 향하는 단사함수가 존재함을 보여라.\n\n따라서 \\(X \\subset Y\\) \\(\\Rightarrow\\) \\(|X|\\leq |Y|\\)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "확률과정론 (2023)",
    "section": "",
    "text": "보충\n\n1wk-1, 6wk-1, 9wk-2, 10wk-1\n\n중간고사\n\n4월11일 수업시간: 범위 4wk-2까지.\n예상문제 업로드 예정\n\n질문하는 방법\n\n카카오톡: 질문하러 가기 // 학기종료이후 폐쇄함\n이메일: guebin@jbnu.ac.kr\n직접방문: 자연과학대학 본관 205호\nZoom: 카카오톡이나 이메일로 미리 시간을 정할 것\nLMS:\n\n참고도서\n\nDurrett, R. (2019). Probability: theory and examples, (Vol. 49). Cambridge university press.\n\n강의노트\n\n\n\n\n\n\n\n\n\n\nDate\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nMay 11, 2023\n\n\n11wk-1: 마코프체인 (8)\n\n\n최규빈\n\n\n\n\nMay 9, 2023\n\n\n10wk-2: 마코프체인 (7)\n\n\n최규빈\n\n\n\n\nApr 27, 2023\n\n\n09wk-1: 마코프체인 (6)\n\n\n최규빈\n\n\n\n\nApr 25, 2023\n\n\n08wk-2: 마코프체인 (5)\n\n\n최규빈\n\n\n\n\nApr 20, 2023\n\n\n08wk-1: 마코프체인 (4)\n\n\n최규빈\n\n\n\n\nApr 13, 2023\n\n\n07wk-2: 마코프체인 (3)\n\n\n최규빈\n\n\n\n\nApr 13, 2023\n\n\n07wk-1: 마코프체인 (2)\n\n\n최규빈\n\n\n\n\nApr 10, 2023\n\n\n06wk-2: 중간고사\n\n\n최규빈\n\n\n\n\nMar 30, 2023\n\n\n05wk-1: 마코프체인 (1)\n\n\n최규빈\n\n\n\n\nMar 29, 2023\n\n\n05wk-2: HW1\n\n\n최규빈\n\n\n\n\nMar 28, 2023\n\n\n04wk-2: 측도론 intro (6)\n\n\n최규빈\n\n\n\n\nMar 23, 2023\n\n\n04wk-1: 측도론 intro (5)\n\n\n최규빈\n\n\n\n\nMar 21, 2023\n\n\n03wk-2: 측도론 intro (4)\n\n\n최규빈\n\n\n\n\nMar 16, 2023\n\n\n03wk-1: 측도론 intro (3)\n\n\n최규빈\n\n\n\n\nMar 14, 2023\n\n\n02wk-2: 측도론 intro (2)\n\n\n최규빈\n\n\n\n\nMar 9, 2023\n\n\n02wk-1: 측도론 intro (1)\n\n\n최규빈\n\n\n\n\nMar 6, 2023\n\n\n01wk-2: 강의소개\n\n\n최규빈\n\n\n\n\n\n\nNo matching items"
  }
]