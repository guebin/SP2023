{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# `q_net`\n",
        "\n",
        "`-` 데이터를 모아보자."
      ],
      "id": "65e07297-ab34-43f4-bdf6-e6055138df40"
    },
    {
      "cell_type": "code",
      "execution_count": 193,
      "metadata": {},
      "outputs": [],
      "source": [
        "current_states = collections.deque(maxlen=50) \n",
        "actions = collections.deque(maxlen=50) \n",
        "next_states = collections.deque(maxlen=50) \n",
        "rewards = collections.deque(maxlen=50) \n",
        "terminations = collections.deque(maxlen=50) \n",
        "\n",
        "current_state, _ = env.reset()\n",
        "for t in range(500): \n",
        "    action = env.action_space.sample()\n",
        "    next_state, reward, terminated, _, _ = env.step(action)\n",
        "\n",
        "    current_states.append(current_state) \n",
        "    actions.append(action)\n",
        "    next_states.append(next_state)\n",
        "    rewards.append(reward)\n",
        "    terminations.append(terminated) \n",
        "    \n",
        "    current_state = next_state \n",
        "    if terminated: break "
      ],
      "id": "8a096d04-4827-4702-b96b-8dd20025f7fc"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`-` 이전코드에서 아래에 대응하는 부분을 잘 구현하면 된다.\n",
        "\n",
        "``` python\n",
        "## 1. q[x,y,a] \n",
        "agent.q = np.zeros([4,4,4])  \n",
        "\n",
        "## 2. q_estimate  \n",
        "x,y = agent.current_state\n",
        "xx,yy = agent.next_state\n",
        "a = agent.action \n",
        "q_estimated = agent.q[x,y,a] \n",
        "\n",
        "## 3. q_realistic = reward + 0.99 * q_future\n",
        "if agent.terminated:\n",
        "    q_realistic = agent.reward\n",
        "else:\n",
        "    q_future = q[xx,yy,:].max()\n",
        "    q_realistic = agent.reward + 0.99 * q_future\n",
        "\n",
        "## 4. q_estimate 와 q_realistic 를 비슷하게 만들어주는 역할을 하는 코드 \n",
        "diff = q_realistic - q_estimated \n",
        "agent.q[x,y,a] = q_estimated + 0.05 * diff\n",
        "```\n",
        "\n",
        "`1`. q_net를 설정"
      ],
      "id": "ee432dd8-edd0-4382-b967-2b2a1db070e8"
    },
    {
      "cell_type": "code",
      "execution_count": 201,
      "metadata": {},
      "outputs": [],
      "source": [
        "q_net = torch.nn.Sequential(\n",
        "    torch.nn.Linear(8,128), # 8개의 상태공간 \n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(128,64), \n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(64,32), \n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(32,4) # 4개의 action값들 \n",
        ")"
      ],
      "id": "b415ac55-a5e2-40f6-9af7-5752719caaec"
    },
    {
      "cell_type": "code",
      "execution_count": 202,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.tensor(current_state)"
      ],
      "id": "cdad3a55-b830-40f0-8716-91ea0e5578d7"
    },
    {
      "cell_type": "code",
      "execution_count": 192,
      "metadata": {},
      "outputs": [],
      "source": [
        "q_net(torch.tensor(current_state))"
      ],
      "id": "ad944757-1ddd-414e-a298-a6b790e13f68"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`1`. q_net를 설정 (배치버전)"
      ],
      "id": "ebf58e72-2ecc-47dd-84c8-c8617095d094"
    },
    {
      "cell_type": "code",
      "execution_count": 199,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_141614/982066375.py:1: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343995622/work/torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  torch.tensor(current_states)"
          ]
        }
      ],
      "source": [
        "torch.tensor(current_states)"
      ],
      "id": "1627b881-ac8e-4c75-bf02-729bd2feedd5"
    },
    {
      "cell_type": "code",
      "execution_count": 200,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.tensor(np.array(current_states)).shap"
      ],
      "id": "59d2bde1-2bee-495e-a5ab-614660117ef5"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": "3"
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  }
}